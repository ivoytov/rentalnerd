{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each models is required to generate a stack ranking of all properties listed for sale in the database.\n",
    "\n",
    "This script takes in a ranking from X months ago, and calculates how many homes have successfully sold and if it was a good sale or not. It then outputs what % of homes in each percentile successfully sold and what % of those were good sells. It should repeat it on several other rankings to get a higher count of properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import os\n",
    "from slacker import Slacker\n",
    "import json\n",
    "import requests\n",
    "from cloudinary.uploader import upload\n",
    "from cloudinary.utils import cloudinary_url\n",
    "from cloudinary.api import delete_resources_by_tag, resources_by_tag\n",
    "\n",
    "csv_path = '/home/ilya/Code/rentalnerd/scraper/'\n",
    "today = dt.date.today()\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "        \n",
    "# slack secrets (in your ~/.bashrc)\n",
    "webhook_url = os.environ.get('SLACK_URL')\n",
    "slacker = Slacker(os.environ.get('SLACK_TOKEN'))\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "discount = 0.050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_rounds(plot):\n",
    "    # uploads the graph to the web and returns the URL\n",
    "    \n",
    "    fig = plot.get_figure()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig('temp_plot.png')\n",
    "    \n",
    "    response = upload(\"temp_plot.png\")\n",
    "    url, options = cloudinary_url(response['public_id'],\n",
    "        format = response['format'],\n",
    "        crop = \"fill\")\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def slack(text, url = None, title = None):\n",
    "    print(\"Slacking: \" + text)\n",
    "    \n",
    "    if url == None:\n",
    "        data=json.dumps({\"text\": text})\n",
    "    else:\n",
    "        data = json.dumps( { \"text\": text, \"attachments\": [ { \"fallback\": \"Model MAE\"\n",
    "                                           , \"title\": title\n",
    "                                           , \"image_url\": url } ] } )\n",
    "    \n",
    "    response = requests.post(webhook_url, data , headers={'Content-Type': 'application/json'})\n",
    "    if response.status_code != 200:\n",
    "        raise ValueError('Request to slack returned an error %s, the response is:\\n%s' % (response.status_code, response.text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (12,13,14,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "closed = pd.read_csv('CSV_backups/ALL-sales.csv',nrows=10000000, index_col=['property_id','transaction_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>transaction_status</th>\n",
       "      <th>date_listed</th>\n",
       "      <th>date_closed</th>\n",
       "      <th>days_on_market</th>\n",
       "      <th>transaction_type</th>\n",
       "      <th>is_latest</th>\n",
       "      <th>price_listed</th>\n",
       "      <th>price_closed</th>\n",
       "      <th>date_transacted_latest</th>\n",
       "      <th>...</th>\n",
       "      <th>school_district_id_5.0</th>\n",
       "      <th>school_district_id_57.0</th>\n",
       "      <th>school_district_id_60.0</th>\n",
       "      <th>school_district_id_67.0</th>\n",
       "      <th>school_district_id_68.0</th>\n",
       "      <th>school_district_id_75.0</th>\n",
       "      <th>school_district_id_87.0</th>\n",
       "      <th>school_district_id_90.0</th>\n",
       "      <th>school_district_id_93.0</th>\n",
       "      <th>school_district_id_96.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_id</th>\n",
       "      <th>transaction_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>639073</th>\n",
       "      <th>23951509</th>\n",
       "      <td>374000</td>\n",
       "      <td>open</td>\n",
       "      <td>6713</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sales</td>\n",
       "      <td>True</td>\n",
       "      <td>374000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-05-19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">9036015</th>\n",
       "      <th>23951477</th>\n",
       "      <td>210000</td>\n",
       "      <td>closed</td>\n",
       "      <td>0</td>\n",
       "      <td>2600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sales</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>210000.0</td>\n",
       "      <td>2007-02-13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23951470</th>\n",
       "      <td>90000</td>\n",
       "      <td>closed</td>\n",
       "      <td>0</td>\n",
       "      <td>341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sales</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>2000-12-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637759</th>\n",
       "      <th>23951456</th>\n",
       "      <td>299999</td>\n",
       "      <td>open</td>\n",
       "      <td>6713</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sales</td>\n",
       "      <td>True</td>\n",
       "      <td>299999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-05-19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650542</th>\n",
       "      <th>23951455</th>\n",
       "      <td>299000</td>\n",
       "      <td>open</td>\n",
       "      <td>6712</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sales</td>\n",
       "      <td>True</td>\n",
       "      <td>299000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-05-18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             price transaction_status  date_listed  \\\n",
       "property_id transaction_id                                           \n",
       "639073      23951509        374000  open               6713          \n",
       "9036015     23951477        210000  closed             0             \n",
       "            23951470        90000   closed             0             \n",
       "637759      23951456        299999  open               6713          \n",
       "650542      23951455        299000  open               6712          \n",
       "\n",
       "                            date_closed  days_on_market transaction_type  \\\n",
       "property_id transaction_id                                                 \n",
       "639073      23951509        0            0.0             sales             \n",
       "9036015     23951477        2600         0.0             sales             \n",
       "            23951470        341          0.0             sales             \n",
       "637759      23951456        0            0.0             sales             \n",
       "650542      23951455        0            0.0             sales             \n",
       "\n",
       "                            is_latest  price_listed  price_closed  \\\n",
       "property_id transaction_id                                          \n",
       "639073      23951509        True       374000.0      0.0            \n",
       "9036015     23951477        True       0.0           210000.0       \n",
       "            23951470        False      0.0           90000.0        \n",
       "637759      23951456        True       299999.0      0.0            \n",
       "650542      23951455        True       299000.0      0.0            \n",
       "\n",
       "                           date_transacted_latest           ...             \\\n",
       "property_id transaction_id                                  ...              \n",
       "639073      23951509        2018-05-19                      ...              \n",
       "9036015     23951477        2007-02-13                      ...              \n",
       "            23951470        2000-12-07                      ...              \n",
       "637759      23951456        2018-05-19                      ...              \n",
       "650542      23951455        2018-05-18                      ...              \n",
       "\n",
       "                            school_district_id_5.0 school_district_id_57.0  \\\n",
       "property_id transaction_id                                                   \n",
       "639073      23951509        0                       0                        \n",
       "9036015     23951477        0                       0                        \n",
       "            23951470        0                       0                        \n",
       "637759      23951456        0                       0                        \n",
       "650542      23951455        0                       0                        \n",
       "\n",
       "                           school_district_id_60.0 school_district_id_67.0  \\\n",
       "property_id transaction_id                                                   \n",
       "639073      23951509        0                       0                        \n",
       "9036015     23951477        0                       0                        \n",
       "            23951470        0                       0                        \n",
       "637759      23951456        0                       0                        \n",
       "650542      23951455        0                       0                        \n",
       "\n",
       "                            school_district_id_68.0 school_district_id_75.0  \\\n",
       "property_id transaction_id                                                    \n",
       "639073      23951509        0                        0                        \n",
       "9036015     23951477        0                        0                        \n",
       "            23951470        0                        0                        \n",
       "637759      23951456        0                        0                        \n",
       "650542      23951455        0                        0                        \n",
       "\n",
       "                           school_district_id_87.0 school_district_id_90.0  \\\n",
       "property_id transaction_id                                                   \n",
       "639073      23951509        0                       0                        \n",
       "9036015     23951477        0                       0                        \n",
       "            23951470        0                       0                        \n",
       "637759      23951456        0                       0                        \n",
       "650542      23951455        0                       0                        \n",
       "\n",
       "                           school_district_id_93.0  school_district_id_96.0  \n",
       "property_id transaction_id                                                   \n",
       "639073      23951509        0                       0                        \n",
       "9036015     23951477        0                       0                        \n",
       "            23951470        0                       0                        \n",
       "637759      23951456        0                       0                        \n",
       "650542      23951455        0                       0                        \n",
       "\n",
       "[5 rows x 171 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'good_sell_prob'\n"
     ]
    }
   ],
   "source": [
    "# read in prior target list for backtesting purposes\n",
    "good_sell_results = np.empty([0,11])\n",
    "discount_results = np.empty([0,11])\n",
    "sell_cnt_results = np.empty([0,11])\n",
    "bins = pd.DataFrame({'A' : []})\n",
    "for lag_days in range(60,59,-1):\n",
    "    try:\n",
    "        prior_target_list = pd.read_csv(csv_path + 'good_sell/gs_target_list_' + (today-dt.timedelta(days=lag_days)) \\\n",
    "                                    .strftime('%Y%m%d') + '.csv', index_col = [0,1]) \\\n",
    "                                    .rename(columns = { 'ypred' : 'good_sell_prob'})\n",
    "\n",
    "        backtest = prior_target_list.join(closed[['price']], how=\"left\").sort_values(by='good_sell_prob',ascending=False)\n",
    "\n",
    "        backtest['discount'] = 1 - backtest.price / backtest.list\n",
    "        backtest['good_sell'] = backtest.apply(lambda row: row.discount < discount if not pd.isnull(row.price) else np.NaN, axis=1)\n",
    "        backtest['outcome'] = backtest.apply(lambda row: \"no_sell\" if pd.isnull(row.price) else \"good_sell\" if row.good_sell else \"bad_sell\", axis=1)\n",
    "            \n",
    "        backtest['probability_bin'] = pd.qcut(backtest.good_sell_prob, np.arange(0,1.1,0.1),duplicates='drop')\n",
    "        fn = 'good_sell_backtest_days_' + (today-dt.timedelta(days=lag_days)).strftime('%Y%m%d') + '.csv'\n",
    "        print(\"Saving file %s\" % fn)\n",
    "        backtest.to_csv(fn)\n",
    "        \n",
    "          \n",
    "        grouped = backtest[['probability_bin','good_sell','discount','list']].astype('float').groupby('probability_bin')\n",
    "        print(grouped.mean())\n",
    "        print(grouped.count())\n",
    "#         print(grouped.good_sell.count() / grouped.list.count())\n",
    "\n",
    "\n",
    "        # store results in arrays for graphing\n",
    "        print(grouped.good_sell.mean())\n",
    "        r = np.append(lag_days,grouped.good_sell.mean().values)\n",
    "        r = np.reshape(r,(1,11))\n",
    "        good_sell_results = np.append(good_sell_results,r,axis=0)\n",
    "        \n",
    "        r = np.append(lag_days,grouped.discount.mean().values)\n",
    "        r = np.reshape(r,(1,11))\n",
    "        discount_results = np.append(discount_results,r,axis=0)\n",
    "        \n",
    "#         r = np.append(lag_days,(grouped.good_sell.count() / grouped.list.count()).values)\n",
    "#         r = np.reshape(r,(1,11))\n",
    "#         sell_cnt_results = np.append(sell_cnt_results,r,axis=0)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         y_all = prior_target_list.good_sell_prob.mean()\n",
    "#         y_sold = backtest.good_sell_prob.mean()\n",
    "\n",
    "#         pos_trigger = prior_target_list.good_sell_prob.quantile(0.75)\n",
    "#         slack(\"Prior target list length: %i\\tNum sold: %i\\tAvg good sell prob: %f\\tAvg good sell prob of sold: %f\" \n",
    "#               % (len(prior_target_list.index), len(backtest.index),y_all, y_sold))\n",
    "\n",
    "#         num_pos = len(prior_target_list[prior_target_list.good_sell_prob > pos_trigger].index)\n",
    "#         positives = backtest[backtest.good_sell_prob > pos_trigger]\n",
    "#         y_pos = (-(positives.price - positives.list) / positives.list).median()\n",
    "#         num_sold = len(positives.index)\n",
    "#         if num_sold == 0:\n",
    "#             slack(\"Num of homes with good_sell_prob > %f: %i\\tPerc of those sold: NONE\\tMed disc to list: NA\" % (pos_trigger, num_pos) )    \n",
    "#         else:\n",
    "#             slack(\"Num of homes with good_sell_prob > %f: %i\\tPerc of those sold: %f\\tMed disc to list: %f\" \n",
    "#                   % (pos_trigger, num_pos, num_sold / num_pos *  100, y_pos * 100))\n",
    "\n",
    "#         neg_trigger = prior_target_list.good_sell_prob.quantile(0.25)\n",
    "#         num_neg = len(prior_target_list[prior_target_list.good_sell_prob < neg_trigger].index)\n",
    "#         negatives = backtest[backtest.good_sell_prob < neg_trigger]\n",
    "#         y_neg = (-(negatives.price - negatives.list) / negatives.list).median()\n",
    "#         num_sold = len(negatives.index)\n",
    "\n",
    "#         if num_sold == 0:\n",
    "#             slack(\"Num of homes with good_sell_prob < %f: %i\\tPerc of those sold: NONE\\tMedian disc to list: NA\" % (neg_trigger, num_neg))\n",
    "#         else:\n",
    "#             slack(\"Num of homes with good_sell_prob < %f: %i\\tPerc of those sold: %f\\tMedian disc to list:%f\" \n",
    "#                   % (neg_trigger, num_neg, len(negatives.index) / num_neg * 100, y_neg * 100))\n",
    "\n",
    "#         slack(backtest.to_string())\n",
    "#         backtest.to_csv(\"median_check.csv\")\n",
    "#         # store results in arrays for graphing\n",
    "#         r = np.array([[lag_days, len(prior_target_list.index), len(backtest.index), num_sold / num_pos * 100, y_pos * 100, len(negatives.index) / num_neg * 100, y_neg * 100]])\n",
    "#         model_results = np.append(model_results,r,axis=0)\n",
    "        \n",
    "    except Exception as err:   \n",
    "        print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:1: RuntimeWarning: Mean of empty slice\n",
      "  if __name__ == '__main__':\n",
      "/home/ilya/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:2: RuntimeWarning: Mean of empty slice\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/ilya/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:3: RuntimeWarning: Mean of empty slice\n",
      "  app.launch_new_instance()\n",
      "/home/ilya/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:6: RuntimeWarning: Mean of empty slice\n",
      "/home/ilya/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:7: RuntimeWarning: Mean of empty slice\n",
      "/home/ilya/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:8: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2d97c8c748>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJDX+Dzd7Jv6ajfm4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2d5e61d9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(np.nanmean(good_sell_results, axis=0)[1:])\n",
    "print(np.nanmean(discount_results, axis=0)[1:])\n",
    "print(np.nanmean(sell_cnt_results, axis=0)[1:])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.nanmean(good_sell_results, axis=0)[1:])\n",
    "plt.plot(np.nanmean(discount_results, axis=0)[1:])\n",
    "plt.plot(np.nanmean(sell_cnt_results, axis=0)[1:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lag days 1\n",
      "\n",
      "\n",
      "File b'/home/ilya/Code/rentalnerd/scraper/neural_network/nn_target_list_20180526.csv' does not exist\n"
     ]
    }
   ],
   "source": [
    "# read in prior target list for backtesting purposes\n",
    "model_results = np.empty([0,7])\n",
    "for lag_days in range(1,2):\n",
    "    print(\"Lag days %i\\n\\n\" % lag_days)\n",
    "    try:\n",
    "        prior_target_list = pd.read_csv(csv_path + 'neural_network/nn_target_list_' + (today-dt.timedelta(days=lag_days)) \\\n",
    "                                    .strftime('%Y%m%d') + '.csv', index_col = [0,1]) \\\n",
    "                                    .rename(columns = { 'ypred' : 'good_sell_prob'})\n",
    "\n",
    "        backtest = prior_target_list.join(closed[['price']], how=\"inner\").sort_values(by='good_sell_prob',ascending=False)\n",
    "        backtest['good_sell'] = (backtest.price >= (backtest.list * (1-discount)))\n",
    "        y_all = prior_target_list.good_sell_prob.mean()\n",
    "        y_sold = backtest.good_sell_prob.mean()\n",
    "\n",
    "        pos_trigger = prior_target_list.good_sell_prob.quantile(0.75)\n",
    "        slack(\"NN: Prior target list length: %i\\tNum sold: %i\\tAvg good sell prob: %f\\tAvg good sell prob of sold: %f\" \n",
    "              % (len(prior_target_list.index), len(backtest.index),y_all, y_sold))\n",
    "\n",
    "        num_pos = len(prior_target_list[prior_target_list.good_sell_prob > pos_trigger].index)\n",
    "        positives = backtest[backtest.good_sell_prob > pos_trigger]\n",
    "        y_pos = (-(positives.price - positives.list) / positives.list).median()\n",
    "        num_sold = len(positives.index)\n",
    "        if num_sold == 0:\n",
    "            slack(\"NN: Num of homes with good_sell_prob > %f: %i\\tPerc of those sold: NONE\\tMed disc to list: NA\" % (pos_trigger, num_pos) )    \n",
    "        else:\n",
    "            slack(\"NN: Num of homes with good_sell_prob > %f: %i\\tPerc of those sold: %f\\tMed disc to list: %f\" \n",
    "                  % (pos_trigger, num_pos, num_sold / num_pos *  100, y_pos * 100))\n",
    "\n",
    "        neg_trigger = prior_target_list.good_sell_prob.quantile(0.25)\n",
    "        num_neg = len(prior_target_list[prior_target_list.good_sell_prob < neg_trigger].index)\n",
    "        negatives = backtest[backtest.good_sell_prob < neg_trigger]\n",
    "        y_neg = (-(negatives.price - negatives.list) / negatives.list).median()\n",
    "        num_sold = len(negatives.index)\n",
    "\n",
    "        if num_sold == 0:\n",
    "            slack(\"NN: Num of homes with good_sell_prob < %f: %i\\tPerc of those sold: NONE\\tMedian disc to list: NA\" % (neg_trigger, num_neg))\n",
    "        else:\n",
    "            slack(\"NN: Num of homes with good_sell_prob < %f: %i\\tPerc of those sold: %f\\tMedian disc to list:%f\" \n",
    "                  % (neg_trigger, num_neg, len(negatives.index) / num_neg * 100, y_neg * 100))\n",
    "\n",
    "        slack(backtest.to_string())\n",
    "        backtest.to_csv(\"median_check.csv\")\n",
    "        # store results in arrays for graphing\n",
    "        r = np.array([[lag_days, len(prior_target_list.index), len(backtest.index), num_sold / num_pos * 100, y_pos * 100, len(negatives.index) / num_neg * 100, y_neg * 100]])\n",
    "        model_results = np.append(model_results,r,axis=0)\n",
    "        \n",
    "    except Exception as err:   \n",
    "        print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_for_sale</th>\n",
       "      <th>num_sold</th>\n",
       "      <th>perc_sold_good</th>\n",
       "      <th>discount_good</th>\n",
       "      <th>perc_sold_bad</th>\n",
       "      <th>discount_bad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [num_for_sale, num_sold, perc_sold_good, discount_good, perc_sold_bad, discount_bad]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "index = pd.Index(model_results[:,0], names='lag_days')\n",
    "graph_results = pd.DataFrame(model_results[:,1:],index=index,columns=['num_for_sale', 'num_sold', 'perc_sold_good','discount_good', 'perc_sold_bad', 'discount_bad']) \\\n",
    "                    .sort_index(ascending=False)\n",
    "\n",
    "graph_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# graph_results[['num_for_sale', 'discount_good','discount_bad']].plot(figsize=(14,14),secondary_y='num_for_sale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'/home/ilya/Code/rentalnerd/scraper/value_buy/vb_target_list_20180526.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-6edfa69ee3ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# read in prior target list for backtesting purposes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprior_target_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'value_buy/vb_target_list_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtoday\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlag_days\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m                                 \u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y%m%d'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m                                 \u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m \u001b[0;34m'ypred'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m'pnl'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbacktest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprior_target_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"inner\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pnl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilya/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilya/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilya/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilya/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilya/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas/_libs/parsers.c:4209)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas/_libs/parsers.c:8873)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'/home/ilya/Code/rentalnerd/scraper/value_buy/vb_target_list_20180526.csv' does not exist"
     ]
    }
   ],
   "source": [
    "# read in prior target list for backtesting purposes\n",
    "prior_target_list = pd.read_csv(csv_path + 'value_buy/vb_target_list_' + (today-dt.timedelta(days=lag_days)) \\\n",
    "                                .strftime('%Y%m%d') + '.csv', index_col = [0,1]) \\\n",
    "                                .rename(columns = { 'ypred' : 'pnl'})\n",
    "\n",
    "try:\n",
    "    backtest = prior_target_list.join(closed['price'], how=\"inner\").sort_values(by='pnl',ascending=False)\n",
    "    backtest['good_sell'] = (backtest.price >= (backtest.list * (1-discount)))\n",
    "    avg_pnl = backtest.pnl.mean()\n",
    "    predicted_price = backtest.predicted_price.mean()\n",
    "    sale_price = backtest.price.mean()\n",
    "\n",
    "    slack(\"Prior target list length: %i\\tNum sold: %i\\tAvg P&L: %f\\tAvg predict price: %f\\tAvg sale price: %f\" \n",
    "          % (len(prior_target_list.index), len(backtest.index),y_all, predicted_price, sale_price))\n",
    "\n",
    "    pos_trigger = prior_target_list.pnl.quantile(0.75)\n",
    "    num_pos = len(prior_target_list[prior_target_list.pnl > pos_trigger].index)\n",
    "    positives = backtest[backtest.pnl > pos_trigger]\n",
    "    y_pos = (-(positives.price - positives.list) / positives.list).mean()\n",
    "    num_sold = len(positives.index)\n",
    "    if num_sold == 0:\n",
    "        slack(\"Num of homes with pnl > %f: %i\\tPerc of those sold: NONE\\tAvg disc to list: NA\" % (pos_trigger, num_pos) )    \n",
    "    else:\n",
    "        slack(\"Num of homes with pnl > %f: %i\\tPerc of those sold: %f\\tAvg disc to list: %f\" \n",
    "              % (pos_trigger, num_pos, num_sold / num_pos, y_pos))\n",
    "\n",
    "    neg_trigger = prior_target_list.pnl.quantile(0.25)\n",
    "\n",
    "    num_neg = len(prior_target_list[prior_target_list.pnl < neg_trigger].index)\n",
    "    negatives = backtest[backtest.pnl < neg_trigger]\n",
    "    y_neg = (-(negatives.price - negatives.list) / negatives.list).mean()\n",
    "    num_sold = len(negatives.index)\n",
    "\n",
    "    if num_sold == 0:\n",
    "        slack(\"Num of homes with pnl < %f: %i\\tPerc of those sold: NONE\\tAvg disc to list: NA\" % (neg_trigger, num_neg))\n",
    "    else:\n",
    "        slack(\"Num of homes with pnl < %f: %i\\tPerc of those sold: %f\\tAvg disc to list:%f\" \n",
    "              % (neg_trigger, num_neg, len(negatives.index) / num_neg, y_neg))\n",
    "\n",
    "    slack(backtest.to_string())\n",
    "except Exception as err:   \n",
    "    slack(\"No homes sold since last run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn = pd.read_csv('neural_network/nn_target_list_' + today.strftime('%Y%m%d') + '.csv', index_col = ['property_id','transaction_id']) \\\n",
    "       .drop(['address','zipcode', 'url','list'],axis=1) \\\n",
    "       .rename(columns = { 'ypred': 'nn_good_sell_prob'}) \\\n",
    "       .drop_duplicates()\n",
    "    \n",
    "gs = pd.read_csv('good_sell/gs_target_list_'  + today.strftime('%Y%m%d') + '.csv', index_col = ['property_id','transaction_id'])  \\\n",
    "       .rename(columns = { 'ypred' : 'gs_good_sell_prob'}) \\\n",
    "       .drop_duplicates()\n",
    "        \n",
    "nn = nn[~nn.index.duplicated(keep='first')]\n",
    "gs = gs[~gs.index.duplicated(keep='first')]\n",
    "    \n",
    "print(\"Len of neural net\\t%i\" % len(nn.index))\n",
    "print(\"Len of good sell\\t%i\" % len(gs.index))\n",
    "\n",
    "c = pd.concat([nn,gs],axis=1, join='inner')\n",
    "\n",
    "c = c[(c.list < 250000) & (c.list > 100000)  \\\n",
    "      & (~c.address.str.contains(\"Rent|rent|LOT|#|Sun City\"))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "url = plot_rounds(c.query('gs_good_sell_prob > 0.00').plot.scatter(x='nn_good_sell_prob', y='gs_good_sell_prob'))\n",
    "slack(\"\", url, \"Model Correlation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for_sale = pd.read_csv('CSV_backups/ALL-for_sale.csv', index_col=['property_id','transaction_id'])\n",
    "for_sale['zipcode'] = for_sale.zipcode.apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import radians, cos, sin, asin, sqrt\n",
    "def haversine(row, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    lon1 = row.longitude\n",
    "    lat1 = row.latitude\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    km = 6367 * c\n",
    "    return km / 1.60934 # convert to miles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for r, target in d.iterrows():\n",
    "    print(target.name[0])\n",
    "    print(target.address)\n",
    "    target.longitude = for_sale.loc[target.name].longitude\n",
    "    target.latitude = for_sale.loc[target.name].latitude\n",
    "    \n",
    "    # get all properties listed for sale in the same zipcode as our target\n",
    "    z = for_sale[(for_sale.zipcode == target.zipcode)]\n",
    "    print(len(z.longitude))\n",
    "    \n",
    "    z['dist'] = z.apply(haversine, lon2 = target.longitude, lat2 = target.latitude, axis=1)\n",
    "    print(z[['address','dist']].nsmallest(5,'dist'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
