{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 8,
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
=======
   "execution_count": 8,
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
<<<<<<< HEAD
<<<<<<< HEAD
=======
=======
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sql extension is already loaded. To reload it, use:\n",
      "  %reload_ext sql\n"
     ]
    },
    {
<<<<<<< HEAD
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
=======
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
     "data": {
      "text/plain": [
       "'Connected: prod@rental_nerd'"
      ]
     },
<<<<<<< HEAD
<<<<<<< HEAD
     "execution_count": 1,
=======
     "execution_count": 8,
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
=======
     "execution_count": 8,
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext sql\n",
    "\n",
    "# imports\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "import math\n",
    "\n",
    "# today's date for output filenames\n",
    "today = (dt.date.today() - dt.date(2000, 1, 1)).days\n",
    "\n",
    "# %sql mysql://root@localhost/rental_nerd\n",
    "%sql mysql://prod:nerd@52.2.153.189/rental_nerd\n"
=======
=======
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
    "\n",
    "# today's date for output filenames\n",
    "today = dt.date.today()\n",
    "\n",
    "# %sql mysql://root@localhost/rental_nerd\n",
    "%sql mysql://prod:nerd@52.2.153.189/rental_nerd"
<<<<<<< HEAD
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
=======
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 30,
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
=======
   "execution_count": 30,
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def top_zipcodes(n = 100):\n",
    "    # query the top 100 zipcodes in the database (roughly equal to all zipcodes >10k properties)\n",
    "    query = %sql (\\\n",
    "    SELECT zipcode, COUNT(id) \\\n",
    "    FROM properties \\\n",
    "    GROUP BY zipcode \\\n",
    "    ORDER BY 2 DESC \\\n",
    "    limit :n)\n",
    "\n",
    "    zipcode_filter = query.DataFrame()\n",
    "#     print(\"Top zipcode by count is\",zipcode_filter.iloc[0,0],\"with\",zipcode_filter.iloc[0,1],\"properties\")\n",
    "#     print(\"100th zipcode by count is\",zipcode_filter.iloc[99,0],\"with\",zipcode_filter.iloc[99,1],\"properties\")\n",
    "    return zipcode_filter.zipcode.values\n",
    "\n",
    "def city_query():\n",
    "    query = %sql (\\\n",
    "    SELECT city_code, COUNT(id) \\\n",
    "    FROM property_transaction_logs \\\n",
    "    GROUP BY city_code \\\n",
    "    ORDER BY 2 DESC \\\n",
    "    limit 100)\n",
    "    return query.DataFrame().city_code.values\n",
    "\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "def sanitize(data):\n",
=======
    "def sanitize(data, zipcode_list = None):\n",
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
=======
    "def sanitize(data, zipcode_list = None):\n",
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
    "    # abort if the city has no top zipcodes\n",
    "    if data.empty:\n",
    "        return 0    \n",
    "    \n",
<<<<<<< HEAD
<<<<<<< HEAD
    "    data.drop(['abnormal', 'bookmarked', 'created_at', 'ignore', 'closed_diff_id', 'id', 'listed_diff_id',\n",
    "                      'notes', 'source', 'updated_at', 'home_type', 'sfh', 'description', \n",
    "                    'event_name', 'neighborhood'], axis=1, inplace=True)\n",
    "    \n",
    "    # fills in some sensible defaults where data is missing\n",
    "    data[\"near_golf_course\"] = data[\"near_golf_course\"].apply(lambda x: True if x == 1.0 else False)\n",
    "    data[\"has_pool\"] = data[\"has_pool\"].apply(lambda x: True if x == 1.0 else False)\n",
    "    data[\"is_latest\"] = data[\"is_latest\"].apply(lambda x: True if x == 1.0 else False)\n",
    "    data[\"garage\"] = data[\"garage\"].apply(lambda x: True if x == 1.0 else False)\n",
    "    data[\"adult\"] = data[\"adult\"].apply(lambda x: True if x == 1.0 else False)\n",
    "    data[\"construction\"] = data[\"construction\"].apply(lambda x: True if x == 1.0 else False)\n",
    "    data[\"townhouse\"] = data[\"townhouse\"].apply(lambda x: True if x == 1.0 else False)\n",
    "    data[\"mobile\"] = data[\"mobile\"].apply(lambda x: True if x == 1.0 else False)\n",
    "    data[\"fsbo\"] = data[\"fsbo\"].apply(lambda x: True if x == 1.0 else False)\n",
    "    \n",
    "    data['date_closed'] = data['date_closed'].apply(lambda x: 0 if x == None else (x - dt.date(2000, 1, 1)).days)\n",
    "    data['date_closed'] = data['date_closed'].astype(int)\n",
    "    \n",
    "    data['date_listed'] = data['date_listed'].apply(lambda x: 0 if x == None else (x - dt.date(2000, 1, 1)).days)\n",
    "    data['date_listed'] = data['date_listed'].astype(int)\n",
    "    \n",
    "    data[\"fixer\"] = data[\"fixer\"].apply(lambda x: True if x == 1.0 else False)\n",
    "    data[\"foreclosure\"] = data[\"foreclosure\"].apply(lambda x: True if x == 1.0 else False)\n",
    "\n",
    "    data[\"school_district_id\"] = data[\"school_district_id\"].astype(str)\n",
    "    data['year_built'] = data['year_built'].apply(lambda x: 1980 if math.isnan(x) else x)\n",
    "\n",
=======
=======
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
    "    data.drop(['abnormal', 'bookmarked', 'created_at', 'ignore', 'is_latest', 'closed_diff_id', 'id', 'listed_diff_id',\n",
    "                      'notes', 'source', 'updated_at', 'home_type', 'sfh', 'description', \n",
    "                    'event_name', 'neighborhood'], axis=1, inplace=True)\n",
    "    \n",
    "    # filters out any non-sensical values or fat finger mistakes in MLS listings\n",
    "    print(\"Entries before filter: \", len(data))\n",
    "\n",
    "    if(data.transaction_type.iloc[0] == 'sales'):\n",
    "        data = data[ data.price > 50000 ]\n",
    "    else:\n",
    "        data = data [ data.price > 500 ]\n",
    "    \n",
    "    if(zipcode_list is not None):\n",
    "        data = data[data.zipcode.isin(zipcode_list)]\n",
    "\n",
    "    print(\"Entries after filter: \",len(data))\n",
    "    \n",
    "    # fills in some sensible defaults where data is missing\n",
    "    data[\"near_golf_course\"] = data[\"near_golf_course\"].apply(lambda x: True if x == 1.0 else False)\n",
    "    data[\"has_pool\"] = data[\"has_pool\"].apply(lambda x: True if x == 1.0 else False)\n",
    "    data[\"garage\"] = data[\"garage\"].apply(lambda x: True if x == 1.0 else False)\n",
    "    data['date_closed'] = data['date_closed'].apply(lambda x: 0 if x == None else (x - dt.date(2000, 1, 1)).days)\n",
    "    data['date_closed'] = data['date_closed'].astype(int)\n",
    "    data[\"school_district_id\"] = data[\"school_district_id\"].astype(str)\n",
<<<<<<< HEAD
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
=======
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
    "    \n",
    "    # convert the area name into dummy variables\n",
    "    dm = pd.get_dummies(data[['city_code', 'zipcode','school_district_id']], prefix=['city_code','zipcode','school_district_id'])\n",
    "    data = pd.concat([data, dm], axis=1)\n",
    "    del dm\n",
    "    \n",
    "    return data\n",
    "\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "def query(city=\"%\", zipcode=None, limit=100, start_date=\"2000-01-01 10:01:13\", ttype='sales'):\n",
=======
    "def query(city=\"%\", zipcode=None, limit=100, start_date=\"2000-01-01 10:01:13\", ttype='sales',tstatus='open'):\n",
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
=======
    "def query(city=\"%\", zipcode=None, limit=100, start_date=\"2000-01-01 10:01:13\", ttype='sales',tstatus='open'):\n",
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
    "    # convert array of zipcodes into sql string which looks like a tuple\n",
    "    placeholders = tuple(zipcode)\n",
    "    \n",
    "    # sql query helper function\n",
    "    query = %sql (\\\n",
    "    SELECT  \\\n",
    "    *, \\\n",
    "    properties.id as 'property_id', \\\n",
    "    property_transaction_logs.id as 'transaction_id', \\\n",
    "    property_school_districts.school_district_id \\\n",
    "    FROM  \\\n",
    "    property_transaction_logs, \\\n",
    "    properties \\\n",
    "    LEFT JOIN \\\n",
    "    property_school_districts ON property_school_districts.property_id = properties.id \\\n",
    "    where  \\\n",
    "    ( abnormal = false OR abnormal IS NULL OR abnormal = 0 ) and \\\n",
    "    properties.sqft between 1 and 10000 and \\\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "    property_transaction_logs.price between 50000 and 400000 and \\\n",
    "    properties.bedrooms <= 6 and \\\n",
    "    properties.bathrooms <= 6 and \\\n",
    "    properties.home_type = 'sfh' and \\\n",
    "    ((properties.latitude BETWEEN 33.421516 AND 33.665268 and \\\n",
    "    properties.longitude BETWEEN -112.274780 AND -111.810608 ) OR \\\n",
    "    (properties.latitude BETWEEN 33.283149 AND 33.513597 and \\\n",
    "    properties.longitude BETWEEN -111.972656 AND -111.846313 )) and \\\n",
    "    properties.`id` = property_transaction_logs.`property_id` and \\\n",
    "    property_transaction_logs.`city_code` = :city and \\\n",
    "    property_transaction_logs.`transaction_type` = :ttype and \\\n",
=======
=======
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
    "    property_transaction_logs.price between 500 and 400000 and \\\n",
    "    properties.bedrooms <= 6 and \\\n",
    "    properties.bathrooms <= 6 and \\\n",
    "    properties.home_type = 'sfh' and \\\n",
    "    ((properties.latitude BETWEEN 33.282668 AND 33.665268 and \\\n",
    "    properties.longitude BETWEEN -112.274780 AND -111.810608 ) OR ( properties.zipcode IN ('85375', '85142', '85143', '85326', '85249', '85234', '85225', '85086', '85041', '85204', '85205', '85209', '85295', '85037', '85233', '85286', '85248', '85331', '85226', '85224', '85048', '85022', '85251', '85298', '85018', '85029', '85138', '85051', '85254', '85302', '85297', '85020', '85255', '85323', '85016', '85335', '85388', '85373', '85202', '85027', '85706', '85035', '85257', '85023', '85043', '85203', '85304', '85303', '85212', '85301', '85392', '85206', '85044', '85053', '85712', '85262', '85374', '85250', '85396', '85015', '85215', '85028', '85021', '85210', '85050', '85306', '85118', '85310', '85253', '85704', '85711', '85296', '85024', '85040', '85017', '85085', '85383', '85009', '85008', '85031', '85019', '85382', '85139', '85006', '85213', '85353', '85013', '85033', '85339', '85258', '85207', '85266', '85340', '85705', '85308', '85351', '85355', '85305', '85007', '85379', '85087', '85390', '85395', '85338', '85757', '85378', '85208', '85345', '85260', '85307', '85045', '85282', '85268', '85032', '85003', '85012', '85263', '85281', '85042', '85054', '85259', '85377', '85283', '85321', '85363', '85083', '85719', '85201', '85701', '85014', '85381', '85004', '85747', '85716', '85387', '85710', '85140') ) ) and \\\n",
    "    properties.zipcode IN :placeholders and \\\n",
    "    properties.`id` = property_transaction_logs.`property_id` and \\\n",
    "    property_transaction_logs.`city_code` = :city and \\\n",
    "    property_transaction_logs.`transaction_type` = :ttype and \\\n",
    "    property_transaction_logs.`transaction_status` = :tstatus and \\\n",
    "    property_transaction_logs.`is_latest` = true and \\\n",
<<<<<<< HEAD
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
=======
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
    "    (properties.fixer is Null or properties.fixer = False) and \\\n",
    "    (properties.townhouse is Null or properties.townhouse = False) and \\\n",
    "    (properties.foreclosure is Null or properties.foreclosure = False) and \\\n",
    "    (properties.adult is Null or properties.adult = False) and \\\n",
    "    (properties.construction is Null or properties.construction = False) and \\\n",
    "    (properties.mobile is Null or properties.mobile = False) \\\n",
    "    order by \\\n",
    "    property_transaction_logs.id desc \\\n",
    "    limit :limit) \n",
    "    \n",
    "    q = query.DataFrame()\n",
    "    q = q.loc[:,~q.columns.duplicated()]\n",
    "    q.set_index('property_id', inplace=True)\n",
    "    q.index.name = 'property_id'\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "    return q"
=======
=======
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
    "    return q\n",
    "\n",
    "def queue_city_queries(city, zipcode_list, for_sale_zipcode_list):\n",
    "    i = query(city=city, zipcode=zipcode_list, limit=limit,ttype = 'sales',tstatus='closed')\n",
    "    j = query(city=city, zipcode=for_sale_zipcode_list, limit=limit,ttype = 'sales',tstatus='open') \n",
    "    \n",
    "    q = pd.concat([i,j])\n",
    "    q = sanitize(q)\n",
    "    \n",
    "    for_sale = q[(q.transaction_type == \"sales\") & \n",
    "                 (q.transaction_status == \"open\") & \n",
    "                 (q.date_listed > (today - dt.timedelta(days=6000))) &\n",
    "                 (q.zipcode.isin(for_sale_zipcode_list))]\n",
    "    sales = q[(q.transaction_type == \"sales\") & (q.transaction_status == \"closed\")]\n",
    "        \n",
    "    data = {'sales': sales, 'for_sale': for_sale }\n",
    "    \n",
    "    return data"
<<<<<<< HEAD
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
=======
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 31,
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
=======
   "execution_count": 31,
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
<<<<<<< HEAD
      "200 rows affected.\n",
      "['85375', '85142', '85143', '85326', '85249', '85234', '85225', '85086', '85041', '85204', '85205', '85209', '85295', '85037', '85233', '85286', '85248', '85331', '85224', '85226', '85048', '85022', '85251', '85298', '85018', '85029', '85138', '85051', '85254', '85302', '85020', '85297', '85255', '85323', '85016', '85335', '85388', '85373', '85202', '85027', '85706', '85035', '85257', '85043', '85023', '85203', '85304', '85303', '85212', '85392', '85301', '85206', '85044', '85053', '85712', '85374', '85262']\n"
=======
      "1845 rows affected.\n",
      "1845 rows affected.\n"
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
=======
      "1845 rows affected.\n",
      "1845 rows affected.\n"
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
     ]
    }
   ],
   "source": [
    "# get list of top zipcodes to only run the model on them (put down 2000 to get every zipcode)\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "# we filter the current listings further to only see the top zipcodes to not predict prices in areas with weak coverage\n",
    "focus_zipcodes = top_zipcodes(200)\n",
    "phoenix_zips = list(filter(lambda x: x.startswith('85'), focus_zipcodes))\n",
    "print(phoenix_zips)\n",
=======
=======
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
    "zipcode_list = top_zipcodes(2000)\n",
    "\n",
    "# we filter the current listings further to only see the top zipcodes to not predict prices in areas with weak coverage\n",
    "focus_zipcodes = top_zipcodes(2000)\n",
<<<<<<< HEAD
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
=======
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
    "\n",
    "# limit on number of lines returned from sql queries (for debugging)\n",
    "limit = 2000000"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 4,
   "metadata": {
    "collapsed": false
=======
=======
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": false
<<<<<<< HEAD
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
=======
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
<<<<<<< HEAD
      "509805 rows affected.\n"
=======
=======
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
      "110329 rows affected.\n",
      "17922 rows affected.\n",
      "Entries before filter:  128251\n",
      "Entries after filter:  123585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ilya/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ilya/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ilya/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ilya/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ilya/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
<<<<<<< HEAD
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
=======
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
<<<<<<< HEAD
    "q = query(city='PH', zipcode=phoenix_zips, limit=limit,ttype = 'sales')\n",
    "q = sanitize(q)"
=======
=======
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
    "q = queue_city_queries(\"PH\", zipcode_list, focus_zipcodes)\n",
    "\n",
    "for k,v in q.items():\n",
    "    v.to_csv('CSV_backups/ALL-' + k + '.csv')\n",
    "    "
<<<<<<< HEAD
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
=======
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for_sale = q[(q.transaction_type == \"sales\") & \n",
    "             (q.transaction_status == \"open\") & \n",
    "             (q.date_listed > (today - 365)) &\n",
    "             (q.is_latest == True)] \n",
    "sales = q[(q.transaction_type == \"sales\")]\n",
    "\n",
    "for_sale.to_csv('CSV_backups/ALL-for_sale.csv')\n",
    "sales.to_csv('CSV_backups/ALL-sales.csv')"
=======
=======
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "670 rows affected.\n",
      "['85375', '85142', '85143', '85326', '85249', '85234', '85225', '85086', '85041', '85204', '85205', '85209', '85295', '85037', '85233', '85286', '85248', '85331', '85226', '85224', '85048', '85022', '85251', '85298', '85018', '85029', '85138', '85051', '85254', '85302', '85297', '85020', '85255', '85323', '85016', '85335', '85388', '85373', '85202', '85027', '85706', '85035', '85257', '85023', '85043', '85203', '85304', '85303', '85212', '85301', '85392', '85206', '85044', '85053', '85712', '85262', '85374', '85250', '85396', '85015', '85215', '85028', '85021', '85210', '85050', '85306', '85118', '85310', '85253', '85704', '85711', '85296', '85024', '85040', '85017', '85085', '85383', '85009', '85008', '85031', '85019', '85382', '85139', '85006', '85213', '85353', '85013', '85033', '85339', '85258', '85207', '85266', '85340', '85705', '85308', '85351', '85355', '85305', '85007', '85379', '85087', '85390', '85395', '85338', '85757', '85378', '85208', '85345', '85260', '85307', '85045', '85282', '85268', '85032', '85003', '85012', '85263', '85281', '85042', '85054', '85259', '85377', '85283', '85321', '85363', '85083', '85719', '85201', '85701', '85014', '85381', '85004', '85747', '85716', '85387', '85710', '85140']\n"
     ]
    }
   ],
   "source": [
    "zipcode_list = top_zipcodes(670)\n",
    "phoenix_zips = list(filter(lambda x: x.startswith('85'), zipcode_list))\n",
    "print(phoenix_zips)"
<<<<<<< HEAD
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
=======
>>>>>>> 685dc74855ceed9ce85ad077a9437fa5faaaeb07
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
