{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sql extension is already loaded. To reload it, use:\n",
      "  %reload_ext sql\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Connected: prod@rental_nerd'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext sql\n",
    "\n",
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit  # for timing models\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# this allows plots to appear directly in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# today's date for output filenames\n",
    "today = dt.date.today()\n",
    "\n",
    "# where to save the xgb models - they get huge so keep them out of any git path\n",
    "path = '/home/ivoytov/rentalnerd-models/'\n",
    "\n",
    "# data columns used for the booster\n",
    "factors = ['property_id', 'bedrooms', 'bathrooms', 'sqft','longitude', 'latitude','zipcode', 'elevation', 'garage'\n",
    "                          ,'year_built', 'level','dist_to_park','dist_to_golf_course', 'has_pool'\n",
    "                          ,'date_closed','multifamily', 'hoa_fees', 'lot']\n",
    "\n",
    "# booster parameters\n",
    "param = {'verbose': 1, 'max_depth':6, 'num_parallel_tree': 10000, 'eval_metric':'mae' }\n",
    "num_round = 10\n",
    "plst = param.items()\n",
    "\n",
    "# slack webhook secret url\n",
    "webhook_url = 'https://hooks.slack.com/services/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'\n",
    "\n",
    "# disable warning on assignment without copy\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "# %sql mysql://root@localhost/rental_nerd\n",
    "%sql mysql://prod:nerd@52.2.153.189/rental_nerd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sanitize(data, zipcode_list = None):\n",
    "    # filters out any non-sensical values or fat finger mistakes in MLS listings\n",
    "    print(\"Entries before filter: \", len(data))\n",
    "\n",
    "    if(data.transaction_type.iloc[0] == 'sales'):\n",
    "        data = data[ data.price > 50000 ]\n",
    "    else:\n",
    "        data = data [ data.price > 500 ]\n",
    "    \n",
    "    if(zipcode_list is not None):\n",
    "        data = data[data.zipcode.isin(zipcode_list)]\n",
    "\n",
    "    print(\"Entries after filter: \",len(data))\n",
    "    \n",
    "    # fills in some sensible defaults where data is missing\n",
    "    data[\"near_golf_course\"] = data[\"near_golf_course\"].apply(lambda x: True if x == 1.0 else False)\n",
    "    data[\"has_pool\"] = data[\"has_pool\"].apply(lambda x: True if x == 1.0 else False)\n",
    "    data[\"garage\"] = data[\"garage\"].apply(lambda x: True if x == 1.0 else False)\n",
    "    data[\"multifamily\"] = data[\"home_type\"].apply(lambda x: True if x == \"mfh\" else False)\n",
    "    data['date_closed'] = data['date_closed'].apply(lambda x: (x - dt.date(2000, 1, 1)))\n",
    "    data['date_closed'] = data['date_closed'].astype(int)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def query(transaction_type, transaction_status, city, zipcode, limit, start_date=\"2000-01-01 10:01:13\", end_date=today):\n",
    "    # convert array of zipcodes into sql string which looks like a tuple\n",
    "    placeholders = tuple(zipcode)\n",
    "    \n",
    "    # sql query helper function\n",
    "    query = %sql (\\\n",
    "    select  \\\n",
    "    *  \\\n",
    "    from  \\\n",
    "    properties, \\\n",
    "    property_transaction_logs, \\\n",
    "    area_name_zipcodes \\\n",
    "    where  \\\n",
    "    properties.sqft between 1 and 10000 and \\\n",
    "    property_transaction_logs.price between 500 and 400000 and \\\n",
    "    properties.bedrooms <= 6 and \\\n",
    "    properties.bathrooms <= 6 and \\\n",
    "    properties.home_type = 'sfh' and \\\n",
    "    property_transaction_logs.created_at > :start_date and \\\n",
    "    property_transaction_logs.created_at < :end_date and \\\n",
    "    area_name_zipcodes.`area_name` LIKE :city and \\\n",
    "    area_name_zipcodes.`zipcode` = properties.`zipcode` and     \\\n",
    "    properties.zipcode IN :placeholders and \\\n",
    "    properties.`id` = property_transaction_logs.`property_id` and \\\n",
    "    property_transaction_logs.`transaction_status` = :transaction_status and \\\n",
    "    property_transaction_logs.`transaction_type` = :transaction_type and \\\n",
    "    property_transaction_logs.`is_latest` = true \\\n",
    "    order by \\\n",
    "    property_transaction_logs.id desc \\\n",
    "    limit :limit) \n",
    "\n",
    "    return query.DataFrame().T.groupby(level=0).first().T\n",
    "\n",
    "def output_model_metrics( x, ypred, y_known, t ):\n",
    "    #Print model report:\n",
    "    mae = metrics.mean_absolute_error(y_known, ypred)\n",
    "    r2 = metrics.explained_variance_score(y_known, ypred)\n",
    "  \n",
    "    slack(\"Model Report: %s \\n n: %i \\n MAE Score: %f \\n R^2: %f\" % (t, len(y_known), mae, r2))\n",
    "\n",
    "def top_zipcodes(n = 100):\n",
    "    # query the top 100 zipcodes in the database (roughly equal to all zipcodes >10k properties)\n",
    "    query = %sql (\\\n",
    "    SELECT zipcode, COUNT(id) \\\n",
    "    FROM properties \\\n",
    "    GROUP BY zipcode \\\n",
    "    ORDER BY 2 DESC \\\n",
    "    limit :n)\n",
    "\n",
    "    zipcode_filter = query.DataFrame()\n",
    "    print(\"Top zipcode by count is\",zipcode_filter.iloc[0,0],\"with\",zipcode_filter.iloc[0,1],\"properties\")\n",
    "    print(\"100th zipcode by count is\",zipcode_filter.iloc[99,0],\"with\",zipcode_filter.iloc[99,1],\"properties\")\n",
    "    return zipcode_filter.zipcode.values\n",
    "\n",
    "\n",
    "def city_query():\n",
    "    query = %sql (\\\n",
    "    SELECT area_name, COUNT(id) \\\n",
    "    FROM area_name_zipcodes \\\n",
    "    GROUP BY area_name \\\n",
    "    ORDER BY 2 DESC \\\n",
    "    limit 100)\n",
    "    return query.DataFrame().area_name.values\n",
    "\n",
    "def slack(text):\n",
    "    print(\"Slacking: \" + text)\n",
    "    response = requests.post(webhook_url, data=json.dumps({\"text\": text}), headers={'Content-Type': 'application/json'})\n",
    "    if response.status_code != 200:\n",
    "        raise ValueError('Request to slack returned an error %s, the response is:\\n%s' % (response.status_code, response.text))\n",
    "        \n",
    "def generate_city_model(city, cut_off_date, zipcode_list):\n",
    "    sales_train = query('sales', 'closed', city, zipcode_list, limit, \"2000-01-01 10:01:13\", cut_off_date)\n",
    "    sales_test = query('sales', 'closed', city, zipcode_list, limit, cut_off_date, today)\n",
    "\n",
    "    # abort if the city has no top zipcodes\n",
    "    if sales_train.empty or sales_test.empty:\n",
    "        print('no rows returned, skipping city')\n",
    "        return 0\n",
    "      \n",
    "    sales_train = sanitize(sales_train)\n",
    "    sales_test = sanitize(sales_test)\n",
    "\n",
    "    # train model based on historical sales information\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    dtrain = xgb.DMatrix(sales_train[factors].values, label=sales_train.price, feature_names=factors)\n",
    "    dtest = xgb.DMatrix(sales_test[factors].values, label=sales_test.price, feature_names=factors)\n",
    "    watchlist  = [(dtest,'eval'), (dtrain,'train')]\n",
    "\n",
    "    bst = xgb.train( plst, dtrain, num_round, watchlist )\n",
    "\n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    slack(\"Calculated sales model for %s; time to train: %f hours\" % (city, (elapsed / 3600)))\n",
    "\n",
    "    # predict the training set using the model - note this is in sample testing\n",
    "    ypred = bst.predict(dtrain)\n",
    "    output_model_metrics( dtrain, ypred, sales_train.price, 'train' )\n",
    "\n",
    "    # predict the testing set using the model - note this is in sample testing\n",
    "    ypred = bst.predict(dtest)\n",
    "    output_model_metrics( dtest, ypred, sales_test.price, 'test' )\n",
    "\n",
    "    for_sale = query('sales', 'open', city, zipcode_list, limit)\n",
    "    # use today's date for 'close date' since the transaction is still open i.e. home is currently listed for sale\n",
    "    for_sale.date_closed = today\n",
    "\n",
    "    # need this to clean data but also to adjust the \"date closed\" to be # of secs from 1/1/2000 (the format the model uses)\n",
    "    for_sale = sanitize(for_sale, zipcode_list)\n",
    "\n",
    "    target = xgb.DMatrix( for_sale[factors].values, feature_names=factors)\n",
    "\n",
    "    ypred = bst.predict(target)\n",
    "\n",
    "    values = np.column_stack((for_sale.property_id.values\n",
    "                             ,for_sale.address.values\n",
    "                             ,ypred\n",
    "                             ,for_sale.price.values\n",
    "                             ,ypred-for_sale.price))\n",
    "    output = pd.DataFrame(values[:,1:],index=values[:,0],columns=['address','ypred','list','gain-loss'])\n",
    "    output = output.sort_values(by='gain-loss',ascending=False)\n",
    "\n",
    "    rent_train = query(transaction_type='rental',transaction_status='closed', city=city,zipcode=zipcode_list, limit=limit)\n",
    "    rent_train = sanitize(rent_train, zipcode_list)\n",
    "\n",
    "    # train rental model\n",
    "    start_time = timeit.default_timer() # start timer\n",
    "    dtrain = xgb.DMatrix(rent_train[factors].values, label=rent_train.price, feature_names=factors)\n",
    "    rent_bst = xgb.train( plst, dtrain, num_round )\n",
    "\n",
    "    elapsed = timeit.default_timer() - start_time # end timer\n",
    "    slack(\"Time to train rental model (hrs): %f \" % (elapsed / 3600))\n",
    "\n",
    "    # predict the training set using the model - note this is in sample testing\n",
    "    ypred = rent_bst.predict(dtrain)\n",
    "    output_model_metrics( dtrain, ypred, rent_train.price, 'train' )\n",
    "\n",
    "    # predict rent prices for home that are listed for sale\n",
    "    ypred = rent_bst.predict(target)\n",
    "    ypred = pd.Series(ypred,index=output.index)\n",
    "    ypred.name = \"rent\"\n",
    "\n",
    "    # calculate estimated cap rate\n",
    "    cr = ypred * 12 / output.list\n",
    "    cr.name = \"cap rate\"\n",
    "\n",
    "    # combine rent predictions to homes listed for sale\n",
    "    best_of = pd.concat([output,ypred, cr],axis=1)\n",
    "    best_of = best_of[ (best_of['gain-loss'] < 50000) & ((best_of['gain-loss'] / best_of.list).abs() < 0.5) ]\n",
    "\n",
    "    # save target list\n",
    "    best_of.to_csv(city+'_target_list.csv')\n",
    "\n",
    "    # save model\n",
    "    bst.save_model(path +  city.lower() + '_sales_' + today.strftime('%Y%m%d') + '.model')\n",
    "\n",
    "    # save rental model\n",
    "    rent_bst.save_model(path + city.lower() + '_rent_' + today.strftime('%Y%m%d') + '.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1180 rows affected.\n",
      "Top zipcode by count is 94565 with 18730 properties\n",
      "100th zipcode by count is 89147 with 9682 properties\n",
      "11 rows affected.\n",
      "Order of city models to run: ['BAY_AREA' 'HOUSTON' 'PH' 'VEGAS' 'DENVER' 'ST_LOUIS' 'SEATTLE' 'SF'\n",
      " 'PORTLAND' 'TUSCON' 'DETROIT']\n",
      "0 rows affected.\n",
      "430210 rows affected.\n",
      "no rows returned, skipping city\n",
      "0 rows affected.\n",
      "229190 rows affected.\n",
      "no rows returned, skipping city\n",
      "570437 rows affected.\n",
      "16596 rows affected.\n",
      "Entries before filter:  570437\n",
      "Entries after filter:  523451\n",
      "Entries before filter:  16596\n",
      "Entries after filter:  15672\n"
     ]
    }
   ],
   "source": [
    "# get list of top zipcodes to only run the model on them\n",
    "zipcode_list = top_zipcodes(20000)\n",
    "\n",
    "\n",
    "# limit on number of lines returned from sql queries (for debugging)\n",
    "limit = 10000000\n",
    "\n",
    "cut_off_date = (today - dt.timedelta(6*365/12)).isoformat()\n",
    "\n",
    "# get list of all available cities\n",
    "cities = city_query()\n",
    "print(\"Order of city models to run:\", cities)\n",
    "\n",
    "for city in cities:\n",
    "    generate_city_model(city, cut_off_date, zipcode_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "slack(\"Everything completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
