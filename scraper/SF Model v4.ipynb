{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/IPython/config.py:13: ShimWarning: The `IPython.config` package has been deprecated. You should import from traitlets.config instead.\n",
      "  \"You should import from traitlets.config instead.\", ShimWarning)\n",
      "/usr/local/lib/python2.7/site-packages/IPython/utils/traitlets.py:5: UserWarning: IPython.utils.traitlets has moved to a top-level traitlets package.\n",
      "  warn(\"IPython.utils.traitlets has moved to a top-level traitlets package.\")\n"
     ]
    }
   ],
   "source": [
    "%load_ext sql\n",
    "import statsmodels.api as sma\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "import datetime\n",
    "from scipy import stats\n",
    "import math\n",
    "\n",
    "from mpl_toolkits.basemap import Basemap # Basemap must be imported before Shapely due to conflict\n",
    "import fiona\n",
    "import shapely as shapely\n",
    "from geopandas import GeoSeries, GeoDataFrame\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry import asShape\n",
    "from time import gmtime, strftime\n",
    "from array import array\n",
    "\n",
    "\n",
    "# imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import math\n",
    "\n",
    "# follow the usual sklearn pattern: import, instantiate, fit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.collections import PatchCollection\n",
    "\n",
    "import statsmodels.formula.api as sm\n",
    "\n",
    "# this allows plots to appear directly in the notebook\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Connected: prod@rental_nerd'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql mysql://prod:nerd@52.2.153.189/rental_nerd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rows affected.\n"
     ]
    }
   ],
   "source": [
    "# query = %sql (\\\n",
    "# SELECT  \\\n",
    "# properties.id as 'property_id', \\\n",
    "# properties.address,  \\\n",
    "# properties.bedrooms,  \\\n",
    "# properties.bathrooms,  \\\n",
    "# properties.sqft,  \\\n",
    "# properties.source,  \\\n",
    "# properties.origin_url,  \\\n",
    "# properties.longitude,  \\\n",
    "# properties.latitude,  \\\n",
    "# properties.elevation,  \\\n",
    "# (2016 - properties.year_built) as 'age',  \\\n",
    "# properties.garage,  \\\n",
    "# properties.level,  \\\n",
    "# properties.luxurious,  \\\n",
    "# properties.dist_to_park,  \\\n",
    "# properties.zipcode, \\\n",
    "# properties.dist_to_golf_course, \\\n",
    "# properties.near_golf_course, \\\n",
    "# properties.has_pool, \\\n",
    "# properties.home_type, \\\n",
    "# property_transaction_logs.id 'ptl_id',  \\\n",
    "# property_transaction_logs.transaction_type,  \\\n",
    "# property_transaction_logs.price,  \\\n",
    "# property_transaction_logs.transaction_status,  \\\n",
    "# property_transaction_logs.days_on_market,  \\\n",
    "# property_transaction_logs.date_closed as 'date',  \\\n",
    "# property_transaction_logs.date_listed,  \\\n",
    "# neighborhoods.name as 'neighborhood',  \\\n",
    "# neighborhoods.id as 'nid',  \\\n",
    "# neighborhoods.shapefile_source,  \\\n",
    "# property_school_districts.school_district_id \\\n",
    "# FROM  \\\n",
    "# properties,  \\\n",
    "# property_transaction_logs,  \\\n",
    "# property_neighborhoods,  \\\n",
    "# neighborhoods,  \\\n",
    "# property_school_districts \\\n",
    "# WHERE  \\\n",
    "# property_school_districts.property_id = properties.id AND  \\\n",
    "# property_transaction_logs.property_id = properties.id AND  \\\n",
    "# property_transaction_logs.transaction_type = \"rental\" AND  \\\n",
    "# property_transaction_logs.date_closed is not null AND \\\n",
    "# neighborhoods.shapefile_source = \"SF\" AND  \\\n",
    "# properties.id = property_neighborhoods.property_id AND  \\\n",
    "# property_neighborhoods.neighborhood_id = neighborhoods.id AND \\\n",
    "# properties.sqft > 0 AND \\\n",
    "# properties.bedrooms IS NOT NULL AND \\\n",
    "# properties.bathrooms IS NOT NULL AND \\\n",
    "# properties.elevation IS NOT NULL AND \\\n",
    "# properties.level IS NOT NULL AND \\\n",
    "# properties.dist_to_park IS NOT NULL AND \\\n",
    "# properties.near_golf_course IS NOT NULL AND \\\n",
    "# properties.home_type IS NOT NULL AND \\\n",
    "# properties.zipcode IS NOT NULL AND \\\n",
    "# properties.sqft IS NOT NULL AND \\\n",
    "# properties.year_built IS NOT NULL AND \\\n",
    "# property_transaction_logs.price > 0 )\n",
    "           \n",
    "    \n",
    "# # properties.has_pool IS NOT NULL AND \\\n",
    "# # properties.garage IS NOT NULL AND \\\n",
    "# data = query.DataFrame()\n",
    "# data_copy = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383 rows affected.\n"
     ]
    }
   ],
   "source": [
    "query = %sql (\\\n",
    "SELECT  \\\n",
    "properties.address, \\\n",
    "properties.bedrooms, \\\n",
    "properties.bathrooms, \\\n",
    "properties.sqft, \\\n",
    "properties.source, \\\n",
    "properties.origin_url, \\\n",
    "properties.longitude, \\\n",
    "properties.latitude, \\\n",
    "properties.elevation, \\\n",
    "(2016 - properties.year_built) as 'age',  \\\n",
    "properties.garage, \\\n",
    "properties.level, \\\n",
    "property_transactions.transaction_type, \\\n",
    "property_transaction_logs.price, \\\n",
    "property_transaction_logs.transaction_status, \\\n",
    "property_transaction_logs.days_on_market, \\\n",
    "property_transaction_logs.date_closed as 'date',  \\\n",
    "property_transaction_logs.date_listed, \\\n",
    "neighborhoods.name as 'neighborhood', \\\n",
    "neighborhoods.id as 'nid', \\\n",
    "neighborhoods.shapefile_source \\\n",
    "FROM \\\n",
    "properties, \\\n",
    "property_transactions, \\\n",
    "property_transaction_logs, \\\n",
    "property_neighborhoods, \\\n",
    "neighborhoods \\\n",
    "WHERE \\\n",
    "properties.id = property_transactions.property_id AND \\\n",
    "property_transactions.property_transaction_log_id = property_transaction_logs.id AND \\\n",
    "property_transactions.transaction_type = \"rental\" AND \\\n",
    "neighborhoods.shapefile_source = \"SF\" AND \\\n",
    "properties.id = property_neighborhoods.property_id AND \\\n",
    "property_neighborhoods.neighborhood_id = neighborhoods.id)\n",
    "\n",
    "data = query.DataFrame()\n",
    "data_copy = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a column of GeoSeries - each house should be represented by a point\n",
    "pts = GeoSeries([Point(x, y) for x, y in zip(data['longitude'], data['latitude'])])\n",
    "data['latlong'] = pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create year dummy variables (because date isn't very intuitive variable)\n",
    "data[\"year\"] = pd.DatetimeIndex(data[\"date\"]).to_period('A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data[\"near_golf_course\"] = data[\"near_golf_course\"].apply(lambda x: True if x == 1.0 else False)\n",
    "# data[\"has_pool\"] = data[\"has_pool\"].apply(lambda x: True if x == 1.0 else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>elevation</th>\n",
       "      <th>age</th>\n",
       "      <th>garage</th>\n",
       "      <th>level</th>\n",
       "      <th>price</th>\n",
       "      <th>days_on_market</th>\n",
       "      <th>nid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1204.000000</td>\n",
       "      <td>1204.000000</td>\n",
       "      <td>1204.000000</td>\n",
       "      <td>1204.000000</td>\n",
       "      <td>1204.000000</td>\n",
       "      <td>1204.000000</td>\n",
       "      <td>443.000000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>1204.000000</td>\n",
       "      <td>1204.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>1204.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.032392</td>\n",
       "      <td>1.643688</td>\n",
       "      <td>1144.402824</td>\n",
       "      <td>-122.423732</td>\n",
       "      <td>37.770007</td>\n",
       "      <td>46.561140</td>\n",
       "      <td>54.404063</td>\n",
       "      <td>0.125475</td>\n",
       "      <td>3.470930</td>\n",
       "      <td>10663.893688</td>\n",
       "      <td>8.642000</td>\n",
       "      <td>50.439369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.070164</td>\n",
       "      <td>0.777992</td>\n",
       "      <td>761.550186</td>\n",
       "      <td>0.029419</td>\n",
       "      <td>0.022224</td>\n",
       "      <td>47.924815</td>\n",
       "      <td>39.260779</td>\n",
       "      <td>0.331572</td>\n",
       "      <td>6.713467</td>\n",
       "      <td>124357.240061</td>\n",
       "      <td>149.231733</td>\n",
       "      <td>25.861556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-122.510000</td>\n",
       "      <td>37.708900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1072.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>729.500000</td>\n",
       "      <td>-122.440000</td>\n",
       "      <td>37.756175</td>\n",
       "      <td>8.107577</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3700.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1100.000000</td>\n",
       "      <td>-122.420000</td>\n",
       "      <td>37.775900</td>\n",
       "      <td>31.017000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4500.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>56.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>-122.397000</td>\n",
       "      <td>37.787100</td>\n",
       "      <td>69.020950</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5991.250000</td>\n",
       "      <td>33.250000</td>\n",
       "      <td>74.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6645.000000</td>\n",
       "      <td>-122.370000</td>\n",
       "      <td>37.806300</td>\n",
       "      <td>247.736000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>3850000.000000</td>\n",
       "      <td>738.000000</td>\n",
       "      <td>93.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          bedrooms    bathrooms         sqft    longitude     latitude  \\\n",
       "count  1204.000000  1204.000000  1204.000000  1204.000000  1204.000000   \n",
       "mean      2.032392     1.643688  1144.402824  -122.423732    37.770007   \n",
       "std       1.070164     0.777992   761.550186     0.029419     0.022224   \n",
       "min       0.000000     0.000000     0.000000  -122.510000    37.708900   \n",
       "25%       1.000000     1.000000   729.500000  -122.440000    37.756175   \n",
       "50%       2.000000     2.000000  1100.000000  -122.420000    37.775900   \n",
       "75%       3.000000     2.000000  1500.000000  -122.397000    37.787100   \n",
       "max       8.000000     9.000000  6645.000000  -122.370000    37.806300   \n",
       "\n",
       "         elevation         age      garage        level           price  \\\n",
       "count  1204.000000  443.000000  526.000000  1204.000000     1204.000000   \n",
       "mean     46.561140   54.404063    0.125475     3.470930    10663.893688   \n",
       "std      47.924815   39.260779    0.331572     6.713467   124357.240061   \n",
       "min       0.000000    1.000000    0.000000     1.000000        0.000000   \n",
       "25%       8.107577   15.000000    0.000000     1.000000     3700.000000   \n",
       "50%      31.017000   54.000000    0.000000     1.000000     4500.000000   \n",
       "75%      69.020950   90.000000    0.000000     3.000000     5991.250000   \n",
       "max     247.736000  167.000000    1.000000    55.000000  3850000.000000   \n",
       "\n",
       "       days_on_market          nid  \n",
       "count      500.000000  1204.000000  \n",
       "mean         8.642000    50.439369  \n",
       "std        149.231733    25.861556  \n",
       "min      -1072.000000     1.000000  \n",
       "25%          8.000000    27.000000  \n",
       "50%         16.000000    56.000000  \n",
       "75%         33.250000    74.000000  \n",
       "max        738.000000    93.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe() #identify filtering tresholds to clean up bad data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries before filter: 1204\n",
      "Entries after filter: 806\n"
     ]
    }
   ],
   "source": [
    "# filter out any outliers, defined as rent >$10k or >2,500 sq ft, or not in SF\n",
    "\n",
    "print \"Entries before filter: \" + `len(data)`\n",
    "data = data[  (data.sqft <= 10000) \n",
    "            & (data.price <= 10000) \n",
    "#             & (data.price > 500)\n",
    "#            & (data.neighborhood == 'South Scottsdale')\n",
    "#             & (data.home_type == 'sfh')\n",
    "#             & (data.transaction_status == 'closed')\n",
    "            & (data.bedrooms <= 6) \n",
    "            & (data.bathrooms <= 6) \n",
    "#             & (data.sqft != 0)\n",
    "            & (data.year > pd.Period('2000', freq='A-DEC'))]\n",
    "\n",
    "print \"Entries after filter: \" + `len(data)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.hist(column=['has_pool','bathrooms','bedrooms','price','garage','level','age','sqft','elevation','luxurious','dist_to_park', 'dist_to_golf_course','near_golf_course'],figsize=(12,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# adjust variables so that for most houses they result in zero (or close to zero)\n",
    "data.elevation = data.elevation - 295\n",
    "data.level = data.level - 1\n",
    "data.bathrooms = data.bathrooms - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ListTable(list):\n",
    "    \"\"\" Overridden list class which takes a 2-dimensional list of \n",
    "        the form [[1,2,3],[4,5,6]], and renders an HTML Table in \n",
    "        IPython Notebook. \"\"\"\n",
    "    \n",
    "    def _repr_html_(self):\n",
    "        html = [\"<table>\"]\n",
    "        for row in self:\n",
    "            html.append(\"<tr>\")\n",
    "            \n",
    "            for col in row:\n",
    "                html.append(\"<td>{0}</td>\".format(col))\n",
    "            \n",
    "            html.append(\"</tr>\")\n",
    "        html.append(\"</table>\")\n",
    "        return ''.join(html)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Artnet white paper index converted to our dataset\n",
    "\n",
    "# create year dummy variables (because date isn't very intuitive variable)\n",
    "z = 'Q'\n",
    "data[\"period\"] = pd.DatetimeIndex(data[\"date\"]).to_period(z)\n",
    "data['period_literal'] = pd.DatetimeIndex(data[\"date\"]).to_period(z).format()\n",
    "\n",
    "paired = data[['address','date','price','period','period_literal','neighborhood','zipcode']]\n",
    "\n",
    "# identify the earliest date, number of periods, and number of pairs\n",
    "base_period = paired.period.min()\n",
    "num_periods = paired.period.max() - paired.period.min()\n",
    "print \"base period: \" + `base_period` + \" end period: \" + `paired.period.max()` + \" and number of periods: \" + `num_periods`\n",
    "\n",
    "# group data into Sets and calc Y_ist of each item\n",
    "paired = paired.groupby(\"address\").filter(lambda x: len(x) >1)\n",
    "paired.sort_values(['address','period'],inplace=True)\n",
    "paired_grp = paired.groupby('address')\n",
    "print 'number of paired transactions in the data: ' + `paired.shape[0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def demean(group):\n",
    "    return pd.DataFrame({'address': group.address, 'original' : group.price, 'demeaned' : group.price - group.price.mean()})\n",
    "\n",
    "# filter out properties with multiple listings in the same quarter\n",
    "paired = paired.groupby(['address','period_literal']).filter(lambda x: len(x) == 1)\n",
    "paired_grp = paired.groupby('address')\n",
    "n = paired.groupby(['address']).apply(demean)\n",
    "n = n[((n.demeaned / n.original).abs() > 0.10)]\n",
    "\n",
    "paired = paired[~paired.address.isin(n.address)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boundary = 'neighborhood' # 'zipcode' or 'neighborhood'\n",
    "\n",
    "table = ListTable()\n",
    "table.append([boundary,'Period','Growth Rate','P Value','n'])\n",
    "\n",
    "sorted_zips = []\n",
    "\n",
    "# index used to calculate adjusted prices. \n",
    "iterables = [data[boundary].unique(), data.period.unique()]\n",
    "mi = pd.MultiIndex.from_product(iterables, names=[boundary, 'period'])\n",
    "price_adjustment_index = pd.Series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "res = sm.ols(formula=\"np.log(price) ~ period + address\", data=paired).fit()\n",
    "\n",
    "#calculate index\n",
    "linked = res.params[res.params.index.str.contains('Period')]\n",
    "linked.name = \"Index\"\n",
    "linked[0] = 100\n",
    "num = pd.Series(linked, copy=True)\n",
    "num[0] = 0\n",
    "num.name = \"n\"\n",
    "growth = pd.Series(linked, copy=True)\n",
    "growth.name = \"Growth Rate\"\n",
    "growth[0] = 0\n",
    "for i in range(1,len(linked)):\n",
    "    linked[i] = (np.exp(res.params[i]))*100\n",
    "    growth[i] = linked[i]/linked[i-1] - 1\n",
    "    num[i] = len(paired[paired.period_literal == filter(str.isdigit, linked.index[i])])\n",
    "\n",
    "# add P values of each prediction\n",
    "p = res.pvalues[res.params.index.str.contains('Period')] * 100\n",
    "p.name = \"P value\"\n",
    "index = pd.concat([linked, growth, p, num], axis=1)\n",
    "index.index = pd.to_datetime(index.index.str.split(\"'\").str.get(1)).to_period(z)\n",
    "\n",
    "print index\n",
    "price_adjustment_index['Phoenix'] = index['Index']  \n",
    "\n",
    "\n",
    "\n",
    "index[['Index']].plot()\n",
    "# index[['Growth Rate']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "price_adjustment_index['Phoenix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for hood in paired[boundary].unique():\n",
    "    sorted_zips.append([hood, len(paired[paired[boundary] == hood])])\n",
    "    \n",
    "for hood, n in sorted(sorted_zips, key =lambda x: x[1], reverse=True):\n",
    "    d = paired[paired[boundary] == hood]\n",
    "    if len(d) < 100:\n",
    "        print 'only ' + `len(d)` + 'transactions in ' + hood\n",
    "        continue\n",
    "\n",
    "    res = sm.ols(formula=\"np.log(price) ~ period + address\", data=d).fit()\n",
    "\n",
    "    #calculate index\n",
    "    linked = res.params[res.params.index.str.contains('Period')]\n",
    "    linked.name = \"Index\"\n",
    "    linked[0] = 100\n",
    "    \n",
    "    growth = pd.Series(linked, copy=True)\n",
    "    growth.name = \"Growth Rate\"\n",
    "    growth[0] = 0\n",
    "    for i in range(1,len(linked)):\n",
    "        linked[i] = (np.exp(res.params[i]))*100\n",
    "        growth[i] = linked[i]/linked[i-1] - 1\n",
    "\n",
    "    \n",
    "    \n",
    "    # add P values of each prediction\n",
    "    p = res.pvalues[res.params.index.str.contains('Period')] * 100\n",
    "    p.name = \"P value\"\n",
    "    index = pd.concat([linked, growth, p], axis=1)\n",
    "    index.index = pd.to_datetime(index.index.str.split(\"'\").str.get(1)).to_period(z)\n",
    "    \n",
    "    # update the price adjustment index to be used for later regressions\n",
    "    price_adjustment_index[hood] = index['Index']  \n",
    "    \n",
    "    last = index.tail(1)\n",
    "    table.append([hood\n",
    "                  ,last.index[0]\n",
    "                  ,round(last.iloc[0]['Growth Rate'] * 100,2)\n",
    "                  ,round(last.iloc[0]['P value'], 2)\n",
    "                  ,n])\n",
    "\n",
    "    index[['Index','P value']].plot(title=hood)\n",
    "    index[['Growth Rate']].plot()\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def g(listing): \n",
    "#     print 'price: ' + `listing.price`\n",
    "#     print 'year: ' + `listing.year`\n",
    "#     print 'hood: ' + listing[boundary]\n",
    "    try:\n",
    "        index_value = price_adjustment_index[listing[boundary]][listing.year] / price_adjustment_index[listing[boundary]][2016]\n",
    "    except KeyError:\n",
    "        try:\n",
    "            index_value = price_adjustment_index['Phoenix'][listing.year] / price_adjustment_index['Phoenix'][2016]\n",
    "        except KeyError:\n",
    "            index_value = 1\n",
    "#     print index_value\n",
    "    indexed_price = listing.price * index_value\n",
    "#     print 'adj price: ' + `indexed_price`\n",
    "    \n",
    "    return indexed_price\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indexed_price = data.apply(g, axis=1)\n",
    "indexed_price.name = \"indexed_price\"\n",
    "data = pd.concat([data,indexed_price],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[['indexed_price','price','year']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(data.date.values[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "out_of_sample_data = data[data.date > datetime.strptime('2016-07-31','%Y-%m-%d').date()]\n",
    "# out_of_sample_data.reset_index(inplace=True)\n",
    "print \"number of transactions in data: \" + `len(data)` + \"\\texcluding latest \" + `len(out_of_sample_data)` + \" transactions\"\n",
    "in_sample_data = data[~data.date.isin(out_of_sample_data.date)]\n",
    "print \"number of transactions in data after exclusion: \" + `len(in_sample_data)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for z in set(out_of_sample_data.zipcode.unique()).difference(in_sample_data.zipcode.unique()):\n",
    "    print(\"shoving missing zipcode into in_sample_data : ?\", z)\n",
    "    in_sample_data = in_sample_data.append(out_of_sample_data[out_of_sample_data.zipcode == z].head(1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dist_to_park unit is 1 degree of latitude or 69 miles north south or 54 miles east west\n",
    "\n",
    "result = sm.ols(formula=\"indexed_price ~ bedrooms + bathrooms + elevation + level + age + dist_to_park + near_golf_course + has_pool + garage + C(school_district_id) + home_type:zipcode:sqft\", data=in_sample_data).fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print list(set(in_sample_data.zipcode.unique()).difference(out_of_sample_data.zipcode.unique()))\n",
    "\n",
    "print list(set(out_of_sample_data.zipcode.unique()).difference(in_sample_data.zipcode.unique()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for z in set(in_sample_data.zipcode.unique()).difference(out_of_sample_data.zipcode.unique()):\n",
    "    print(\"shoving missing zipcode into out_of_sample_data : ?\", z)\n",
    "    out_of_sample_data = out_of_sample_data.append(in_sample_data[in_sample_data.zipcode == z].head(1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(out_of_sample_data.zipcode.unique())\n",
    "print len(in_sample_data.zipcode.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import patsy\n",
    "x = patsy.dmatrix(\"bedrooms + bathrooms + elevation + level + age + dist_to_park + near_golf_course + has_pool + garage + home_type:zipcode:sqft\", data=out_of_sample_data) \n",
    "p = result.predict(x, transform=False)\n",
    "print 'length of prediction from .predict ' + `len(p)`\n",
    "pprice_out = pd.Series(p)\n",
    "pprice_out.name = \"prediction\"\n",
    "print pprice_out.head()\n",
    "print 'length of prediction price ' + `len(pprice_out)`\n",
    "print 'length of out of sample ' + `len(out_of_sample_data)`\n",
    "errors_out = out_of_sample_data.price.values - pprice_out\n",
    "errors_out.name = 'error'\n",
    "print errors_out.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'length of OOS data: ' + `len(out_of_sample_data)`\n",
    "print 'length of prediction: ' + `len(pprice_out)`\n",
    "out_of_sample_data.reset_index(drop=True, inplace=True)\n",
    "out_of_sample_result = pd.concat([out_of_sample_data,pprice_out,errors_out],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'length of out of sample data ' + `len(out_of_sample_result)`\n",
    "print 'length of predicted price of OOS data ' + `len(pprice_out)`\n",
    "print 'length of error of OOS data ' + `len(errors_out)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_of_sample_result[['address','price','prediction','error','zipcode']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "percent_errors_out = (1.0 * out_of_sample_result.error.abs() / out_of_sample_result.price)\n",
    "percent_errors_out.name = 'error'\n",
    "\n",
    "print percent_errors_out.median()\n",
    "\n",
    "hooderrors_out = out_of_sample_result[['zipcode']]\n",
    "hooderrors_out = pd.concat([hooderrors_out,errors_out.abs()],axis=1)\n",
    "hood_group_out = hooderrors_out.groupby('zipcode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error_avg_out = hood_group_out.agg([np.median,len])\n",
    "print error_avg_out.head()\n",
    "error_avg_out.sort_values(by=('error','len'),ascending=False,inplace=True)\n",
    "error_avg_out.plot(kind='bar',figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_of_sample_result[out_of_sample_result.zipcode == '85251'][['property_id','address','date','price','prediction','sqft']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output = [['zipcode','sfh','multifamily']]\n",
    "table = ListTable()\n",
    "table.append(output[0])\n",
    "\n",
    "for row in data.zipcode.unique():\n",
    "    output_row = [row, '99', '99']\n",
    "    for i in result.params.index:\n",
    "        if 'zipcode' not in i: continue\n",
    "\n",
    "        if 'zipcode[' + row + ']' in i:\n",
    "            if 'home_type[mfh]' in i:\n",
    "                output_row[2] = `result.params[i]`\n",
    "                output.append(output_row)\n",
    "                table.append(output_row)\n",
    "\n",
    "            if 'home_type[sfh]' in i:\n",
    "                output_row[1] = `result.params[i]`\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = 'rentalnerd_importer/lib/tasks/model_files/'\n",
    "\n",
    "with open(path + 'model_zipcode_ph.csv', 'wb') as csvfile:\n",
    "    hoodwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    \n",
    "    for i in output:\n",
    "        hoodwriter.writerow(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtype = [('Effect', 'S100'), ('Coefficient', float)]\n",
    "\n",
    "with open(path + 'model_features_ph.csv', 'wb') as csvfile:\n",
    "    modelwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "    header = ['Effect','Coefficient']\n",
    "    table.append(header)\n",
    "    modelwriter.writerow(header)\n",
    "    modelwriter.writerow(['base_rent', result.params.Intercept])  # hardcode 0 as base rent\n",
    "    modelwriter.writerow(['bedrooms', result.params.bedrooms])\n",
    "    modelwriter.writerow(['bathrooms', result.params.bathrooms])\n",
    "    modelwriter.writerow(['dist_to_park', result.params.dist_to_park])\n",
    "    modelwriter.writerow(['elevation', result.params.elevation])\n",
    "    modelwriter.writerow(['near_golf_course', result.params['near_golf_course[T.True]']])\n",
    "    modelwriter.writerow(['level', result.params.level])\n",
    "    modelwriter.writerow(['age', result.params.age])\n",
    "    modelwriter.writerow(['garage', result.params.garage])\n",
    "    modelwriter.writerow(['has_pool', result.params['has_pool[T.True]']])\n",
    "    modelwriter.writerow(['mean square error of residuals', result.mse_resid])\n",
    "\n",
    "result.cov_params().to_csv(path + 'model_covs_ph.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = [['district_id','coefficient']]\n",
    "table = ListTable()\n",
    "table.append(output[0])\n",
    "\n",
    "for row in sorted(data.school_district_id.unique()):\n",
    "    output_row = [row, '99']\n",
    "    for i in result.params.index:\n",
    "        if 'school_district_id' not in i: continue\n",
    "\n",
    "        if 'school_district_id)[T.' + `row` + ']' in i:\n",
    "            output_row[1] = `result.params[i]`\n",
    "            output.append(output_row)\n",
    "            table.append(output_row)\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(path + 'model_schools_ph.csv', 'wb') as csvfile:\n",
    "    schoolswriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    \n",
    "    for i in output:\n",
    "        schoolswriter.writerow(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "errors = result.resid\n",
    "errors.name = 'error'\n",
    "pprice = data.indexed_price - errors\n",
    "pprice.name = \"prediction\"\n",
    "data = pd.concat([data, errors], axis=1)\n",
    "data = pd.concat([data, pprice], axis=1)\n",
    "\n",
    "# visualize the relationship between the features and the response using scatterplots\n",
    "errors.sort_values(inplace=True)\n",
    "errors.plot(kind='bar').get_xaxis().set_ticks([])\n",
    "\n",
    "# show errors by neighborhood to see if there are any neighborhoods with funky differences\n",
    "\n",
    "hooderrors = data[['zipcode']]\n",
    "hooderrors = pd.concat([hooderrors,errors.abs()],axis=1)\n",
    "hood_group = hooderrors.groupby('zipcode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "error_avg = hood_group.agg([np.median,len])\n",
    "error_avg.sort_values(by=('error','len'),ascending=False,inplace=True)\n",
    "error_avg.plot(kind='bar',figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show errors by year to see if there are any years with funky differences\n",
    "yearerrors = data[['year']]\n",
    "percent_errors = (1.0 * errors.abs() / data.price)\n",
    "percent_errors.name = 'error'\n",
    "yearerrors = pd.concat([yearerrors,percent_errors],axis=1)\n",
    "\n",
    "year_group = yearerrors.groupby('year')\n",
    "error_avg = year_group.median()\n",
    "error_avg.plot(kind='bar')\n",
    "print error_avg\n",
    "\n",
    "# show errors by source to see if there are any sources have noisy data\n",
    "\n",
    "srcerrors = data[['source']]\n",
    "\n",
    "srcerrors = pd.concat([srcerrors,percent_errors],axis=1)\n",
    "\n",
    "src_group = srcerrors.groupby('source')\n",
    "error_avg = src_group.median()\n",
    "error_avg.sort_values(by='error',ascending=False).plot(kind='bar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a table of all properties with outsized errors and listed in recent past - for future plotting\n",
    "plot_data = data[(data.error / data.price < -0.2) & (data.year > pd.Period('2015', freq='A-DEC'))]\n",
    "len(plot_data)\n",
    "plot_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(24,24))\n",
    "ax = fig.add_subplot(111)\n",
    "# Create the Basemap\n",
    "event_map = Basemap(projection='merc', resolution='h', epsg=2227\n",
    "                    , llcrnrlon=-112.4, llcrnrlat=33.25, urcrnrlon=-111.7, urcrnrlat=33.79)\n",
    "\n",
    "# Draw important features\n",
    "event_map.arcgisimage(service='World_Shaded_Relief', xpixels = 1000, verbose= True)\n",
    "# add neighborhoods\n",
    "event_map.readshapefile('data/ZillowNeighborhoods-AZ/ZillowNeighborhoods-AZ', 'PHX', color='black', zorder=2)\n",
    "event_map.readshapefile('data/gold_phx/gold_phx', 'PHX', color='green', zorder=3)\n",
    "event_map.readshapefile('data/parks_phx/OGRGeoJSON', 'PHX', color='brown', zorder=3)\n",
    "# create array storing lats and longs\n",
    "listing_coords = zip(plot_data.latitude,plot_data.longitude, plot_data.sqft, plot_data.price, plot_data.error)\n",
    "# Draw the points on the map:\n",
    "for longitude, latitude, sqft, price, error in listing_coords:\n",
    "    x, y = event_map(latitude, longitude) # Convert lat, long to y,x\n",
    "    if((1.0 * error / price) > 0.3): \n",
    "        color = 'ro'\n",
    "    elif ((1.0 * error / price) < -0.3): \n",
    "        color = 'bo'\n",
    "    elif ((1.0 * error / price) > 0.1): \n",
    "        color = 'co'\n",
    "    else:\n",
    "        color = 'go'\n",
    "\n",
    "    event_map.plot(x,y, color, alpha=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_data[(plot_data.zipcode == '85251')][['property_id','address','home_type','error','price','prediction','sqft','year','dist_to_park','near_golf_course']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(data[((data.zipcode == '85251') & (data.year == pd.Period('2016', freq='A-DEC')))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print result.resid[1]\n",
    "# print result.fittedvalues[1]\n",
    "# print data.price[1]\n",
    "# print data.price[1] - result.fittedvalues[1]\n",
    "\n",
    "# house = data.iloc[1]\n",
    "house = data[data.address == '8347 W Vernon Ave, Phoenix, AZ 85037']\n",
    "print house\n",
    "\n",
    "beds = result.params.bedrooms * house.bedrooms\n",
    "baths = result.params.bathrooms * house.bathrooms\n",
    "footage = house.sqft *result.params['home_type[sfh]:zipcode[85037]:sqft'] * house.sqft\n",
    "age = result.params.age * house.age\n",
    "park = result.params.dist_to_park * house.dist_to_park\n",
    "gc = result.params['near_golf_course[T.True]'] * house.near_golf_course\n",
    "view = result.params.elevation * house.elevation\n",
    "pool = result.params['has_pool[T.True]'] * house.has_pool\n",
    "\n",
    "print 'intercept: ' + `result.params.Intercept`\n",
    "print '3 bedrooms: ' + `beds`\n",
    "print '2 bathrooms: ' + `baths`\n",
    "print 'px for square feet: ' + `footage`\n",
    "print '20 years old: ' + `age`\n",
    "print 'dist to park: ' + `park`\n",
    "print 'near golf course: ' + `gc`\n",
    "print 'elevation: ' + `view`\n",
    "print 'pool: ' + `pool`\n",
    "print 'SHOULD be predicted rent: ' + `result.params.Intercept + beds + baths + footage + age + park + gc + view + pool`\n",
    "print 'predicted rent: ' + `house.prediction`\n",
    "print 'actual rent: ' + `house.price`\n",
    "print 'error: ' + `house.error`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
