{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/IPython/config.py:13: ShimWarning: The `IPython.config` package has been deprecated. You should import from traitlets.config instead.\n",
      "  \"You should import from traitlets.config instead.\", ShimWarning)\n",
      "/usr/local/lib/python2.7/site-packages/IPython/utils/traitlets.py:5: UserWarning: IPython.utils.traitlets has moved to a top-level traitlets package.\n",
      "  warn(\"IPython.utils.traitlets has moved to a top-level traitlets package.\")\n"
     ]
    }
   ],
   "source": [
    "%load_ext sql\n",
    "import statsmodels.api as sma\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "import datetime\n",
    "from scipy import stats\n",
    "import math\n",
    "\n",
    "import fiona\n",
    "import shapely as shapely\n",
    "from geopandas import GeoSeries, GeoDataFrame\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry import asShape\n",
    "from time import gmtime, strftime\n",
    "from array import array\n",
    "\n",
    "\n",
    "# imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "# follow the usual sklearn pattern: import, instantiate, fit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.collections import PatchCollection\n",
    "\n",
    "import statsmodels.formula.api as sm\n",
    "\n",
    "# this allows plots to appear directly in the notebook\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Connected: prod@rental_nerd'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql mysql://prod:nerd@52.2.153.189/rental_nerd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = %sql (\\\n",
    "SELECT  \\\n",
    "properties.id as 'property_id', \\\n",
    "properties.address,  \\\n",
    "properties.bedrooms,  \\\n",
    "properties.bathrooms,  \\\n",
    "properties.sqft,  \\\n",
    "properties.source,  \\\n",
    "properties.origin_url,  \\\n",
    "properties.longitude,  \\\n",
    "properties.latitude,  \\\n",
    "properties.elevation,  \\\n",
    "properties.year_built,  \\\n",
    "properties.garage,  \\\n",
    "properties.level,  \\\n",
    "properties.luxurious,  \\\n",
    "properties.dist_to_park,  \\\n",
    "property_transaction_logs.id 'ptl_id',  \\\n",
    "property_transaction_logs.transaction_type,  \\\n",
    "property_transaction_logs.price,  \\\n",
    "property_transaction_logs.transaction_status,  \\\n",
    "property_transaction_logs.days_on_market,  \\\n",
    "property_transaction_logs.date_closed,  \\\n",
    "property_transaction_logs.date_listed,  \\\n",
    "neighborhoods.name as 'neighborhood',  \\\n",
    "neighborhoods.id as 'nid',  \\\n",
    "neighborhoods.shapefile_source,  \\\n",
    "prediction_results.pred_std as 'pred_std' \\\n",
    "FROM  \\\n",
    "properties,  \\\n",
    "property_transaction_logs,  \\\n",
    "property_neighborhoods,  \\\n",
    "neighborhoods,  \\\n",
    "prediction_results \\\n",
    "WHERE  \\\n",
    "property_transaction_logs.property_id = properties.id AND  \\\n",
    "property_transaction_logs.transaction_type = \"rental\" AND  \\\n",
    "neighborhoods.shapefile_source = \"PH\" AND  \\\n",
    "properties.id = property_neighborhoods.property_id AND  \\\n",
    "property_neighborhoods.neighborhood_id = neighborhoods.id AND \\\n",
    "property_transaction_logs.date_closed is not null AND \\\n",
    "prediction_results.property_transaction_log_id = property_transaction_logs.id AND \\\n",
    "properties.sqft > 0 AND \\\n",
    "prediction_results.pred_std > 0 AND \\\n",
    "property_transaction_logs.price > 0 )\n",
    "               \n",
    "data = result.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fill NaN values with some reasonable defaults\n",
    "data.year_built = data.year_built.fillna(1970)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Date_final = [0.1] * len(data)\n",
    "\n",
    "for x in range(0,len(data)):\n",
    "    data\n",
    "    if data[\"date_closed\"][x] is not None :\n",
    "        # print \" row: \"+ `x` + \": using date_rented\"\n",
    "        # data.ix['Date_final',x]\n",
    "        Date_final[x] = data[\"date_closed\"][x]\n",
    "        \n",
    "    elif data[\"date_listed\"][x] is not None :\n",
    "        # print \" row: \"+ `x` + \": using date_listed\"\n",
    "        Date_final[x] = data[\"date_listed\"][x]\n",
    "    else:\n",
    "        Date_final[x] = data[\"date_closed\"][2]\n",
    "        print \" row: \"+ `x` + \": we are screwed\"\n",
    "\n",
    "data['date'] = pd.to_datetime(Date_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create zip code feature\n",
    "\n",
    "zipcode = data['address'].str[-5:]\n",
    "zipcode.name = 'zipcode'\n",
    "data = pd.concat([data,zipcode],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a column of GeoSeries - each house should be represented by a point\n",
    "pts = GeoSeries([Point(x, y) for x, y in zip(data['longitude'], data['latitude'])])\n",
    "data['latlong'] = pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create year dummy variables (because date isn't very intuitive variable)\n",
    "data[\"year\"] = pd.DatetimeIndex(data[\"date\"]).to_period('A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fiona\n",
    "import shapely as shapely\n",
    "from shapely.geometry import asShape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[data.property_id == 22099][['address','price','date','date_closed','date_listed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.describe() #identify filtering tresholds to clean up bad data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# filter out any outliers, defined as rent >$10k or >2,500 sq ft, or not in SF\n",
    "\n",
    "print \"Entries before filter: \" + `len(data)`\n",
    "data = data[  (data.sqft <= 10000) \n",
    "            & (data.price <= 4000) \n",
    "            & (data.price != 0) \n",
    "#            & (data.neighborhood == 'South Scottsdale')\n",
    "            & (data.transaction_status == 'closed')\n",
    "            & (data.bedrooms <= 6) \n",
    "            & (data.bathrooms <= 6) \n",
    "            & (data.sqft != 0)\n",
    "            & (data.year > pd.Period('2000', freq='A-DEC'))]\n",
    "\n",
    "print \"Entries after filter: \" + `len(data)`\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.hist(column=['bathrooms','bedrooms','price','garage','level','year_built','sqft','elevation','luxurious','dist_to_park'],figsize=(12,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ListTable(list):\n",
    "    \"\"\" Overridden list class which takes a 2-dimensional list of \n",
    "        the form [[1,2,3],[4,5,6]], and renders an HTML Table in \n",
    "        IPython Notebook. \"\"\"\n",
    "    \n",
    "    def _repr_html_(self):\n",
    "        html = [\"<table>\"]\n",
    "        for row in self:\n",
    "            html.append(\"<tr>\")\n",
    "            \n",
    "            for col in row:\n",
    "                html.append(\"<td>{0}</td>\".format(col))\n",
    "            \n",
    "            html.append(\"</tr>\")\n",
    "        html.append(\"</table>\")\n",
    "        return ''.join(html)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "age = 2016 - data.year_built \n",
    "age.name = 'age'\n",
    "data = pd.concat([data,age],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result = sm.ols(formula=\"price ~ bedrooms + bathrooms + age + elevation +\\\n",
    "zipcode:sqft:year-1\", data=data).fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output = [['neighborhood','rent per foot']]\n",
    "table = ListTable()\n",
    "table.append(output[0])\n",
    "\n",
    "for row in data.neighborhood.unique():\n",
    "    output_row = [row, '99']\n",
    "    for i in result.params.index:\n",
    "        if 'neighborhood' not in i: continue\n",
    "\n",
    "        if '2015' in i:\n",
    "            if 'neighborhood[' + row + ']' in i:\n",
    "                output_row[1] = `result.params[i]`\n",
    "                output.append(output_row)\n",
    "                table.append(output_row)\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = 'rentalnerd_importer/lib/tasks/model_files/'\n",
    "\n",
    "dtype = [('Effect', 'S100'), ('Coefficient', float)]\n",
    "\n",
    "with open(path + 'model_features_ph.csv', 'wb') as csvfile:\n",
    "    modelwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "    header = ['Effect','Coefficient']\n",
    "    table.append(header)\n",
    "    modelwriter.writerow(header)\n",
    "    modelwriter.writerow(['base_rent', 0]) # result.params.Intercept])  hardcode 0 as base rent\n",
    "    modelwriter.writerow(['bedrooms', result.params.bedrooms])\n",
    "    modelwriter.writerow(['bathrooms', result.params.bathrooms])\n",
    "    modelwriter.writerow(['dist_to_park', 0])\n",
    "    modelwriter.writerow(['elevation', result.params.elevation])\n",
    "    modelwriter.writerow(['level', 0])\n",
    "    modelwriter.writerow(['age', result.params.age])\n",
    "    modelwriter.writerow(['garage', 0])\n",
    "    modelwriter.writerow(['mean square error of residuals', result.mse_resid])\n",
    "\n",
    "result.cov_params().to_csv(path + 'model_covs_ph.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(path + 'model_hoods_ph.csv', 'wb') as csvfile:\n",
    "    hoodwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    \n",
    "    for i in output:\n",
    "        hoodwriter.writerow(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "errors = result.resid\n",
    "errors.name = 'error'\n",
    "pprice = errors + data.price\n",
    "pprice.name = \"prediction\"\n",
    "data = pd.concat([data, errors], axis=1)\n",
    "data = pd.concat([data, pprice], axis=1)\n",
    "\n",
    "# visualize the relationship between the features and the response using scatterplots\n",
    "errors.sort_values(inplace=True)\n",
    "errors.plot(kind='bar').get_xaxis().set_ticks([])\n",
    "\n",
    "# show errors by neighborhood to see if there are any neighborhoods with funky differences\n",
    "\n",
    "hooderrors = data[['zipcode']]\n",
    "\n",
    "hooderrors = pd.concat([hooderrors,errors.abs()],axis=1)\n",
    "\n",
    "hood_group = hooderrors.groupby('zipcode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "error_avg = hood_group.agg([np.median,len])\n",
    "error_avg.sort_values(by=('error','len'),ascending=False,inplace=True)\n",
    "error_avg.plot(kind='bar',figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show errors by year to see if there are any years with funky differences\n",
    "yearerrors = data[['year']]\n",
    "yearerrors = pd.concat([yearerrors,errors.abs()],axis=1)\n",
    "\n",
    "year_group = yearerrors.groupby('year')\n",
    "error_avg = year_group.median()\n",
    "error_avg.sort_values(by='error',ascending=False).plot(kind='bar')\n",
    "\n",
    "# show errors by source to see if there are any sources have noisy data\n",
    "\n",
    "srcerrors = data[['source']]\n",
    "\n",
    "srcerrors = pd.concat([srcerrors,errors.abs()],axis=1)\n",
    "\n",
    "src_group = srcerrors.groupby('source')\n",
    "error_avg = src_group.median()\n",
    "error_avg.sort_values(by='error',ascending=False).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import Basemap\n",
    "import fiona\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.collections import PatchCollection\n",
    "\n",
    "\n",
    "plot_data = data[(data.zipcode == '85021')] \n",
    "len(plot_data)\n",
    "plot_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,12))\n",
    "ax = fig.add_subplot(111)\n",
    "# Create the Basemap\n",
    "event_map = Basemap(projection='merc', resolution='h', epsg=2227\n",
    "                    , llcrnrlon=-111.97, llcrnrlat=33.45, urcrnrlon=-111.87, urcrnrlat=33.57)\n",
    "# Draw important features\n",
    "event_map.arcgisimage(service='World_Shaded_Relief', xpixels = 1500, verbose= True)\n",
    "# add neighborhoods\n",
    "event_map.readshapefile('data/ZillowNeighborhoods-AZ/ZillowNeighborhoods-AZ', 'PHX', color='black', zorder=2)\n",
    "event_map.readshapefile('data/gold_phx/gold_phx', 'PHX', fill_color='green', zorder=3)\n",
    "event_map.readshapefile('data/parks_phx/gold_phx', 'PHX', fill_color='brown', zorder=3)\n",
    "# create array storing lats and longs\n",
    "listing_coords = zip(plot_data.latitude,plot_data.longitude, plot_data.sqft, plot_data.price, plot_data.pred_std)\n",
    "# Draw the points on the map:\n",
    "for longitude, latitude, sqft, price, pred_std in listing_coords:\n",
    "    x, y = event_map(latitude, longitude) # Convert lat, long to y,x\n",
    "    if((1.0 * price/sqft) < 0.5): \n",
    "        color = 'ro'\n",
    "    elif ((1.0 * price/sqft) < 0.8): \n",
    "        color = 'bo'\n",
    "    elif ((1.0 * price/sqft) <1.1): \n",
    "        color = 'co'\n",
    "    else:\n",
    "        color = 'go'\n",
    "\n",
    "    event_map.plot(x,y, color, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from decimal import *\n",
    "\n",
    "# fig = plt.figure(figsize=(12,12))\n",
    "# ax = fig.add_subplot(111)\n",
    "# # Create the Basemap\n",
    "# event_map = Basemap(projection='merc', resolution='h', epsg=2227\n",
    "#                     , llcrnrlon=-111.97, llcrnrlat=33.45, urcrnrlon=-111.87, urcrnrlat=33.57)\n",
    "# # Draw important features\n",
    "# event_map.arcgisimage(service='World_Shaded_Relief', xpixels = 1500, verbose= True)\n",
    "# # add neighborhoods\n",
    "# event_map.readshapefile('data/ZillowNeighborhoods-AZ/ZillowNeighborhoods-AZ', 'PHX', color='black', zorder=2)\n",
    "# event_map.readshapefile('data/gold_phx/gold_phx', 'PHX_golf_courses', zorder=3)\n",
    "# event_map.readshapefile('data/parks_phx/OGRGeoJSON', 'PHX_parks', zorder=3)\n",
    "\n",
    "# patches = []\n",
    "# patches.append( Polygon(event_map.PHX_golf_courses, True) )\n",
    "# patches.append( Polygon(event_map.PHX_parks, True) )\n",
    "\n",
    "\n",
    "\n",
    "# # fill in color\n",
    "# ax.add_collection(PatchCollection(patches, facecolor= 'green', edgecolor='k', linewidths=1., zorder=2))\n",
    "\n",
    "\n",
    "\n",
    "# # Draw the points on the map:\n",
    "# for longitude, latitude, sqft, price, pred_std in listing_coords:\n",
    "#     x, y = event_map(latitude, longitude) # Convert lat, long to y,x\n",
    "#     price_d = Decimal(price)\n",
    "#     pred_d = Decimal(pred_std) \n",
    "#     if((pred_d/price_d) < Decimal(0.1)):\n",
    "#         color = 'ro'\n",
    "#     elif ((pred_d/price_d) < Decimal(0.2)):\n",
    "#         color = 'bo'\n",
    "#     elif ((pred_d/price_d) < Decimal(0.3)):\n",
    "#         color = 'co' \n",
    "#     else:\n",
    "#         color = 'go'\n",
    "    \n",
    "#     event_map.plot(x,y, color, alpha=0.3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# prstd, iv_l, iv_u = wls_prediction_std(result)\n",
    "\n",
    "# zip(data.address, data.price, data.prediction, prstd, iv_l, iv_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Artnet white paper index converted to our dataset\n",
    "\n",
    "# create year dummy variables (because date isn't very intuitive variable)\n",
    "f = 'Q'\n",
    "data[\"period\"] = pd.DatetimeIndex(data[\"date\"]).to_period(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paired = data[['property_id','address','price','period','date','neighborhood','zipcode']]\n",
    "\n",
    "# identify the earliest date, number of periods, and number of pairs\n",
    "base_period = paired.period.min()\n",
    "num_periods = paired.period.max() - paired.period.min()\n",
    "print \"base period: \" + `base_period` + \" end period: \" + `paired.period.max()` + \" and number of periods: \" + `num_periods`\n",
    "\n",
    "paired.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(paired.groupby(\"address\").filter(lambda x: len(x['address']) >1).groupby('property_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#paired.groupby(\"address\").filter(lambda x: len(x['address']) >9)\n",
    "\n",
    "\n",
    "paired.groupby([\"address\",\"period\"]).apply(lambda g: g[g['date'] == g['date'].max()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# group data into Sets and calc Y_ist of each item\n",
    "paired = paired.drop_duplicates().groupby(\"address\").filter(lambda x: len(x) >1)\n",
    "paired.sort_values(['address','period'],inplace=True)\n",
    "paired_grp = paired.groupby('address')\n",
    "print 'number of paired transactions in the data: ' + `paired.shape[0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d = paired\n",
    "\n",
    "res = sm.ols(formula=\"np.log(price) ~ period + address\", data=d).fit()\n",
    "\n",
    "#calculate index\n",
    "linked = res.params[res.params.index.str.contains('Period')]\n",
    "linked.name = \"Index\"\n",
    "linked[0] = 100\n",
    "growth = pd.Series(linked, copy=True)\n",
    "growth.name = \"Growth Rate\"\n",
    "growth[0] = 0\n",
    "for i in range(1,len(linked)):\n",
    "    linked[i] = (np.exp(res.params[i]))*100\n",
    "    growth[i] = linked[i]/linked[i-1] - 1\n",
    "\n",
    "# add P values of each prediction\n",
    "p = res.pvalues[res.params.index.str.contains('Period')] * 100\n",
    "p.name = \"P value\"\n",
    "index = pd.concat([linked, growth, p], axis=1)\n",
    "index.index = pd.to_datetime(index.index.str.split(\"'\").str.get(1))\n",
    "\n",
    "print index\n",
    "\n",
    "index[['Index','P value']].plot()\n",
    "index[['Growth Rate']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "table = ListTable()\n",
    "table.append(['Zipcode','Period','Growth Rate','P Value','n'])\n",
    "\n",
    "sorted_zips = []\n",
    "for hood in paired.zipcode.unique():\n",
    "    sorted_zips.append([hood, len(paired[paired.zipcode == hood])])\n",
    "    \n",
    "for hood, n in sorted(sorted_zips, key =lambda x: x[1], reverse=True):\n",
    "    d = paired[paired.zipcode == hood]\n",
    "    if len(d) < 50:\n",
    "        continue\n",
    "\n",
    "    res = sm.ols(formula=\"np.log(price) ~ period + address\", data=d).fit()\n",
    "\n",
    "    #calculate index\n",
    "    linked = res.params[res.params.index.str.contains('Period')]\n",
    "    linked.name = \"Index\"\n",
    "    linked[0] = 100\n",
    "    growth = pd.Series(linked, copy=True)\n",
    "    growth.name = \"Growth Rate\"\n",
    "    growth[0] = 0\n",
    "    for i in range(1,len(linked)):\n",
    "        linked[i] = (np.exp(res.params[i]))*100\n",
    "        growth[i] = linked[i]/linked[i-1] - 1\n",
    "\n",
    "    # add P values of each prediction\n",
    "    p = res.pvalues[res.params.index.str.contains('Period')] * 100\n",
    "    p.name = \"P value\"\n",
    "    index = pd.concat([linked, growth, p], axis=1)\n",
    "    index.index = pd.to_datetime(index.index.str.split(\"'\").str.get(1))\n",
    "\n",
    "    last = index.tail(1)\n",
    "    table.append([hood\n",
    "                  ,last.index[0]\n",
    "                  ,round(last.iloc[0]['Growth Rate'] * 100,2)\n",
    "                  ,round(last.iloc[0]['P value'], 2)\n",
    "                  ,n])\n",
    "\n",
    "    index[['Index','P value']].plot(title=hood)\n",
    "    index[['Growth Rate']].plot()\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
