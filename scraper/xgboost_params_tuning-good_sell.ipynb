{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Based on: https://github.com/fmfn/BayesianOptimization/blob/master/examples/xgboost_example.py\n",
    "Computes the best parameters for XGB model optimization\n",
    "'''\n",
    "\n",
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import datetime as dt\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from slacker import Slacker\n",
    "import json\n",
    "import requests\n",
    "from cloudinary.uploader import upload\n",
    "from cloudinary.utils import cloudinary_url\n",
    "from cloudinary.api import delete_resources_by_tag, resources_by_tag\n",
    "\n",
    "import os\n",
    "# slack secrets (in your ~/.bashrc)\n",
    "webhook_url = os.environ.get('SLACK_URL')\n",
    "slacker = Slacker(os.environ.get('SLACK_TOKEN'))\n",
    "\n",
    "%load_ext sql\n",
    "# %sql mysql://root@localhost/rental_nerd\n",
    "%sql mysql://prod:nerd@52.2.153.189/rental_nerd\n",
    "limit = 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def XGBcv(max_depth, gamma, min_child_weight, max_delta_step, subsample, colsample_bytree, alpha):\n",
    "    folds = 5\n",
    "    paramt = {\n",
    "        'eta': 0.05,\n",
    "        'verbose_eval': False,\n",
    "        'silent': True,\n",
    "        'objective': 'binary:logistic',\n",
    "        'booster': 'gbtree',\n",
    "        'eval_metric': 'error',\n",
    "        'updater': 'grow_gpu',\n",
    "#         'eta': max(eta, 0),\n",
    "        'max_depth': int(max_depth),\n",
    "        'alpha': max(alpha, 0),\n",
    "        'gamma': max(gamma, 0),\n",
    "        'subsample': max(min(subsample, 1), 0),\n",
    "        'colsample_bytree': max(min(colsample_bytree, 1), 0),\n",
    "        'min_child_weight': int(min_child_weight),\n",
    "        'max_delta_step': int(max_delta_step)\n",
    "    }\n",
    "    \n",
    "    out = xgb.cv(paramt,\n",
    "           dtrain,\n",
    "           num_boost_round=3000,\n",
    "           folds=tscv.split(dtrain),\n",
    "           callbacks=[xgb.callback.early_stop(50)])\n",
    "    \n",
    "    output = -out['test-error-mean'].values[-1]\n",
    "    del out\n",
    "    gc.collect()\n",
    "    \n",
    "    return output\n",
    "\n",
    "def sanitize(data, zipcode_list = None):\n",
    "    # abort if the city has no top zipcodes\n",
    "    if data.empty:\n",
    "        return 0    \n",
    "    \n",
    "    data.drop(['abnormal', 'bookmarked', 'created_at', 'ignore', 'is_latest', 'id', 'closed_diff_id', 'listed_diff_id',\n",
    "                     'notes', 'source', 'updated_at', 'home_type', 'sfh', 'description', \n",
    "                   'event_name', 'neighborhood'], axis=1, inplace=True)\n",
    "    \n",
    "    # filters out any non-sensical values or fat finger mistakes in MLS listings\n",
    "    print(\"Entries before filter: \", len(data))\n",
    "\n",
    "    if(data.transaction_type.iloc[0] == 'sales'):\n",
    "        data = data[ data.price > 50000 ]\n",
    "    else:\n",
    "        data = data [ data.price > 500 ]\n",
    "    \n",
    "    if(zipcode_list is not None):\n",
    "        data = data[data.zipcode.isin(zipcode_list)]\n",
    "        \n",
    "#     data = data [ (data.price_closed - data.price_listed).abs() < 50000 ]\n",
    "\n",
    "    print(\"Entries after filter: %i\" % len(data))\n",
    "    \n",
    "    # fills in some sensible defaults where data is missing\n",
    "    data[\"near_golf_course\"] = data[\"near_golf_course\"].apply(lambda x: True if x == 1.0 else False)\n",
    "    data[\"has_pool\"] = data[\"has_pool\"].apply(lambda x: True if x == 1.0 else False)\n",
    "    data[\"garage\"] = data[\"garage\"].apply(lambda x: True if x == 1.0 else False)\n",
    "    data['date_closed'] = data['date_closed'].apply(lambda x: 0 if x == None else (x - dt.date(2000, 1, 1)).days)\n",
    "    data['date_closed'] = data['date_closed'].astype(int)\n",
    "    \n",
    "    # convert the area name into dummy variables\n",
    "    dm = pd.get_dummies(data[['area_name', 'zipcode']], prefix=['area_name','zipcode'])\n",
    "    data = pd.concat([data, dm], axis=1)\n",
    "    del dm\n",
    "    \n",
    "    return data\n",
    "\n",
    "def slack(text, url = None, title = None):\n",
    "    print(\"Slacking: \" + text)\n",
    "    \n",
    "    if url == None:\n",
    "        data=json.dumps({\"text\": text})\n",
    "    else:\n",
    "        data = json.dumps( { \"text\": text, \"attachments\": [ { \"fallback\": \"Model MAE\"\n",
    "                                           , \"title\": title\n",
    "                                           , \"image_url\": url } ] } )\n",
    "    \n",
    "    response = requests.post(webhook_url, data , headers={'Content-Type': 'application/json'})\n",
    "    if response.status_code != 200:\n",
    "        raise ValueError('Request to slack returned an error %s, the response is:\\n%s' % (response.status_code, response.text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000 rows affected.\n"
     ]
    }
   ],
   "source": [
    "query = %sql (\\\n",
    "    SELECT \\\n",
    "    area_name_zipcodes.area_name, \\\n",
    "    properties.*, \\\n",
    "    property_transaction_logs.id as 'transaction_id', \\\n",
    "    property_transaction_logs.* \\\n",
    "    FROM  \\\n",
    "    property_transaction_logs \\\n",
    "    LEFT JOIN \\\n",
    "    properties on properties.id = property_transaction_logs.`property_id`  \\\n",
    "    LEFT JOIN \\\n",
    "    area_name_zipcodes on properties.zipcode = area_name_zipcodes.zipcode \\\n",
    "    where \\\n",
    "    home_type = 'sfh' AND \\\n",
    "    properties.sqft between 1 and 10000 and \\\n",
    "    ( abnormal = false OR abnormal IS NULL OR abnormal = 0 ) and \\\n",
    "    property_transaction_logs.price between 500 and 400000 and \\\n",
    "    properties.bedrooms <= 6 and \\\n",
    "    properties.bathrooms <= 6 and \\\n",
    "    transaction_type = 'sales' and  \\\n",
    "    date_closed is not null and \\\n",
    "    price_closed is not null and \\\n",
    "    days_on_market is not null and \\\n",
    "    transaction_status = 'closed' \\\n",
    "    ORDER BY property_transaction_logs.date_closed DESC \\\n",
    "    LIMIT :limit )\n",
    "\n",
    "\n",
    "df = query.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.set_index('property_id', inplace=True)\n",
    "df.index.name = 'property_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init_values = {'target': [-0.05, -0.05, -0.06, -0.049, -0.051, -0.049, -0.057, -0.042, -0.041, -0.042, -0.041, -0.049, -0.042, -0.049, -0.049, -0.049, -0.0498], 'alpha': [8.97, 9.99, 14.44, 15.33, 1.84, 3.14, 8.05, 0.0, 0.0, 1.1253151004836615, 0.0, 8.3889978143639041, 20.0, 20.0, 20.0, 20.0, 20.0], 'colsample_bytree': [0.35, 0.26, 0.08, 0.79, 0.07, 0.44, 0.19, 0.76773471073923794, 0.86250026996278017, 0.52707508555192784, 1.0, 0.01, 1.0, 1.0, 0.01, 0.01, 0.01], 'gamma': [9.37, 6.42, 5.29, 13.86, 11.14, 6.71, 18.87, 12.875736167500573, 0.09699579988250584, 8.4021367237458282, 6.0922437971030794, 6.2339155688477641, 20.0, 0.0, 20.0, 0.0, 20.0], 'max_delta_step': [0.09, 2.86, 6.28, 4.59, 5.2, 3.95, 1.04, 10.0, 10.0, 10.0, 1.4218851574340832, 10.0, 0.0, 10.0, 10.0, 0.0, 0.0], 'max_depth': [14.6, 10.0, 5.23, 12.72, 6.5, 9.24, 11.25, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 15.0, 15.0, 15.0, 15.0], 'min_child_weight': [19.96, 6.34, 33.74, 33.38, 22.08, 32.19, 33.91, 1.0, 3.9516518856239315, 10.824894348243927, 1.0, 1.0, 14.188984760492747, 40.0, 28.534267447538799, 17.59366558111461, 1.0], 'subsample': [0.8, 0.8, 2.88, 2.73, 4.85, 3.68, 2.65, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 0.10000000000000001, 0.10000000000000001, 0.10000000000000001, 0.10000000000000001]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['area_name', 'id', 'address', 'neighborhood', 'bedrooms', 'bathrooms',\n",
      "       'sqft', 'source', 'origin_url', 'created_at', 'updated_at', 'latitude',\n",
      "       'longitude', 'elevation', 'lookup_address', 'luxurious', 'garage',\n",
      "       'year_built', 'level', 'dist_to_park', 'sfh', 'dist_to_golf_course',\n",
      "       'zipcode', 'near_golf_course', 'home_type', 'has_pool', 'bookmarked',\n",
      "       'notes', 'hoa_fees', 'lot', 'zestimate_rent', 'zestimate_sale', 'saves',\n",
      "       'event_name', 'construction', 'adult', 'description', 'rooms',\n",
      "       'stories', 'images', 'transaction_id', 'id', 'price',\n",
      "       'transaction_status', 'date_listed', 'date_closed', 'days_on_market',\n",
      "       'created_at', 'updated_at', 'transaction_type', 'is_latest', 'abnormal',\n",
      "       'ignore', 'closed_diff_id', 'listed_diff_id', 'price_listed',\n",
      "       'price_closed', 'date_transacted_latest'],\n",
      "      dtype='object')\n",
      "Entries before filter:  40000\n",
      "Entries after filter: 38394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ilya/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ilya/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ilya/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ilya/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "df = sanitize(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {       'max_depth': (5, 15),\n",
    "                 'gamma': (0.0, 20.0),\n",
    "                 'min_child_weight': (1, 40),\n",
    "                 'max_delta_step': (0, 10),\n",
    "                 'subsample': (0.1, 5.0),\n",
    "                 'colsample_bytree' :(0.01, 1.0),\n",
    "                 'alpha': (0, 20)\n",
    "               }\n",
    "\n",
    "XGB_BOpt = BayesianOptimization(XGBcv, params)\n",
    "XGB_BOpt.initialize(init_values)\n",
    "\n",
    "discount = .10\n",
    "df['good_sell'] = (df.price_closed >= (df.price_listed * (1 - discount )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = df.columns\n",
    "# ind2remove = ['Unnamed: 0', 'address', 'area_name', 'date_listed', 'id', 'listed_diff_id', 'lookup_address',\n",
    "#               'origin_url', 'neighborhood', 'zipcode', 'luxurious', 'transaction_status', 'transaction_type',\n",
    "#               'zestimate_sale']\n",
    "ind2remove = ['area_name', 'address', 'origin_url', 'lookup_address', 'zipcode', 'zestimate_rent', 'date_listed', 'date_closed', \n",
    "              'zestimate_sale', 'construction', 'stories', 'transaction_id', 'transaction_status', 'good_sell', \n",
    "              'transaction_type', 'price_closed', 'date_transacted_latest', 'updated_at','notes','price']\n",
    "\n",
    "factors = np.setdiff1d(cols, ind2remove)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m----------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   subsample | \n",
      "Multiple eval metrics have been passed: 'test-error' will be used for early stopping.\n",
      "\n",
      "Will train until test-error hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[26]\ttrain-error:0.0395113+0.000260937\ttest-error:0.0395377+0.000390347\n",
      "\n",
      "    1 | 00m20s | \u001b[35m  -0.03954\u001b[0m | \u001b[32m  12.7038\u001b[0m | \u001b[32m            0.5000\u001b[0m | \u001b[32m  19.4210\u001b[0m | \u001b[32m          2.3397\u001b[0m | \u001b[32m     8.5051\u001b[0m | \u001b[32m           13.1419\u001b[0m | \u001b[32m     0.9018\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-error' will be used for early stopping.\n",
      "\n",
      "Will train until test-error hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[59]\ttrain-error:0.0394593+0.000224479\ttest-error:0.0396157+0.000357019\n",
      "\n",
      "    2 | 00m20s |   -0.03962 |   10.5655 |             0.5062 |    9.0090 |           8.6364 |      6.2643 |             8.8924 |      1.4109 | \n",
      "Multiple eval metrics have been passed: 'test-error' will be used for early stopping.\n",
      "\n",
      "Will train until test-error hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[12]\ttrain-error:0.0386387+0.000308653\ttest-error:0.0390167+0.000417656\n",
      "\n",
      "    3 | 00m13s | \u001b[35m  -0.03902\u001b[0m | \u001b[32m   2.9179\u001b[0m | \u001b[32m            0.9654\u001b[0m | \u001b[32m   4.9603\u001b[0m | \u001b[32m          1.4093\u001b[0m | \u001b[32m     5.6025\u001b[0m | \u001b[32m            4.4016\u001b[0m | \u001b[32m     3.1739\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-error' will be used for early stopping.\n",
      "\n",
      "Will train until test-error hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[13]\ttrain-error:0.0395503+0.000231979\ttest-error:0.0395377+0.000448668\n",
      "\n",
      "    4 | 00m37s |   -0.03954 |    9.9601 |             0.7895 |    5.1120 |           1.5922 |     13.5541 |            19.0535 |      0.5597 | \n",
      "Multiple eval metrics have been passed: 'test-error' will be used for early stopping.\n",
      "\n",
      "Will train until test-error hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\ttrain-error:0.045554+0.00049851\ttest-error:0.0456843+0.000365814\n",
      "\n",
      "    5 | 00m24s |   -0.04568 |    9.1183 |             0.1506 |   18.3829 |           5.4739 |     13.8099 |            24.5272 |      0.3755 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m----------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   subsample | \n",
      "Multiple eval metrics have been passed: 'test-error' will be used for early stopping.\n",
      "\n",
      "Will train until test-error hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[25]\ttrain-error:0.0382223+0.000434251\ttest-error:0.0388863+0.000376399\n",
      "\n",
      "    6 | 00m41s | \u001b[35m  -0.03889\u001b[0m | \u001b[32m   0.0000\u001b[0m | \u001b[32m            1.0000\u001b[0m | \u001b[32m  20.0000\u001b[0m | \u001b[32m          9.5792\u001b[0m | \u001b[32m     5.0000\u001b[0m | \u001b[32m            1.0000\u001b[0m | \u001b[32m     5.0000\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-error' will be used for early stopping.\n",
      "\n",
      "Will train until test-error hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-error:0.0459187+1.72111e-05\ttest-error:0.0459187+3.44513e-05\n",
      "\n",
      "    7 | 00m26s |   -0.04592 |    0.0000 |             0.0100 |    0.0000 |          10.0000 |      8.8462 |             1.0000 |      5.0000 | \n",
      "Multiple eval metrics have been passed: 'test-error' will be used for early stopping.\n",
      "\n",
      "Will train until test-error hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-error:0.0459187+1.72111e-05\ttest-error:0.0459187+3.44513e-05\n",
      "\n",
      "    8 | 00m21s |   -0.04592 |   10.4139 |             0.0100 |   20.0000 |          10.0000 |      5.0000 |             1.0000 |      0.1000 | \n",
      "Multiple eval metrics have been passed: 'test-error' will be used for early stopping.\n",
      "\n",
      "Will train until test-error hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-error:0.0459187+1.72111e-05\ttest-error:0.0459187+3.44513e-05\n",
      "\n",
      "    9 | 00m14s |   -0.04592 |    0.0000 |             0.0100 |    5.5042 |          10.0000 |      5.0000 |            18.9665 |      0.1000 | \n",
      "Multiple eval metrics have been passed: 'test-error' will be used for early stopping.\n",
      "\n",
      "Will train until test-error hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[11]\ttrain-error:0.0395373+0.000262097\ttest-error:0.0395633+0.000517539\n",
      "\n",
      "   10 | 00m21s |   -0.03956 |   20.0000 |             1.0000 |    0.0000 |          10.0000 |      5.0000 |            40.0000 |      5.0000 | \n",
      "Multiple eval metrics have been passed: 'test-error' will be used for early stopping.\n",
      "\n",
      "Will train until test-error hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[7]\ttrain-error:0.0395113+0.000236255\ttest-error:0.0395633+0.000517539\n",
      "\n",
      "   11 | 01m25s |   -0.03956 |    0.0000 |             1.0000 |    0.0000 |           0.0000 |     15.0000 |            40.0000 |      5.0000 | \n",
      "Multiple eval metrics have been passed: 'test-error' will be used for early stopping.\n",
      "\n",
      "Will train until test-error hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-error:0.0459187+1.72111e-05\ttest-error:0.0459187+3.44513e-05\n",
      "\n",
      "   12 | 00m14s |   -0.04592 |   17.3421 |             0.0100 |    0.0000 |          10.0000 |      5.0000 |             1.0000 |      5.0000 | \n",
      "Multiple eval metrics have been passed: 'test-error' will be used for early stopping.\n",
      "\n",
      "Will train until test-error hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-error:0.0459187+1.72111e-05\ttest-error:0.0459187+3.44513e-05\n",
      "\n",
      "   13 | 00m14s |   -0.04592 |   20.0000 |             0.0100 |   20.0000 |           0.0000 |      5.0000 |            40.0000 |      5.0000 | \n",
      "Multiple eval metrics have been passed: 'test-error' will be used for early stopping.\n",
      "\n",
      "Will train until test-error hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\ttrain-error:0.0453717+0.000381489\ttest-error:0.0453977+0.000665815\n",
      "\n",
      "   14 | 00m21s |   -0.04540 |   19.9888 |             0.1911 |   12.8356 |           5.7135 |      9.9968 |            11.9573 |      3.0054 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-error' will be used for early stopping.\n",
      "\n",
      "Will train until test-error hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\ttrain-error:0.0453717+0.000381489\ttest-error:0.0453977+0.000665815\n",
      "\n",
      "   15 | 00m21s |   -0.04540 |   19.9888 |             0.1911 |   12.8356 |           5.7135 |      9.9968 |            11.9573 |      3.0054 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-error' will be used for early stopping.\n",
      "\n",
      "Will train until test-error hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\ttrain-error:0.0453717+0.000381489\ttest-error:0.0453977+0.000665815\n",
      "\n",
      "   16 | 00m21s |   -0.04540 |   19.9888 |             0.1911 |   12.8356 |           5.7135 |      9.9968 |            11.9573 |      3.0054 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-error' will be used for early stopping.\n",
      "\n",
      "Will train until test-error hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\ttrain-error:0.0453717+0.000381489\ttest-error:0.0453977+0.000665815\n",
      "\n",
      "   17 | 00m21s |   -0.04540 |   19.9888 |             0.1911 |   12.8356 |           5.7135 |      9.9968 |            11.9573 |      3.0054 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-error' will be used for early stopping.\n",
      "\n",
      "Will train until test-error hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\ttrain-error:0.0453717+0.000381489\ttest-error:0.0453977+0.000665815\n",
      "\n",
      "   18 | 00m21s |   -0.04540 |   19.9888 |             0.1911 |   12.8356 |           5.7135 |      9.9968 |            11.9573 |      3.0054 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-error' will be used for early stopping.\n",
      "\n",
      "Will train until test-error hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\ttrain-error:0.0453717+0.000381489\ttest-error:0.0453977+0.000665815\n",
      "\n",
      "   19 | 00m21s |   -0.04540 |   19.9888 |             0.1911 |   12.8356 |           5.7135 |      9.9968 |            11.9573 |      3.0054 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-error' will be used for early stopping.\n",
      "\n",
      "Will train until test-error hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\ttrain-error:0.0453717+0.000381489\ttest-error:0.0453977+0.000665815\n",
      "\n",
      "   20 | 00m21s |   -0.04540 |   19.9888 |             0.1911 |   12.8356 |           5.7135 |      9.9968 |            11.9573 |      3.0054 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-error' will be used for early stopping.\n",
      "\n",
      "Will train until test-error hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\ttrain-error:0.0453717+0.000381489\ttest-error:0.0453977+0.000665815\n",
      "\n",
      "   21 | 00m21s |   -0.04540 |   19.9888 |             0.1911 |   12.8356 |           5.7135 |      9.9968 |            11.9573 |      3.0054 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-error' will be used for early stopping.\n",
      "\n",
      "Will train until test-error hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\ttrain-error:0.0453717+0.000381489\ttest-error:0.0453977+0.000665815\n",
      "\n",
      "   22 | 00m21s |   -0.04540 |   19.9888 |             0.1911 |   12.8356 |           5.7135 |      9.9968 |            11.9573 |      3.0054 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-error' will be used for early stopping.\n",
      "\n",
      "Will train until test-error hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\ttrain-error:0.0453717+0.000381489\ttest-error:0.0453977+0.000665815\n",
      "\n",
      "   23 | 00m21s |   -0.04540 |   19.9888 |             0.1911 |   12.8356 |           5.7135 |      9.9968 |            11.9573 |      3.0054 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-error' will be used for early stopping.\n",
      "\n",
      "Will train until test-error hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\ttrain-error:0.0453717+0.000381489\ttest-error:0.0453977+0.000665815\n",
      "\n",
      "   24 | 00m21s |   -0.04540 |   19.9888 |             0.1911 |   12.8356 |           5.7135 |      9.9968 |            11.9573 |      3.0054 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-error' will be used for early stopping.\n",
      "\n",
      "Will train until test-error hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\ttrain-error:0.0453717+0.000381489\ttest-error:0.0453977+0.000665815\n",
      "\n",
      "   25 | 00m21s |   -0.04540 |   19.9888 |             0.1911 |   12.8356 |           5.7135 |      9.9968 |            11.9573 |      3.0054 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-error' will be used for early stopping.\n",
      "\n",
      "Will train until test-error hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\ttrain-error:0.0453717+0.000381489\ttest-error:0.0453977+0.000665815\n",
      "\n",
      "   26 | 00m21s |   -0.04540 |   19.9888 |             0.1911 |   12.8356 |           5.7135 |      9.9968 |            11.9573 |      3.0054 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-error' will be used for early stopping.\n",
      "\n",
      "Will train until test-error hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\ttrain-error:0.0453717+0.000381489\ttest-error:0.0453977+0.000665815\n",
      "\n",
      "   27 | 00m21s |   -0.04540 |   19.9888 |             0.1911 |   12.8356 |           5.7135 |      9.9968 |            11.9573 |      3.0054 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-error' will be used for early stopping.\n",
      "\n",
      "Will train until test-error hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\ttrain-error:0.0453717+0.000381489\ttest-error:0.0453977+0.000665815\n",
      "\n",
      "   28 | 00m21s |   -0.04540 |   19.9888 |             0.1911 |   12.8356 |           5.7135 |      9.9968 |            11.9573 |      3.0054 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-error' will be used for early stopping.\n",
      "\n",
      "Will train until test-error hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\ttrain-error:0.0453717+0.000381489\ttest-error:0.0453977+0.000665815\n",
      "\n",
      "   29 | 00m21s |   -0.04540 |   19.9888 |             0.1911 |   12.8356 |           5.7135 |      9.9968 |            11.9573 |      3.0054 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-error' will be used for early stopping.\n",
      "\n",
      "Will train until test-error hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\ttrain-error:0.0453717+0.000381489\ttest-error:0.0453977+0.000665815\n",
      "\n",
      "   30 | 00m21s |   -0.04540 |   19.9888 |             0.1911 |   12.8356 |           5.7135 |      9.9968 |            11.9573 |      3.0054 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-error' will be used for early stopping.\n",
      "\n",
      "Will train until test-error hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\ttrain-error:0.0453717+0.000381489\ttest-error:0.0453977+0.000665815\n",
      "\n",
      "   31 | 00m21s |   -0.04540 |   19.9888 |             0.1911 |   12.8356 |           5.7135 |      9.9968 |            11.9573 |      3.0054 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-error' will be used for early stopping.\n",
      "\n",
      "Will train until test-error hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\ttrain-error:0.0453717+0.000381489\ttest-error:0.0453977+0.000665815\n",
      "\n",
      "   32 | 00m21s |   -0.04540 |   19.9888 |             0.1911 |   12.8356 |           5.7135 |      9.9968 |            11.9573 |      3.0054 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-error' will be used for early stopping.\n",
      "\n",
      "Will train until test-error hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\ttrain-error:0.0453717+0.000381489\ttest-error:0.0453977+0.000665815\n",
      "\n",
      "   33 | 00m21s |   -0.04540 |   19.9888 |             0.1911 |   12.8356 |           5.7135 |      9.9968 |            11.9573 |      3.0054 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-error' will be used for early stopping.\n",
      "\n",
      "Will train until test-error hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\ttrain-error:0.0453717+0.000381489\ttest-error:0.0453977+0.000665815\n",
      "\n",
      "   34 | 00m21s |   -0.04540 |   19.9888 |             0.1911 |   12.8356 |           5.7135 |      9.9968 |            11.9573 |      3.0054 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-error' will be used for early stopping.\n",
      "\n",
      "Will train until test-error hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\ttrain-error:0.0453717+0.000381489\ttest-error:0.0453977+0.000665815\n",
      "\n",
      "   35 | 00m21s |   -0.04540 |   19.9888 |             0.1911 |   12.8356 |           5.7135 |      9.9968 |            11.9573 |      3.0054 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(df[factors].values, label=df.good_sell, feature_names=factors)\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# per link below i need to use Upper Confidence Bound and add some alpha (square of stdev), otherwise it starts to loop\n",
    "# https://github.com/fmfn/BayesianOptimization/issues/10 \n",
    "XGB_BOpt.maximize(init_points=5, n_iter=30, acq='ucb', kappa=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target': [-0.05, -0.05, -0.06, -0.049, -0.051, -0.049, -0.057, -0.042, -0.041, -0.042, -0.041, -0.049, -0.042, -0.049, -0.049, -0.049, -0.0498, -0.038886333333333335, -0.045918666666666663, -0.045918666666666663, -0.045918666666666663, -0.039563333333333332, -0.039563333333333332, -0.045918666666666663, -0.045918666666666663, -0.045397666666666669, -0.045397666666666669, -0.045397666666666669, -0.045397666666666669, -0.045397666666666669, -0.045397666666666669, -0.045397666666666669, -0.045397666666666669, -0.045397666666666669, -0.045397666666666669, -0.045397666666666669, -0.045397666666666669, -0.045397666666666669, -0.045397666666666669, -0.045397666666666669, -0.045397666666666669, -0.045397666666666669, -0.045397666666666669, -0.045397666666666669, -0.045397666666666669, -0.045397666666666669, -0.045397666666666669], 'alpha': [8.97, 9.99, 14.44, 15.33, 1.84, 3.14, 8.05, 0.0, 0.0, 1.1253151004836615, 0.0, 8.388997814363904, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 10.413942738936765, 0.0, 20.0, 0.0, 17.34206170143981, 20.0, 19.988758255469438, 19.988758255469438, 19.988758255469438, 19.988758255469438, 19.988758255469438, 19.988758255469438, 19.988758255469438, 19.988758255469438, 19.988758255469438, 19.988758255469438, 19.988758255469438, 19.988758255469438, 19.988758255469438, 19.988758255469438, 19.988758255469438, 19.988758255469438, 19.988758255469438, 19.988758255469438, 19.988758255469438, 19.988758255469438, 19.988758255469438, 19.988758255469438], 'colsample_bytree': [0.35, 0.26, 0.08, 0.79, 0.07, 0.44, 0.19, 0.7677347107392379, 0.8625002699627802, 0.5270750855519278, 1.0, 0.01, 1.0, 1.0, 0.01, 0.01, 0.01, 1.0, 0.01, 0.01, 0.01, 1.0, 1.0, 0.01, 0.01, 0.19114230425715104, 0.19114230425715104, 0.19114230425715104, 0.19114230425715104, 0.19114230425715104, 0.19114230425715104, 0.19114230425715104, 0.19114230425715104, 0.19114230425715104, 0.19114230425715104, 0.19114230425715104, 0.19114230425715104, 0.19114230425715104, 0.19114230425715104, 0.19114230425715104, 0.19114230425715104, 0.19114230425715104, 0.19114230425715104, 0.19114230425715104, 0.19114230425715104, 0.19114230425715104, 0.19114230425715104], 'gamma': [9.37, 6.42, 5.29, 13.86, 11.14, 6.71, 18.87, 12.875736167500573, 0.09699579988250584, 8.402136723745828, 6.092243797103079, 6.233915568847764, 20.0, 0.0, 20.0, 0.0, 20.0, 20.0, 0.0, 20.0, 5.5041667919596753, 0.0, 0.0, 0.0, 20.0, 12.835622285762687, 12.835622285762687, 12.835622285762687, 12.835622285762687, 12.835622285762687, 12.835622285762687, 12.835622285762687, 12.835622285762687, 12.835622285762687, 12.835622285762687, 12.835622285762687, 12.835622285762687, 12.835622285762687, 12.835622285762687, 12.835622285762687, 12.835622285762687, 12.835622285762687, 12.835622285762687, 12.835622285762687, 12.835622285762687, 12.835622285762687, 12.835622285762687], 'max_delta_step': [0.09, 2.86, 6.28, 4.59, 5.2, 3.95, 1.04, 10.0, 10.0, 10.0, 1.4218851574340832, 10.0, 0.0, 10.0, 10.0, 0.0, 0.0, 9.5791871004340461, 10.0, 10.0, 10.0, 10.0, 0.0, 10.0, 0.0, 5.7134678177293434, 5.7134678177293434, 5.7134678177293434, 5.7134678177293434, 5.7134678177293434, 5.7134678177293434, 5.7134678177293434, 5.7134678177293434, 5.7134678177293434, 5.7134678177293434, 5.7134678177293434, 5.7134678177293434, 5.7134678177293434, 5.7134678177293434, 5.7134678177293434, 5.7134678177293434, 5.7134678177293434, 5.7134678177293434, 5.7134678177293434, 5.7134678177293434, 5.7134678177293434, 5.7134678177293434], 'max_depth': [14.6, 10.0, 5.23, 12.72, 6.5, 9.24, 11.25, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 15.0, 15.0, 15.0, 15.0, 5.0, 8.8462073936983163, 5.0, 5.0, 5.0, 15.0, 5.0, 5.0, 9.9968196629140937, 9.9968196629140937, 9.9968196629140937, 9.9968196629140937, 9.9968196629140937, 9.9968196629140937, 9.9968196629140937, 9.9968196629140937, 9.9968196629140937, 9.9968196629140937, 9.9968196629140937, 9.9968196629140937, 9.9968196629140937, 9.9968196629140937, 9.9968196629140937, 9.9968196629140937, 9.9968196629140937, 9.9968196629140937, 9.9968196629140937, 9.9968196629140937, 9.9968196629140937, 9.9968196629140937], 'min_child_weight': [19.96, 6.34, 33.74, 33.38, 22.08, 32.19, 33.91, 1.0, 3.9516518856239315, 10.824894348243927, 1.0, 1.0, 14.188984760492747, 40.0, 28.5342674475388, 17.59366558111461, 1.0, 1.0, 1.0, 1.0, 18.96645605717039, 40.0, 40.0, 1.0, 40.0, 11.957271098025851, 11.957271098025851, 11.957271098025851, 11.957271098025851, 11.957271098025851, 11.957271098025851, 11.957271098025851, 11.957271098025851, 11.957271098025851, 11.957271098025851, 11.957271098025851, 11.957271098025851, 11.957271098025851, 11.957271098025851, 11.957271098025851, 11.957271098025851, 11.957271098025851, 11.957271098025851, 11.957271098025851, 11.957271098025851, 11.957271098025851, 11.957271098025851], 'subsample': [0.8, 0.8, 2.88, 2.73, 4.85, 3.68, 2.65, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 0.1, 0.1, 0.1, 0.1, 5.0, 5.0, 0.10000000000000001, 0.10000000000000001, 5.0, 5.0, 5.0, 5.0, 3.0054490172975243, 3.0054490172975243, 3.0054490172975243, 3.0054490172975243, 3.0054490172975243, 3.0054490172975243, 3.0054490172975243, 3.0054490172975243, 3.0054490172975243, 3.0054490172975243, 3.0054490172975243, 3.0054490172975243, 3.0054490172975243, 3.0054490172975243, 3.0054490172975243, 3.0054490172975243, 3.0054490172975243, 3.0054490172975243, 3.0054490172975243, 3.0054490172975243, 3.0054490172975243, 3.0054490172975243]}\n"
     ]
    }
   ],
   "source": [
    "# not used - reset the variable\n",
    "#new_init = { 'target': [], 'alpha': [], 'colsample_bytree': [], 'gamma': [], 'max_delta_step': [], 'max_depth': [], 'min_child_weight': [], 'subsample': [] }\n",
    "new_init = init_values\n",
    "\n",
    "# store resulting values to help seed the next run. make sure not to overwrite but add incrementally\n",
    "# copy paste the print out of init_values into the cell above\n",
    "for i in range(len(XGB_BOpt.res['all']['values'])):\n",
    "    new_init['target'].append(XGB_BOpt.res['all']['values'][i])\n",
    "    for k,v in XGB_BOpt.res['all']['params'][i].items():\n",
    "        new_init[k].append(v)\n",
    "    \n",
    "print (new_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_val': 20.0, 'max_params': {'max_depth': 1.0, 'gamma': 20.0, 'min_child_weight': 0.0, 'max_delta_step': 5.0, 'subsample': 14.188984760492747, 'colsample_bytree': 5.0, 'alpha': -0.042000000000000003}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9b6bd08240>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEiNEQmHBlAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9b8385e0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "print(XGB_BOpt.res['max'])\n",
    "(pd.DataFrame(XGB_BOpt.res['all']['values'])*-1.0).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from cloudinary.uploader import upload\n",
    "from cloudinary.utils import cloudinary_url\n",
    "from cloudinary.api import delete_resources_by_tag, resources_by_tag\n",
    "\n",
    "def plot_rounds(plot):\n",
    "    # uploads the graph to the web and returns the URL\n",
    "    \n",
    "    fig = plot.get_figure()\n",
    "    fig.savefig('temp_plot.png')\n",
    "    \n",
    "    response = upload(\"temp_plot.png\")\n",
    "    url, options = cloudinary_url(response['public_id'],\n",
    "        format = response['format'],\n",
    "        crop = \"fill\")\n",
    "    return url\n",
    "\n",
    "def slack(text, url = None):\n",
    "    print(\"Slacking: \" + text)\n",
    "    \n",
    "    if url == None:\n",
    "        data=json.dumps({\"text\": text})\n",
    "    else:\n",
    "        data = json.dumps( { \"text\": text, \"attachments\": [ { \"fallback\": \"Model MAE\"\n",
    "                                           , \"title\": \"Model Mean Average Error by Iteration ($)\"\n",
    "                                           , \"image_url\": url } ] } )\n",
    "    \n",
    "    response = requests.post(webhook_url, data , headers={'Content-Type': 'application/json'})\n",
    "    if response.status_code != 200:\n",
    "        raise ValueError('Request to slack returned an error %s, the response is:\\n%s' % (response.status_code, response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py:852: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slacking: Bayesian Search: Max params {'max_val': 20.0, 'max_params': {'max_depth': 1.0, 'gamma': 20.0, 'min_child_weight': 0.0, 'max_delta_step': 5.0, 'subsample': 14.188984760492747, 'colsample_bytree': 5.0, 'alpha': -0.042000000000000003}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<slacker.Response at 0x7f9b6bcb6d30>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3X9wHOd93/H3BweAAEWCsixaYQTGlBPaM4wTKTIiK2PX\ndZTGESVVjOs6IzWqHKUzDGspI0+bqFKSuumPdDyO02iUasTKKlOrcqJ6JnbMqMwoTmQ2bho6Ii1Z\nNi0xQVXaIkuLdFwDoIlfh/v2j9slz2eQOAC3u7fLz2sGQ9zu3t2zc8P94Hmeve+jiMDMzKyv6AaY\nmVlvcCCYmRngQDAzs4QDwczMAAeCmZklHAhmZgY4EMzMLOFAMDMzwIFgZmaJ/qIbsByXX355bNmy\npehmmJmVyqFDh74RERuXOq5UgbBlyxYOHjxYdDPMzEpF0lc7Oc5DRmZmBjgQzMws0VEgSLpR0hFJ\n45LuX2S/JD2U7H9B0rVt+2uSnpP0VNv2X5T0kqTDkj68ulMxM7PVWHIOQVINeBj4SeAY8KykvRHx\nlZbDtgNbk5+3Ao8k/6buBV4ERlpe98eBHcDVETEr6XWrPBczM1uFTnoI1wHjEfFyRMwBT9K8kLfa\nATweTQeASyVtApA0CtwMPNb2nH8KfCgiZgEi4uQqzsPMzFapk0C4Enil5fGxZFunxzwI3Ac02p7z\nRuDvSPq8pP8h6Uc7brWZmXVdppPKkm4BTkbEoUV29wOXAdcDvwx8QpIWeY2dkg5KOnjq1Kksm2tm\ndlHr5HsIx4HNLY9Hk22dHPMe4FZJNwFDwIikJyLiDpq9iE9Gcw3Pv5LUAC4HvuOqHxGPAo8CjI2N\ndbTe58z8Av/lfx3lzGy9k8OXbc1AjTt/7PWsHxrI5PU79bW/PcMffOEYnS6D2tcn3nPtKJsvW5tx\ny8ysjDoJhGeBrZKuonmRvw34R23H7AXukfQkzcnkiYg4ATyQ/CDpncAvJWEA8IfAjwOflfRGYBD4\nxupOp+ng0f/Hh/74JZrv241XPCe99m6+bC23Xv293X3xZfqvB47y0c/9n47PMQI+9dxx9t7zdjYM\nFxtmZtZ7lgyEiKhLugd4GqgBeyLisKRdyf7dwD7gJmAcOAPc1cF77wH2SPoyMAe8Lzr9U3cJE9Pz\nADz9gXfwpu9Z342XPOsbp2cZ+3d/ysSZua6+7kp868w8mzYM8ZcP/ERHxx/66je57dED/LP/9jwf\nvXOMvr4up6WZlVpHpSsiYh/Ni37rtt0tvwdw9xKvsR/Y3/J4DrjjfMevxtRMMxDWD3W/MsdIMkyU\nhk6RJqbnz7anE295/WV88JZt/MtPH+Z3nhnn3r+3NcPWmVnZVPKbylMzzbmDLAJhsL+P4YEakzPZ\nzE8sx+TM/LKHfu64/vW859pRHvyzv+aZl17NqGVmVkYVDYR5JLhkMJvafSPD/Uyc6YUeQp2R4eWd\noyR+491vZtumET7w5PMc/ca3M2qdmZVNJQNhcqbOusH+zMbINwwP9MSQ0eT0PCMrmBweGqix+463\n0Ncndj1xiDNzxfd2zKx4lQyEqZl6JsNFqZGhASZneiQQVnjr6+bL1vLQbT/CkVenuP8PvtTxratm\nVl0VDYT5TL8j0As9hIVGMDVbX9Xto+9440Z+6V1vYu8X/y97/uJo9xpnZqVU0UDIuIcwXHwPIb2T\naiVDRq3e/87v56d+8Ar+/b4XOfDy33ajaWZWUtUMhNn5TANhw/BA4ZPKaQ9ltV8wk8RH3ns1r3/t\nWu75vS9wYmK6G80zsxKqZiDM1DMdMhoZHmBqtk6jUdy4++R0cyK4G984Xj80wH+64y1Mzy3w/o9/\ngdn6wqpf08zKp8KBkOWkcj8RMJVRraROpD2EkS6d59Yr1vOR917Nc1/7Fv/mj76y9BPMrHIqFwgR\nkcukMjTv8ilKOoexYW33znP7D21i19/9fj7++a/xiWdfWfoJZlYplQuE2XqD+YXIfFIZii1fca6H\n0N3g+6V3vZG3/8Dl/Nqnv8wLx77V1dc2s96W3VWzIOlfzt0aSlnM2R5CgXcaTXZpUrldf62Ph27/\nEf7+7/xPbn/0AK9dt6arr29mvatygXCujlGGk8pDxQ8ZTUzPU+sTawdrXX/tyy4Z5Hfv+lEe+9zL\nzC/4C2tmZfe5Do+rcCBk2ENYW/yQUVrYbpFF5rrijVes58P/8OpMXtvM8vXgbZ0dV7k5hHOlr7Ps\nITTDJr31swgT0/VMh8XM7OJTwUDIvoewbk0/fSp+UtmrnplZN1UwELJbHCclqfDyFSutdGpmdj4V\nDITsJ5Wh+AJ3DgQz67bKBsK6NdmOr28YHij8i2keMjKzbuooECTdKOmIpHFJ9y+yX5IeSva/IOna\ntv01Sc9Jeqpl269LOi7p+eTnptWfTjMQ1q3pp5bxAvIjQ8X1ECJi2espm5ktZclAkFQDHga2A9uA\n2yVtaztsO7A1+dkJPNK2/17gxUVe/rcj4prkZ99yG7+YZtmK7O++2TA8UNi6yjPzzW9ju4dgZt3U\nSQ/hOmA8Il6OiDngSWBH2zE7gMej6QBwqaRNAJJGgZuBx7rY7vNKewhZGxnuL6yHcLZsxTLXUzYz\nu5BOAuFKoLXS2bFkW6fHPAjcBzQWee1fTIaY9kh6TWdNvrCs10JIjRQ4h3C2sJ17CGbWRZlOKku6\nBTgZEYcW2f0I8AbgGuAE8FvneY2dkg5KOnjq1Kkl3zPrtRBSI0MDzNYbzMznv3ZAVoXtzOzi1kkg\nHAc2tzweTbZ1cszbgFslHaU51HSDpCcAIuLViFiIiAbwUZpDU98lIh6NiLGIGNu4ceOSjc16LYRU\nkSWwsypsZ2YXt04C4Vlgq6SrJA0CtwF7247ZC9yZ3G10PTARESci4oGIGI2ILcnznomIOwDSOYbE\nu4Evr/ZkgMzXQkiNFFjx9NwcggPBzLpnyT+lI6Iu6R7gaaAG7ImIw5J2Jft3A/uAm4Bx4AxwVwfv\n/WFJ1wABHAV+YUVn0GZyJp8aPxsKXBPBPQQzy0JHV87kltB9bdt2t/wewN1LvMZ+YH/L43+8jHZ2\nZLa+wFy9kc+kcoEF7iams6/XZGYXn0p9UzmvshVQbA9hYnqeSwZrDNQq9fGZWcEqdUXJo9JpqshV\n01y2wsyyULFAyH4thNTZdZXPFNND8ISymXVbxQIhvx7CQK2PtYO1YnoIDgQzy0DFAiH7tRBaFVXg\nzoXtzCwLlQqEtNhcXhfLZgns/O8ympqpew7BzLquUoGQ55ARFFfgrjmH4FtOzay7KhYIzYtzHtVO\noZhV0+oLDU7PuodgZt1XsUCos3awRn9O9+ePDOW/rvJUzsNiZnbxqFgg5FP6OjVSQA/Bpa/NLCuV\nCoTTs/mUvk6NDA9werZOoxG5vacL25lZVioVCHmVvk5tGB4g4twwTh7Su5rcQzCzbqtUIEzmtDhO\nqojyFROudGpmGalUIOQ+h5C8V57zCF5P2cyyUrFAqLM+p1tOoZhV0zypbGZZqVgg5H+XEeTfQ+jv\nE8MDtdze08wuDpUJhPmFBjPzjcrPIUxON0tfS8rtPc3s4lCZQMi7bAUU10PwLadmloUKBUJ+ayGk\nLhmsUetTroEwOVN3IJhZJioUCPn3ECQxMtSfa8XTZulr32FkZt3XUSBIulHSEUnjku5fZL8kPZTs\nf0HStW37a5Kek/TUIs/955JC0uUrP41z4/h5Lzyfd4G7qWkvn2lm2VgyECTVgIeB7cA24HZJ29oO\n2w5sTX52Ao+07b8XeHGR194MvAv42rJb3qaoom8jw/kWuPMcgpllpZMewnXAeES8HBFzwJPAjrZj\ndgCPR9MB4FJJmwAkjQI3A48t8tq/DdwHrLoYUBFDRpBvDyEimJxxD8HMstFJIFwJvNLy+FiyrdNj\nHqR50W+0PkHSDuB4RHzxQm8uaaekg5IOnjp16rzHFTGpDEkPIadAmJ5fYH4hHAhmlolMJ5Ul3QKc\njIhDbdvXAr8CfHCp14iIRyNiLCLGNm7ceN7jiuohNNdVzmdSOZ289loIZpaFTgLhOLC55fFosq2T\nY94G3CrpKM2hphskPQF8P3AV8MVk3yjwBUnfs4JzAJo9hKGBPgZyWhwntSHHOQQXtjOzLHVy9XwW\n2CrpKkmDwG3A3rZj9gJ3JncbXQ9MRMSJiHggIkYjYkvyvGci4o6I+FJEvC4itiT7jgHXRsTXV3oi\nUzlXOk2NDPczV28wM7+Q+Xu5sJ2ZZWnJK0tE1CXdAzwN1IA9EXFY0q5k/25gH3ATMA6cAe7KrsmL\ny3sthFRrgbuhjOsLTbqHYGYZ6ugKGhH7aF70W7ftbvk9gLuXeI39wP7z7NvSSTsuZHJmvpgewtC5\n8hWvGxnK9L3O9hA8h2BmGajUN5WL+AZvngXuXPrazLJUoUDIt/R1Ks8Cd+l7FHGeZlZ9lQmE07N1\n1q/J/y/nDTkGwuR0nXVr+unP+U4qM7s4VObKUtSkcjpMlUeBOxe2M7MsVSIQ6gsNzswtFHTbaY49\nhBnXMTKz7FQiEE7PNv86X1fAX88DtT7WDtZyKV/hwnZmlqVKBEJRZStSeRW4m3TpazPLUCUCIb0d\ns6jx9bzKVzgQzCxLlQiEcz2EYi6WzQJ3ecwh1P2lNDPLTMUCoZgeQrMEdrZ3GdUXGpyerbuHYGaZ\nqUggFLMWQmpkuD/zHsJkuiKcC9uZWUYqEgjFTypnPYfgwnZmlrWKBEKxJR1GhgaYmqmz0Fj1SqDn\n5cJ2Zpa1igRCncH+Ptb0Z1t++nzSv9qnMuwlnC1st9aBYGbZqEQgTBZU6TQ1cnZNhOwmlt1DMLOs\nVSIQpgpaCyGVR4G7NGw8h2BmWalIIBRT2C51tsBdhkNGXj7TzLJWkUAoZi2EVDqun2kPYWaegZoY\nzniZTjO7eFUkEIpZCyHVuq5yViaSshWSMnsPM7u4dRQIkm6UdETSuKT7F9kvSQ8l+1+QdG3b/pqk\n5yQ91bLt3ybHPi/pTyR970pPovghozzmEOY9oWxmmVoyECTVgIeB7cA24HZJ29oO2w5sTX52Ao+0\n7b8XeLFt229GxA9HxDXAU8AHl9/8pqInldcO1ujvU+ZzCC59bWZZ6qSHcB0wHhEvR8Qc8CSwo+2Y\nHcDj0XQAuFTSJgBJo8DNwGOtT4iIyZaHlwAr+lbXQiP49txCoT0ESYxkXAJ7cqbuQDCzTHUSCFcC\nr7Q8PpZs6/SYB4H7gEb7C0v6DUmvAD/LeXoIknZKOijp4KlTp75rf7o4TtELz2/IuMCdS1+bWdYy\nnVSWdAtwMiIOLbY/In41IjYDHwfuOc8xj0bEWESMbdy48bv2T830xhe2RoayLXDn9ZTNLGudBMJx\nYHPL49FkWyfHvA24VdJRmkNNN0h6YpH3+Djwng7b/B2KLmyXynLIKCLcQzCzzHUSCM8CWyVdJWkQ\nuA3Y23bMXuDO5G6j64GJiDgREQ9ExGhEbEme90xE3AEgaWvL83cAL63kBNJAKGI95VYjGVY8PTO3\nQL0RnkMws0wteRWNiLqke4CngRqwJyIOS9qV7N8N7ANuAsaBM8BdHbz3hyS9iebcwleBXSs5gaLX\nQkg15xCyCYSzhe0cCGaWoY7+rI6IfTQv+q3bdrf8HsDdS7zGfmB/y+MVDRG165kho6HmpHJEdP3L\nYy5sZ2Z5KP03lYteCyG1YXiAuYUGM/PfdTPVqrmwnZnlofSBcHZpyR4YMoJsCtxNeLU0M8tB6QNh\naqbOQE2s6S/2VNIqpFncaTTpSqdmloMKBEKzbEXRRd+yLHDnHoKZ5aECgVBsYbtUlgXuJnvkTioz\nq7YKBEKxayGksp5DWL+mn1qfS1+bWXYqEAjFroWQSr80NnEmizkEF7Yzs+xVIxB6oIeQ1hmayKDA\nnUtfm1keKhAIxa6FkOqv9XHJYC2TIaNJF7YzsxxUIBB6o4cAzXmErCaVfYeRmWWt1IHQaASn5+o9\n89fzSEb1jDxkZGZ5KHUgnJ6rE9E7t2NmVQLbpa/NLA+lDoReKWyX2jA8cLaURrfMLzT49tyCA8HM\nMlfyQOitL2w1K552t4cwdbZWU2+EnplVV8kDoQd7CF0OhLNlK9b2RuiZWXWVOhBO91ggjAz3MzVb\nZ6ERXXvNSa+FYGY5KXUg9FqNn3Scf6qL30VwYTszy0upA6HXxtezKHCXhp5vOzWzrFUiENb1SCCk\nf8V3MxDcQzCzvHQUCJJulHRE0rik+xfZL0kPJftfkHRt2/6apOckPdWy7TclvZQc/ylJly638VMz\n89T6xPBAbblPzcTI2TURunfrafpankMws6wtGQiSasDDwHZgG3C7pG1th20HtiY/O4FH2vbfC7zY\ntu0zwJsj4oeBvwYeWG7j07IVRS+Ok8qqhzBY62NooNSdOTMrgU6uMtcB4xHxckTMAU8CO9qO2QE8\nHk0HgEslbQKQNArcDDzW+oSI+JOISP+UPgCMLrfxvbIWQipd4rKbBe6aZSt6J/TMrLo6CYQrgVda\nHh9LtnV6zIPAfUDjAu/x88AfL7ZD0k5JByUdPHXq1Hfs65W1EFJZ9BAmZ1zHyMzykek4hKRbgJMR\ncegCx/wqUAc+vtj+iHg0IsYiYmzjxo3fsa+XKp0CDA/UGKipq19Ocx0jM8tLJ4FwHNjc8ng02dbJ\nMW8DbpV0lOZQ0w2SnkgPkvRzwC3Az0bEsr/NNdkjayGkJDEy1N0Cd821EHrnHM2sujoJhGeBrZKu\nkjQI3AbsbTtmL3BncrfR9cBERJyIiAciYjQitiTPeyYi7oDmnUs0h5JujYgzK2n81EzvlL5OdbvA\n3YR7CGaWkyWvphFRl3QP8DRQA/ZExGFJu5L9u4F9wE3AOHAGuKuD9/6PwBrgM8mE6YGI2LWcxvfa\npDLA+i6XwJ6cqZ+drDYzy1JHV5qI2Efzot+6bXfL7wHcvcRr7Af2tzz+gWW0c7HX4/RsvaeGjKC7\nBe4iwj0EM8tNaW9u//bcAo3oncJ2qZGh/q4Fwpm5BRYa4TkEM8tFaQOh19ZCSHVzXWWXrTCzPJU4\nEHqr9HVqZHiAyZl5VnDT1HdxYTszy1OJAyHtIfRWIGwYHmB+IZieX1j1a02ccQ/BzPJT2kCYPNtD\n6K2LZTre340CdxNeHMfMclTaQOi1tRBS3SxfkYaeewhmlocSB0LvTipDdwrceVLZzPJU2kDotfWU\nU+mXyNLx/9VIb1/tlQWAzKzaShsIUzN1an1i7WBvLI6T6nYPYf1QP7U+l742s+yVOBDmWbem99YJ\n6Oa6ypMzLmxnZvkpcSDUWbem94ZS0iGsbtxl5NLXZpan0gbCZI+thZDqr/Wxbk1/d3oI0y5sZ2b5\nKW0gTPXwcEq3yle4sJ2Z5anEgdCbPQRoDht1Y1LZcwhmlqfyBsJs762FkHIPwczKqLyBMNN7ayGk\nRrqwJsL8QoMzcwsubGdmuSllIERETw8ZdWORnEl/S9nMclbKQJieby4c06s9hG6sq+yyFWaWt1IG\nQq+uhZAaGRrg9Gyd+kJjxa+RBopvOzWzvHQUCJJulHRE0rik+xfZL0kPJftfkHRt2/6apOckPdWy\n7b2SDktqSBpbTqN7dS2E1IbkIj61il6CewhmlrclA0FSDXgY2A5sA26XtK3tsO3A1uRnJ/BI2/57\ngRfbtn0Z+AfAny+30Wf/eu7RIaORLpTAnvRaCGaWs056CNcB4xHxckTMAU8CO9qO2QE8Hk0HgEsl\nbQKQNArcDDzW+oSIeDEijqyk0b0+ZNSNAnfuIZhZ3joJhCuBV1oeH0u2dXrMg8B9wMoH1Nv06loI\nqa70ELyespnlLNNJZUm3ACcj4tAqXmOnpIOSDp46dQooTw9hNYEwMT3PYH8fQwO9Vd7bzKqrk0A4\nDmxueTyabOvkmLcBt0o6SnOo6QZJTyyngRHxaESMRcTYxo0bgd6fVO7GusqT03XPH5hZrjoJhGeB\nrZKukjQI3AbsbTtmL3BncrfR9cBERJyIiAciYjQitiTPeyYi7lhto6dm6khwyWBvBkI3egjN0te9\neX5mVk1LBkJE1IF7gKdp3in0iYg4LGmXpF3JYfuAl4Fx4KPA+5d6XUnvlnQM+DHgv0t6utNGp2sh\n9PXoSmJDA30M1LSqSeXJmXnPH5hZrjr6EzQi9tG86Ldu293yewB3L/Ea+4H9LY8/BXyq86ae0+tV\nQCWtusDdxPQ8l10y2MVWmZldWCm/qXy6h+sYpVZb4M6rpZlZ3koZCL1c2C41MrT6HkIv94LMrHrK\nGQiz8z25nnKr1RS4iwgmZ+ruIZhZrsoZCD28FkJqNUNG355rVnN1YTszy1OJA6G3L5YbhvtXHAgu\nW2FmRShdIDQXx5nv/R5CMofQvAFreVzYzsyKULpAmK03mF+IEvQQBqg3gjNzC8t+rnsIZlaE0gXC\n2aJvPR4II6uoeHq2h+BAMLMclS4QzhW26+2L5WrKV7iHYGZFKHEg9HgPYRUF7np9ASAzq6YSBkJv\nr4WQWm0PQer90DOzailhIJSjh3B21bQVBMLk9Dzre7h4n5lVUwkDobfXQkilXypbSQ9hctqVTs0s\nfyUMhHJMKqftW9FdRjMubGdm+StdIKQTrr1ey6jWJ9av6V/xHIInlM0sb6ULhKmZZmG7WgnG15v1\njJZ/l9GES1+bWQFKGAi9X8coNbLCRXImp+subGdmuSthIMyXJhBWWuDOPQQzK0IJA6H3S1+nRoYG\nlj2pPFdvMD2/4DkEM8tdR4Eg6UZJRySNS7p/kf2S9FCy/wVJ17btr0l6TtJTLdsuk/QZSX+T/Pua\nTtpSpiGjlayrnAbIhrUOBDPL15KBIKkGPAxsB7YBt0va1nbYdmBr8rMTeKRt/73Ai23b7gf+LCK2\nAn+WPF5SGUpfp1aySI5LX5tZUTrpIVwHjEfEyxExBzwJ7Gg7ZgfweDQdAC6VtAlA0ihwM/DYIs/5\nWPL7x4Cf7qTBp2fL1UP49twC8wuNjp/jwnZmVpROAuFK4JWWx8eSbZ0e8yBwH9B+VbwiIk4kv38d\nuKKTBk+WbMgIzn2ZrhNnC9s5EMwsZ5lOKku6BTgZEYcudFw0lxVbdGkxSTslHZR08NSpU8zVG6zv\n8S+lpVZSvuJcD6Ec52hm1dFJIBwHNrc8Hk22dXLM24BbJR2lOdR0g6QnkmNebRlW2gScXOzNI+LR\niBiLiLHXvPZyoPfLVqRWUuDOi+OYWVE6CYRnga2SrpI0CNwG7G07Zi9wZ3K30fXARESciIgHImI0\nIrYkz3smIu5oec77kt/fB3x6qYYsNJqdiLIMGaUTwyvpIXhS2czytuSVNSLqku4BngZqwJ6IOCxp\nV7J/N7APuAkYB84Ad3Xw3h8CPiHpnwBfBX5mqSc0zgZCOS6WG1awjObkzDxr+vsYGqhl1Swzs0V1\n9Kd2ROyjedFv3ba75fcA7l7iNfYD+1se/y3wE503FRaiZD2EFSyS49LXZlaUUn1TuVGyIaOVrJrm\nshVmVpRSBULaQyjL+Pqa/j4Ga33Lqng6OV1npCSBZ2bVUq5AKFkPQdKyK566h2BmRSllIPT64jit\nRob7lz2p7DkEMytCqQKhEbB2sEZ/rTzN3rDMekbuIZhZUcpzZaXZQyjLcFFqOYEQEUw6EMysIKW6\nujYiSvMdhNTI0AB/Mf4N3vHhzy55bBA0ojyT5mZWLaUKhDL2EH72rd+3rPWfr79K/NQPfk+GLTIz\nW1yprq7NQCjXX89vfcNreesbXlt0M8zMllSqOYTmkFGpMszMrDRKFQgLjfCXtszMMlK6QCjbkJGZ\nWVmUKhACSrM4jplZ2ZQqEKA8ZSvMzMqmhIHgISMzsyyULhDWuYdgZpaJ0gWCh4zMzLJRukBwWQcz\ns2yULhDcQzAzy0ZHgSDpRklHJI1Lun+R/ZL0ULL/BUnXJtuHJP2VpC9KOizpX7c852pJfynpS5L+\nSNJIJ23xpLKZWTaWDARJNeBhYDuwDbhd0ra2w7YDW5OfncAjyfZZ4IaIuBq4BrhR0vXJvseA+yPi\nh4BPAb/cSYPdQzAzy0YnPYTrgPGIeDki5oAngR1tx+wAHo+mA8ClkjYlj08nxwwkP5E8fiPw58nv\nnwHes1RDJBgo0eI4ZmZl0snV9UrglZbHx5JtHR0jqSbpeeAk8JmI+HxyzGHOBct7gc1LNaSmzstI\nm5nZ8mT+53ZELETENcAocJ2kNye7fh54v6RDwHpgbrHnS9op6aCkgxGNrJtrZnbR6iQQjvOdf72P\nJtuWdUxEfAv4LHBj8viliHhXRLwF+H3gfy/25hHxaESMRcTYYL/nD8zMstJJIDwLbJV0laRB4DZg\nb9sxe4E7k7uNrgcmIuKEpI2SLgWQNAz8JPBS8vh1yb99wK8Bu5dqyHJWHjMzs+VZ8k/uiKhLugd4\nGqgBeyLisKRdyf7dwD7gJmAcOAPclTx9E/Cx5E6lPuATEfFUsu92SXcnv38S+N2l2rLOlU7NzDKj\niFj6qB4xNjYWBw8eLLoZZmalIulQRIwtdZzv4TQzM8CBYGZmCQeCmZkBDgQzM0s4EMzMDHAgmJlZ\nwoFgZmaAA8HMzBKl+mKapCngSNHtyMHlwDeKbkTGLoZzBJ9n1ZT1PF8fERuXOqhstSCOdPJtu7Jr\nVnat9nleDOcIPs+qqfp5esjIzMwAB4KZmSXKFgiPFt2AnFwM53kxnCP4PKum0udZqkllMzPLTtl6\nCGZmlpFSBIKkGyUdkTQu6f6i25MVSUclfUnS85Iqs/CDpD2STkr6csu2yyR9RtLfJP++psg2dsN5\nzvPXJR1PPtPnJd1UZBtXS9JmSZ+V9BVJhyXdm2yv1Od5gfOs1OfZrueHjJLV1v6a5vKbx2gu6Xl7\nRHyl0IZlQNJRYCwiynif83lJegdwGng8It6cbPsw8M2I+FAS8q+JiH9RZDtX6zzn+evA6Yj4SJFt\n6xZJm4BNEfEFSeuBQ8BPAz9HhT7PC5znz1Chz7NdGXoI1wHjEfFyRMwBTwI7Cm6TLUNE/DnwzbbN\nO4CPJb9/jOZ/tlI7z3lWSkSciIgvJL9PAS8CV1Kxz/MC51lpZQiEK4FXWh4fo7ofTAB/KumQpJ1F\nNyZjV0R1kQAiAAABmElEQVTEieT3rwNXFNmYjP2ipBeSIaVSD6W0krQF+BHg81T482w7T6jo5wnl\nCISLydsj4hpgO3B3MgRRedEct+ztscuVewR4A3ANcAL4rWKb0x2S1gF/AHwgIiZb91Xp81zkPCv5\neabKEAjHgc0tj0eTbZUTEceTf08Cn6I5XFZVrybjtOl47cmC25OJiHg1IhYiogF8lAp8ppIGaF4k\nPx4Rn0w2V+7zXOw8q/h5tipDIDwLbJV0laRB4DZgb8Ft6jpJlySTV0i6BHgX8OULP6vU9gLvS35/\nH/DpAtuSmfQimXg3Jf9MJQn4z8CLEfEfWnZV6vM833lW7fNs1/N3GQEkt3Y9CNSAPRHxGwU3qesk\nvYFmrwCaRQd/ryrnKen3gXfSrBT5KvCvgD8EPgF8H/BV4GciotQTsuc5z3fSHF4I4CjwCy1j7aUj\n6e3A54AvAY1k86/QHF+vzOd5gfO8nQp9nu1KEQhmZpa9MgwZmZlZDhwIZmYGOBDMzCzhQDAzM8CB\nYGZmCQeCmZkBDgQzM0s4EMzMDID/D0EgsrDraOMhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9b6bc39630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = pd.DataFrame(XGB_BOpt.res['all']['params'])\n",
    "error = pd.Series(XGB_BOpt.res['all']['values']) * -1\n",
    "error.name = 'test-error'\n",
    "result = pd.concat([error, result], axis=1)\n",
    "result.head(25)\n",
    "\n",
    "url = plot_rounds(error.plot())\n",
    "slack(\"Bayesian Search: Max params %s\" % XGB_BOpt.res['max'], url)\n",
    "\n",
    "file = 'ALL-bayesian-parameters.csv'\n",
    "result.to_csv(file)\n",
    "slacker.files.upload(file, channels='#progress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
