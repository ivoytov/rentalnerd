{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import os\n",
    "from bayes_opt import BayesianOptimization\n",
    "import xgboost as xgb\n",
    "\n",
    "# data columns used for the booster\n",
    "factors = ['property_id', 'bedrooms', 'bathrooms', 'sqft','longitude', 'latitude','zipcode', 'elevation', 'garage'\n",
    "                          ,'year_built', 'level','dist_to_park','dist_to_golf_course', 'has_pool'\n",
    "                          ,'date_closed','multifamily', 'hoa_fees', 'lot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def XGBcv(max_depth, gamma, min_child_weight, max_delta_step, subsample, colsample_bytree, alpha):\n",
    "    folds = 5\n",
    "    paramt = {\n",
    "        'alpha': max(alpha, 0)\n",
    "        'gamma': max(gamma, 0),\n",
    "        'max_depth': int(max_depth),\n",
    "        'eta': 0.1,\n",
    "        'objective': 'reg:linear',\n",
    "        'silent': True,\n",
    "        'subsample': max(min(subsample, 1), 0),\n",
    "        'colsample_bytree': max(min(colsample_bytree, 1), 0),\n",
    "        'min_child_weight': int(min_child_weight),\n",
    "        'max_delta_step': max_delta_step.astype(int),\n",
    "        'seed': 2017,\n",
    "        'updater': 'grow_gpu' \n",
    "    }\n",
    "\n",
    "    print(\" Search parameters (%d-fold validation):\\n %s\" % (folds, paramt), file=log_file)\n",
    "\n",
    "    out = xgb.cv(paramt,\n",
    "           dtrain,\n",
    "           num_boost_round=20000,\n",
    "           nfold=folds,\n",
    "           verbose_eval=None,\n",
    "           metrics=\"mae\",\n",
    "           show_stdv=True,\n",
    "           callbacks=[xgb.callback.early_stop(50)])\n",
    "    \n",
    "    print(out, file=log_file)\n",
    "    \n",
    "    return -out['test-mae-mean'].values[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Bayesian Optimization ...\n",
      "\n",
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m----------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   subsample | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1 | 278m09s | \u001b[35m-192045.00625\u001b[0m | \u001b[32m            0.7340\u001b[0m | \u001b[32m   1.9498\u001b[0m | \u001b[32m          1.8635\u001b[0m | \u001b[32m     9.7687\u001b[0m | \u001b[32m            6.3913\u001b[0m | \u001b[32m     0.6269\u001b[0m | \n",
      "    2 | 170m37s | \u001b[35m-188049.21094\u001b[0m | \u001b[32m            0.2010\u001b[0m | \u001b[32m   1.2642\u001b[0m | \u001b[32m          3.4389\u001b[0m | \u001b[32m     8.9223\u001b[0m | \u001b[32m            9.9119\u001b[0m | \u001b[32m     0.5487\u001b[0m | \n",
      "    3 | 188m06s | \u001b[35m-186046.62812\u001b[0m | \u001b[32m            0.5770\u001b[0m | \u001b[32m   0.9262\u001b[0m | \u001b[32m          4.8631\u001b[0m | \u001b[32m     8.1638\u001b[0m | \u001b[32m            9.9059\u001b[0m | \u001b[32m     0.5769\u001b[0m | \n",
      "    4 | 04m34s | \u001b[35m-23304.43184\u001b[0m | \u001b[32m            0.4152\u001b[0m | \u001b[32m   1.4671\u001b[0m | \u001b[32m          0.8429\u001b[0m | \u001b[32m    14.1423\u001b[0m | \u001b[32m            1.1963\u001b[0m | \u001b[32m     0.6040\u001b[0m | \n",
      "    5 | 04m40s | -28375.83184 |             0.5698 |    1.8337 |           0.1558 |      6.8217 |             4.3094 |      0.8065 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m----------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   subsample | \n",
      "    6 | 04m00s | -34374.63789 |             0.4310 |    1.8947 |           0.0000 |      4.0251 |             1.2633 |      1.0000 | \n",
      "    7 | 04m23s | -41138.09258 |             0.2000 |    0.0001 |           0.0000 |     15.0000 |             1.0000 |      1.0000 | \n",
      "    8 | 05m24s | -28838.09961 |             0.5375 |    1.8811 |           0.0000 |      5.9396 |             3.5262 |      0.8554 | \n"
     ]
    }
   ],
   "source": [
    "log_file = open(\"xgboost_parameter_tuning.log\", 'a')\n",
    "\n",
    "fast_params = {'max_depth': (4, 6),\n",
    "                'gamma': (0.0001, 0.005),\n",
    "                'min_child_weight': (1, 2),\n",
    "                'max_delta_step': (0, 1),\n",
    "                'subsample': (0.2, 0.4),\n",
    "                'colsample_bytree': (0.2, 0.4),\n",
    "                'alpha': (0, 10)\n",
    "                }\n",
    "\n",
    "slow_params = { 'max_depth': (5, 15),\n",
    "                 'gamma': (0.0, 10.0),\n",
    "                 'min_child_weight': (1, 20),\n",
    "                 'max_delta_step': (0, 5),\n",
    "                 'subsample': (0.5, 1.0),\n",
    "                 'colsample_bytree' :(0.1, 1.0),\n",
    "                 'alpha': (0, 10)\n",
    "               }\n",
    "\n",
    "# params = fast_params\n",
    "params = slow_params\n",
    "\n",
    "XGB_BOpt = BayesianOptimization(XGBcv, params)\n",
    "\n",
    "df = pd.read_csv('CSV_backups/PH-sales.csv')\n",
    "dtrain = xgb.DMatrix(df[factors].values, label=df.price, feature_names=factors)\n",
    "\n",
    "print('\\nRunning Bayesian Optimization ...\\n')\n",
    "XGB_BOpt.maximize(init_points=5, n_iter=25)\n",
    "\n",
    "print('\\nFinal Results')\n",
    "print('XGBOOST: %f' % XGB_BOpt.res['max']['max_val'])\n",
    "print('\\nFinal Results', file=log_file)\n",
    "print('XGBOOST: %f' % XGB_BOpt.res['max']['max_val'], file=log_file)\n",
    "log_file.flush()\n",
    "log_file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
