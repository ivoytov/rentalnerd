{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sql extension is already loaded. To reload it, use:\n",
      "  %reload_ext sql\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Connected: prod@rental_nerd'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext sql\n",
    "\n",
    "# imports\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import math\n",
    "\n",
    "# today's date for output filenames\n",
    "today = (dt.date.today() - dt.date(2000, 1, 1)).days\n",
    "\n",
    "# %sql mysql://root@localhost/rental_nerd\n",
    "%sql mysql://prod:nerd@52.2.153.189/rental_nerd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def top_zipcodes(n = 100):\n",
    "    # query the top 100 zipcodes in the database (roughly equal to all zipcodes >10k properties)\n",
    "    query = %sql (\\\n",
    "    SELECT zipcode, COUNT(id) \\\n",
    "    FROM properties \\\n",
    "    GROUP BY zipcode \\\n",
    "    ORDER BY 2 DESC \\\n",
    "    limit :n)\n",
    "\n",
    "    zipcode_filter = query.DataFrame()\n",
    "#     print(\"Top zipcode by count is\",zipcode_filter.iloc[0,0],\"with\",zipcode_filter.iloc[0,1],\"properties\")\n",
    "#     print(\"100th zipcode by count is\",zipcode_filter.iloc[99,0],\"with\",zipcode_filter.iloc[99,1],\"properties\")\n",
    "    return zipcode_filter.zipcode.values\n",
    "\n",
    "def city_query():\n",
    "    query = %sql (\\\n",
    "    SELECT city_code, COUNT(id) \\\n",
    "    FROM property_transaction_logs \\\n",
    "    GROUP BY city_code \\\n",
    "    ORDER BY 2 DESC \\\n",
    "    limit 100)\n",
    "    return query.DataFrame().city_code.values\n",
    "\n",
    "def sanitize(data):\n",
    "    # abort if the city has no top zipcodes\n",
    "    if data.empty:\n",
    "        return 0    \n",
    "    data.fillna(value=0, inplace=True)\n",
    "    \n",
    "    data.drop(['abnormal', 'bookmarked', 'created_at', 'ignore', 'closed_diff_id', 'id', 'listed_diff_id',\n",
    "                      'notes', 'source', 'updated_at', 'home_type', 'sfh', 'description', \n",
    "                    'event_name', 'pended', 'neighborhood'], axis=1, inplace=True)\n",
    "    \n",
    "    # fills in some sensible defaults where data is missing\n",
    "    data[\"near_golf_course\"] = data[\"near_golf_course\"].apply(lambda x: True if x == 1.0 else False)\n",
    "    data[\"has_pool\"] = data[\"has_pool\"].apply(lambda x: True if x == 1.0 else False)\n",
    "    data[\"is_latest\"] = data[\"is_latest\"].apply(lambda x: True if x == 1.0 else False)\n",
    "    data[\"garage\"] = data[\"garage\"].apply(lambda x: True if x == 1.0 else False)\n",
    "    data[\"adult\"] = data[\"adult\"].apply(lambda x: True if x == 1.0 else False)\n",
    "    data[\"construction\"] = data[\"construction\"].apply(lambda x: True if x == 1.0 else False)\n",
    "    data[\"townhouse\"] = data[\"townhouse\"].apply(lambda x: True if x == 1.0 else False)\n",
    "    data[\"mobile\"] = data[\"mobile\"].apply(lambda x: True if x == 1.0 else False)\n",
    "    data[\"fsbo\"] = data[\"fsbo\"].apply(lambda x: True if x == 1.0 else False)\n",
    "    \n",
    "    data['date_closed'] = data['date_closed'].apply(lambda x: 0 if (x == 0) else (x - dt.date(2000, 1, 1)).days)\n",
    "    data['date_closed'] = data['date_closed'].astype(int)\n",
    "    \n",
    "    data['date_listed'] = data['date_listed'].apply(lambda x: 0 if (x == 0) else (x - dt.date(2000, 1, 1)).days)\n",
    "    data['date_listed'] = data['date_listed'].astype(int)\n",
    "    \n",
    "    data[\"fixer\"] = data[\"fixer\"].apply(lambda x: True if x == 1.0 else False)\n",
    "    data[\"foreclosure\"] = data[\"foreclosure\"].apply(lambda x: True if x == 1.0 else False)\n",
    "\n",
    "    data[\"school_district_id\"] = data[\"school_district_id\"].astype(str)\n",
    "    data['year_built'] = data['year_built'].apply(lambda x: 1980 if math.isnan(x) else x)\n",
    "\n",
    "    data['lot'] = data['lot'].apply(lambda x: int(0 if x is None else x))\n",
    "    data['hoa_fees'] = data['hoa_fees'].apply(lambda x: int(0 if x is None else x))\n",
    "    data['rooms'] = data['rooms'].apply(lambda x: int(0 if x is None else x))\n",
    "    data['saves'] = data['saves'].apply(lambda x: int(0 if x is None else x))\n",
    "    data['stories'] = data['stories'].apply(lambda x: int(0 if x is None else x))\n",
    "    \n",
    "    # convert to km\n",
    "    data['dist_to_lightrail_station'] = data['dist_to_lightrail_station'].apply(lambda x: x * 100) \n",
    "    data['dist_to_lightrail_line'] = data['dist_to_lightrail_line'].apply(lambda x: x * 100) \n",
    "    data['dist_to_hiway'] = data['dist_to_hiway'].apply(lambda x: x * 100) \n",
    "    data['dist_to_waterway'] = data['dist_to_waterway'].apply(lambda x: x * 100) \n",
    "    data['dist_to_airport'] = data['dist_to_airport'].apply(lambda x: x * 100) \n",
    "    data['dist_to_starbucks'] = data['dist_to_starbucks'].apply(lambda x: x * 100) \n",
    "    data['dist_to_railway'] = data['dist_to_railway'].apply(lambda x: x * 100) \n",
    "    data['dist_to_park'] = data['dist_to_park'].apply(lambda x: x * 100) \n",
    "    data['dist_to_shopping'] = data['dist_to_shopping'].apply(lambda x: x * 100) \n",
    "    \n",
    "    \n",
    "    # convert the area name into dummy variables\n",
    "    dm = pd.get_dummies(data[['city_code', 'zipcode','school_district_id']], prefix=['city_code','zipcode','school_district_id'])\n",
    "    data = pd.concat([data, dm], axis=1)\n",
    "    del dm\n",
    "    \n",
    "    return data\n",
    "\n",
    "def query(city=\"%\", zipcode=None, limit=100, start_date=\"2000-01-01 10:01:13\", ttype='sales'):\n",
    "    # convert array of zipcodes into sql string which looks like a tuple\n",
    "    placeholders = tuple(zipcode)\n",
    "    \n",
    "    # sql query helper function\n",
    "    query = %sql (\\\n",
    "    SELECT  \\\n",
    "    *, \\\n",
    "    properties.id as 'property_id', \\\n",
    "    property_transaction_logs.id as 'transaction_id', \\\n",
    "    property_school_districts.school_district_id \\\n",
    "    FROM  \\\n",
    "    property_transaction_logs, \\\n",
    "    properties \\\n",
    "    LEFT JOIN \\\n",
    "    property_school_districts ON property_school_districts.property_id = properties.id \\\n",
    "    where  \\\n",
    "    ( abnormal = false OR abnormal IS NULL OR abnormal = 0 ) and \\\n",
    "    properties.sqft between 500 and 4000 and \\\n",
    "    property_transaction_logs.price between 50000 and 400000 and \\\n",
    "    properties.bedrooms <= 6 and \\\n",
    "    properties.bathrooms <= 6 and \\\n",
    "    properties.home_type = 'sfh' and \\\n",
    "    ((properties.latitude BETWEEN 33.421516 AND 33.665268 and \\\n",
    "    properties.longitude BETWEEN -112.274780 AND -111.810608 ) OR \\\n",
    "    (properties.latitude BETWEEN 33.283149 AND 33.513597 and \\\n",
    "    properties.longitude BETWEEN -111.972656 AND -111.846313 )) and \\\n",
    "    properties.`id` = property_transaction_logs.`property_id` and \\\n",
    "    property_transaction_logs.`city_code` = :city and \\\n",
    "    property_transaction_logs.`transaction_type` = :ttype and \\\n",
    "    (properties.fixer is Null or properties.fixer = False) and \\\n",
    "    (properties.townhouse is Null or properties.townhouse = False) and \\\n",
    "    (properties.foreclosure is Null or properties.foreclosure = False) and \\\n",
    "    (properties.adult is Null or properties.adult = False) and \\\n",
    "    (properties.construction is Null or properties.construction = False) and \\\n",
    "    (properties.mobile is Null or properties.mobile = False) \\\n",
    "    order by \\\n",
    "    property_transaction_logs.id desc \\\n",
    "    limit :limit) \n",
    "    \n",
    "    q = query.DataFrame()\n",
    "    q = q.loc[:,~q.columns.duplicated()]\n",
    "    q.set_index('property_id', inplace=True)\n",
    "    q.index.name = 'property_id'\n",
    "    return q\n",
    "\n",
    "def queue_city_queries(city, zipcode_list, for_sale_zipcode_list):\n",
    "    i = query(city=city, zipcode=zipcode_list, limit=limit,ttype = 'sales',tstatus='closed')\n",
    "    j = query(city=city, zipcode=for_sale_zipcode_list, limit=limit,ttype = 'sales',tstatus='open') \n",
    "    \n",
    "    q = pd.concat([i,j])\n",
    "    q = sanitize(q)\n",
    "    \n",
    "    for_sale = q[(q.transaction_type == \"sales\") & \n",
    "                 (q.transaction_status == \"open\") & \n",
    "                 (q.date_listed > (today - dt.timedelta(days=6000))) &\n",
    "                 (q.zipcode.isin(for_sale_zipcode_list))]\n",
    "    sales = q[(q.transaction_type == \"sales\") & (q.transaction_status == \"closed\")]\n",
    "        \n",
    "    data = {'sales': sales, 'for_sale': for_sale }\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 rows affected.\n",
      "['85375', '85142', '85143', '85326', '85249', '85234', '85086', '85225', '85041', '85204', '85205', '85209', '85295', '85037', '85248', '85233', '85286', '85331', '85224', '85226', '85048', '85022', '85251', '85298', '85018', '85138', '85029', '85051', '85254', '85255', '85302', '85020', '85297', '85323', '85016', '85335', '85388', '85373', '85202', '85027', '85706', '85035', '85257', '85043', '85023', '85203', '85212', '85304', '85303', '85206', '85044', '85392', '85301', '85053', '85374', '85712', '85262']\n"
     ]
    }
   ],
   "source": [
    "# get list of top zipcodes to only run the model on them (put down 2000 to get every zipcode)\n",
    "# we filter the current listings further to only see the top zipcodes to not predict prices in areas with weak coverage\n",
    "focus_zipcodes = top_zipcodes(200)\n",
    "phoenix_zips = list(filter(lambda x: x.startswith('85'), focus_zipcodes))\n",
    "print(phoenix_zips)\n",
    "\n",
    "# limit on number of lines returned from sql queries (for debugging)\n",
    "limit = 200000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "523355 rows affected.\n"
     ]
    }
   ],
   "source": [
    "q = query(city='PH', zipcode=phoenix_zips, limit=limit,ttype = 'sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q = sanitize(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for_sale = q[(q.transaction_type == \"sales\") & \n",
    "             (q.transaction_status == \"open\") & \n",
    "             (q.date_listed > (today - 365)) &\n",
    "             (q.is_latest == True)] \n",
    "sales = q[(q.transaction_type == \"sales\")]\n",
    "\n",
    "for_sale.to_csv('CSV_backups/ALL-for_sale.csv')\n",
    "sales.to_csv('CSV_backups/ALL-sales.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
