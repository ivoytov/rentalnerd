{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import contextlib\n",
    "\n",
    "import os\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# this allows plots to appear directly in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "# data columns used for the booster\n",
    "factors = ['property_id', 'bedrooms', 'bathrooms', 'sqft','longitude', 'latitude','zipcode', 'elevation', 'garage'\n",
    "                          ,'year_built', 'level','dist_to_park','dist_to_golf_course', 'has_pool'\n",
    "                          ,'date_closed','multifamily', 'hoa_fees', 'lot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def XGBcv(max_depth, gamma, min_child_weight, max_delta_step, subsample,\n",
    "          colsample_bytree, folds):\n",
    "    paramt = {\n",
    "        'gamma': gamma,\n",
    "        'booster': 'gbtree',\n",
    "        'max_depth': max_depth.astype(int),\n",
    "        'eta': 0.1,\n",
    "        # Use the line below for classification\n",
    "        'objective': 'reg:linear',\n",
    "        # DO NOT use the line below when doing classification\n",
    "        #'num_class': 12,\n",
    "        'silent': True,\n",
    "        'subsample': subsample,\n",
    "        'colsample_bytree': colsample_bytree,\n",
    "        'min_child_weight': min_child_weight,\n",
    "        'max_delta_step': max_delta_step.astype(int),\n",
    "        'seed': 101,\n",
    "        'updater': 'grow_gpu' \n",
    "    }\n",
    "\n",
    "    cv_score = 0\n",
    "\n",
    "    print(\" Search parameters (%d-fold validation):\\n %s\" % (folds, paramt),\n",
    "          file=log_file)\n",
    "    log_file.flush()\n",
    "\n",
    "    # Do not optimize the number of boosting rounds, as early stopping will take care of that\n",
    "\n",
    "    out = xgb.cv(paramt,\n",
    "           dtrain,\n",
    "           num_boost_round=20000,\n",
    "           stratified=True,\n",
    "           nfold=folds,\n",
    "           verbose_eval=None,\n",
    "           early_stopping_rounds=20,\n",
    "           metrics=\"mae\",\n",
    "           show_stdv=True)\n",
    "    \n",
    "    print(out, file=log_file)\n",
    "    # All relevant things in XGboost output are in stdout, so we screen result[1]\n",
    "    # for a line with \"cv-mean\". This line signifies the end of output and contains CV values.\n",
    "    # Next we split the line to extract CV values. We also print the whole CV run into file\n",
    "\n",
    "    print('', file=log_file)\n",
    "    cv_score = out.iloc[-1]['train-mae-mean']\n",
    "\n",
    "\n",
    "    # The CV metrics function in XGboost can be lots of things. Some of them need to be maximized, like AUC.\n",
    "    # If the metrics needs to be minimized, e.g, logloss, the return line below should be a negative number\n",
    "    # as Bayesian Optimizer only knows how to maximize the function\n",
    "\n",
    "    return (-1.0 * cv_score)\n",
    "\n",
    "def run_bayes_search_for_best_params(city, speed='fast'):\n",
    "    # Create a file to store XGBoost output\n",
    "    # New lines are added to this file rather than overwriting it\n",
    "    log_file = open(\"XGBoost-output-from-BOpt.txt\", 'a')\n",
    "\n",
    "    fast_params = {'max_depth': (4, 6),\n",
    "                    'gamma': (0.0001, 0.005),\n",
    "                    'min_child_weight': (1, 2),\n",
    "                    'max_delta_step': (0, 1),\n",
    "                    'subsample': (0.2, 0.4),\n",
    "                    'colsample_bytree': (0.2, 0.4),\n",
    "                    'folds': 5 }\n",
    "    \n",
    "    slow_params = { 'max_depth': (4, 15),\n",
    "                     'gamma': (0.0001, 2.0),\n",
    "                     'min_child_weight': (1, 10),\n",
    "                     'max_delta_step': (0, 5),\n",
    "                     'subsample': (0.2, 1.0),\n",
    "                     'colsample_bytree' :(0.2, 1.0),\n",
    "                     'folds': 10\n",
    "                   }\n",
    "    \n",
    "    if speed == 'fast':\n",
    "        params = fast_params\n",
    "    else:\n",
    "        params = slow_params\n",
    "    \n",
    "    XGB_BOpt = BayesianOptimization(XGBcv, params)\n",
    "\n",
    "    df = pd.read_csv('CSV_backups/' + city + '-sales.csv')\n",
    "    dtrain = xgb.DMatrix(df[factors].values, label=df.price, feature_names=factors)\n",
    "\n",
    "\n",
    "    print('\\n', file=log_file)\n",
    "    log_file.flush()\n",
    "\n",
    "    print('Running Bayesian Optimization ...\\n')\n",
    "    XGB_BOpt.maximize(init_points=5, n_iter=5)\n",
    "\n",
    "    print('\\nFinal Results')\n",
    "    print('XGBOOST: %f' % XGB_BOpt.res['max']['max_val'])\n",
    "    print('\\nFinal Results', file=log_file)\n",
    "    print('XGBOOST: %f' % XGB_BOpt.res['max']['max_val'], file=log_file)\n",
    "    log_file.flush()\n",
    "    log_file.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Bayesian Optimization ...\n",
      "\n",
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m----------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |     folds |     gamma |   max_delta_step |   max_depth |   min_child_weight |   subsample | \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-cf734faacec5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_bayes_search_for_best_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PH'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fast'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-ca385fdaf41f>\u001b[0m in \u001b[0;36mrun_bayes_search_for_best_params\u001b[0;34m(city, speed)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Running Bayesian Optimization ...\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mXGB_BOpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nFinal Results'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilya/anaconda3/lib/python3.6/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0my_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilya/anaconda3/lib/python3.6/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(self, init_points)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;31m# Generate random points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         l = [np.random.uniform(x[0], x[1], size=init_points)\n\u001b[0;32m---> 91\u001b[0;31m              for x in self.bounds]\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;31m# Concatenate new random points to possible existing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilya/anaconda3/lib/python3.6/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;31m# Generate random points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         l = [np.random.uniform(x[0], x[1], size=init_points)\n\u001b[0;32m---> 91\u001b[0;31m              for x in self.bounds]\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;31m# Concatenate new random points to possible existing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "run_bayes_search_for_best_params('PH', 'fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
