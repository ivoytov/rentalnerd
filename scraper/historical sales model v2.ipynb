{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivoytov/.local/lib/python3.4/site-packages/IPython/config.py:13: ShimWarning: The `IPython.config` package has been deprecated. You should import from traitlets.config instead.\n",
      "  \"You should import from traitlets.config instead.\", ShimWarning)\n",
      "/home/ivoytov/.local/lib/python3.4/site-packages/IPython/utils/traitlets.py:5: UserWarning: IPython.utils.traitlets has moved to a top-level traitlets package.\n",
      "  warn(\"IPython.utils.traitlets has moved to a top-level traitlets package.\")\n",
      "/home/ivoytov/.local/lib/python3.4/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/ivoytov/.local/lib/python3.4/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Connected: prod@rental_nerd'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext sql\n",
    "\n",
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit  # for timing models\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# this allows plots to appear directly in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# today's date for output filenames\n",
    "today = dt.date.today()\n",
    "\n",
    "# where to save the xgb models - they get huge so keep them out of any git path\n",
    "path = '/home/ivoytov/rentalnerd-models/'\n",
    "\n",
    "# data columns used for the booster\n",
    "factors = ['property_id', 'bedrooms', 'bathrooms', 'sqft','longitude', 'latitude','zipcode', 'elevation', 'garage'\n",
    "                          ,'year_built', 'level','dist_to_park','dist_to_golf_course', 'has_pool'\n",
    "                          ,'date_closed','multifamily', 'hoa_fees', 'lot']\n",
    "\n",
    "# booster parameters\n",
    "param = {'verbose': 1, 'max_depth':6, 'num_parallel_tree': 10000, 'eval_metric':'mae' }\n",
    "num_round = 20\n",
    "plst = param.items()\n",
    "\n",
    "# slack webhook secret url\n",
    "webhook_url = 'https://hooks.slack.com/services/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'\n",
    "\n",
    "# disable warning on assignment without copy\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "# %sql mysql://root@localhost/rental_nerd\n",
    "%sql mysql://prod:nerd@52.2.153.189/rental_nerd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sanitize(data, zipcode_list = None):\n",
    "    # abort if the city has no top zipcodes\n",
    "    if data.empty:\n",
    "        return 0    \n",
    "    \n",
    "    # filters out any non-sensical values or fat finger mistakes in MLS listings\n",
    "    print(\"Entries before filter: \", len(data))\n",
    "\n",
    "    if(data.transaction_type.iloc[0] == 'sales'):\n",
    "        data = data[ data.price > 50000 ]\n",
    "    else:\n",
    "        data = data [ data.price > 500 ]\n",
    "    \n",
    "    if(zipcode_list is not None):\n",
    "        data = data[data.zipcode.isin(zipcode_list)]\n",
    "\n",
    "    print(\"Entries after filter: \",len(data))\n",
    "    \n",
    "    # fills in some sensible defaults where data is missing\n",
    "    data[\"near_golf_course\"] = data[\"near_golf_course\"].apply(lambda x: True if x == 1.0 else False)\n",
    "    data[\"has_pool\"] = data[\"has_pool\"].apply(lambda x: True if x == 1.0 else False)\n",
    "    data[\"garage\"] = data[\"garage\"].apply(lambda x: True if x == 1.0 else False)\n",
    "    data[\"multifamily\"] = data[\"home_type\"].apply(lambda x: True if x == \"mfh\" else False)\n",
    "    data['date_closed'] = data['date_closed'].apply(lambda x: (x - dt.date(2000, 1, 1)))\n",
    "    data['date_closed'] = data['date_closed'].astype(int)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def query_for_sale(city, zipcode, limit):\n",
    "    # convert array of zipcodes into sql string which looks like a tuple\n",
    "    placeholders = tuple(zipcode)\n",
    "    \n",
    "    # sql query helper function\n",
    "    query = %sql (\\\n",
    "    select  \\\n",
    "    *  \\\n",
    "    from  \\\n",
    "    properties, \\\n",
    "    property_transaction_logs, \\\n",
    "    area_name_zipcodes \\\n",
    "    where  \\\n",
    "    properties.sqft between 1 and 10000 and \\\n",
    "    property_transaction_logs.price between 500 and 400000 and \\\n",
    "    properties.bedrooms <= 6 and \\\n",
    "    properties.bathrooms <= 6 and \\\n",
    "    properties.home_type = 'sfh' and \\\n",
    "    area_name_zipcodes.`area_name` LIKE :city and \\\n",
    "    area_name_zipcodes.`zipcode` = properties.`zipcode` and     \\\n",
    "    properties.zipcode IN :placeholders and \\\n",
    "    properties.`id` = property_transaction_logs.`property_id` and \\\n",
    "    property_transaction_logs.`transaction_status` = 'open' and \\\n",
    "    property_transaction_logs.`transaction_type` = 'sales' and \\\n",
    "    property_transaction_logs.`is_latest` = true \\\n",
    "    order by \\\n",
    "    property_transaction_logs.id desc \\\n",
    "    limit :limit) \n",
    "\n",
    "    return query.DataFrame().T.groupby(level=0).first().T\n",
    "\n",
    "def query(transaction_type, transaction_status, city, zipcode, limit, start_date=\"2000-01-01 10:01:13\", end_date=today):\n",
    "    # convert array of zipcodes into sql string which looks like a tuple\n",
    "    placeholders = tuple(zipcode)\n",
    "    \n",
    "    # sql query helper function\n",
    "    query = %sql (\\\n",
    "    select  \\\n",
    "    *  \\\n",
    "    from  \\\n",
    "    properties, \\\n",
    "    property_transaction_logs, \\\n",
    "    area_name_zipcodes \\\n",
    "    where  \\\n",
    "    properties.sqft between 1 and 10000 and \\\n",
    "    property_transaction_logs.price between 500 and 400000 and \\\n",
    "    properties.bedrooms <= 6 and \\\n",
    "    properties.bathrooms <= 6 and \\\n",
    "    properties.home_type = 'sfh' and \\\n",
    "    property_transaction_logs.date_closed > :start_date and \\\n",
    "    property_transaction_logs.date_closed < :end_date and \\\n",
    "    area_name_zipcodes.`area_name` LIKE :city and \\\n",
    "    area_name_zipcodes.`zipcode` = properties.`zipcode` and     \\\n",
    "    properties.zipcode IN :placeholders and \\\n",
    "    properties.`id` = property_transaction_logs.`property_id` and \\\n",
    "    property_transaction_logs.`transaction_status` = :transaction_status and \\\n",
    "    property_transaction_logs.`transaction_type` = :transaction_type and \\\n",
    "    property_transaction_logs.`is_latest` = true \\\n",
    "    order by \\\n",
    "    property_transaction_logs.id desc \\\n",
    "    limit :limit) \n",
    "\n",
    "    return query.DataFrame().T.groupby(level=0).first().T\n",
    "\n",
    "def output_model_metrics( x, ypred, y_known, t ):\n",
    "    #Print model report:\n",
    "    mae = metrics.mean_absolute_error(y_known, ypred)\n",
    "    r2 = metrics.explained_variance_score(y_known, ypred)\n",
    "  \n",
    "    slack(\"Model Report: %s \\n n: %i \\n MAE Score: %f \\n R^2: %f\" % (t, len(y_known), mae, r2))\n",
    "\n",
    "def top_zipcodes(n = 100):\n",
    "    # query the top 100 zipcodes in the database (roughly equal to all zipcodes >10k properties)\n",
    "    query = %sql (\\\n",
    "    SELECT zipcode, COUNT(id) \\\n",
    "    FROM properties \\\n",
    "    GROUP BY zipcode \\\n",
    "    ORDER BY 2 DESC \\\n",
    "    limit :n)\n",
    "\n",
    "    zipcode_filter = query.DataFrame()\n",
    "    print(\"Top zipcode by count is\",zipcode_filter.iloc[0,0],\"with\",zipcode_filter.iloc[0,1],\"properties\")\n",
    "    print(\"100th zipcode by count is\",zipcode_filter.iloc[99,0],\"with\",zipcode_filter.iloc[99,1],\"properties\")\n",
    "    return zipcode_filter.zipcode.values\n",
    "\n",
    "\n",
    "def city_query():\n",
    "    query = %sql (\\\n",
    "    SELECT area_name, COUNT(id) \\\n",
    "    FROM area_name_zipcodes \\\n",
    "    GROUP BY area_name \\\n",
    "    ORDER BY 2 DESC \\\n",
    "    limit 100)\n",
    "    return query.DataFrame().area_name.values\n",
    "\n",
    "def slack(text):\n",
    "    print(\"Slacking: \" + text)\n",
    "    response = requests.post(webhook_url, data=json.dumps({\"text\": text}), headers={'Content-Type': 'application/json'})\n",
    "    if response.status_code != 200:\n",
    "        raise ValueError('Request to slack returned an error %s, the response is:\\n%s' % (response.status_code, response.text))\n",
    "\n",
    "def queue_city_queries(city, cut_off_date, zipcode_list):\n",
    "    # call all of the needed queries so SQL server can go to sleep (connection can be dropped)\n",
    "    sales_train = query('sales', 'closed', city, zipcode_list, limit, \"2000-01-01 10:01:13\", cut_off_date)\n",
    "    sales_test = query('sales', 'closed', city, zipcode_list, limit, cut_off_date, today)\n",
    "    for_sale = query_for_sale(city, zipcode_list, limit)\n",
    "    rent_train = query('rental','closed', city,zipcode_list, limit, \"2000-01-01 10:01:13\", cut_off_date)\n",
    "    rent_test = query('rental','closed', city,zipcode_list, limit, cut_off_date, today)\n",
    "        \n",
    "    # use today's date for 'close date' since the transaction is still open i.e. home is currently listed for sale\n",
    "    for_sale.date_closed = today\n",
    "\n",
    "    data = {'sales_train': sales_train, 'sales_test': sales_test\n",
    "            , 'rent_train': rent_train, 'rent_test': rent_test, 'for_sale': for_sale }\n",
    "    \n",
    "    for k, v in data.items():\n",
    "        if v.empty:\n",
    "            print('no rows returned for key', k, 'in city: ', city)\n",
    "            return 0\n",
    "        data[k] = sanitize(v, zipcode_list)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def train_model(train, test, factors):\n",
    "    dtrain = xgb.DMatrix(train[factors].values, label=train.price, feature_names=factors)\n",
    "    dtest = xgb.DMatrix(test[factors].values, label=test.price, feature_names=factors)\n",
    "    watchlist  = [(dtest,'eval'), (dtrain,'train')]\n",
    "\n",
    "    bst = xgb.train( plst, dtrain, num_round, watchlist, early_stopping_rounds = 3 )\n",
    "    \n",
    "    if hasattr(bst, 'best_score'):\n",
    "        slack(\"Early stopping occured, best_score %f, best_iteration %i\" % (bst.best_score, bst.best_iteration))\n",
    "\n",
    "    # predict the training set using the model - note this is in sample testing\n",
    "    ypred = bst.predict(dtrain)\n",
    "    output_model_metrics( dtrain, ypred, train.price, 'train' )\n",
    "\n",
    "    # predict the testing set using the model - note this is in sample testing\n",
    "    ypred = bst.predict(dtest)\n",
    "    output_model_metrics( dtest, ypred, test.price, 'test' )\n",
    "    \n",
    "    return bst\n",
    "        \n",
    "def generate_city_model(data):\n",
    "    # train model based on historical sales information\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    bst = train_model(data['sales_train'], data['sales_test'], factors)\n",
    "    \n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    slack(\"Calculated sales model for %s; time to train: %f hours\" % (city, (elapsed / 3600)))\n",
    "    \n",
    "    target = xgb.DMatrix( data['for_sale'][factors].values, feature_names=factors)\n",
    "    ypred = bst.predict(target)\n",
    "\n",
    "    values = np.column_stack((data['for_sale'].property_id.values\n",
    "                             ,data['for_sale'].address.values\n",
    "                             ,ypred\n",
    "                             ,data['for_sale'].price.values\n",
    "                             ,ypred-data['for_sale'].price))\n",
    "    output = pd.DataFrame(values[:,1:],index=values[:,0],columns=['address','ypred','list','gain-loss'])\n",
    "    output = output.sort_values(by='gain-loss',ascending=False)\n",
    "\n",
    "    # train rental model\n",
    "    start_time = timeit.default_timer() # start timer\n",
    "    rent_bst = train_model(data['rent_train'], data['rent_test'], factors)\n",
    "    \n",
    "    elapsed = timeit.default_timer() - start_time # end timer\n",
    "    slack(\"Calculated rental model for %s; time to train: %f hours\" % (city, (elapsed / 3600)))\n",
    "\n",
    "    # predict rent prices for home that are listed for sale\n",
    "    ypred = rent_bst.predict(target)\n",
    "    ypred = pd.Series(ypred,index=output.index)\n",
    "    ypred.name = \"rent\"\n",
    "\n",
    "    # calculate estimated cap rate\n",
    "    cr = ypred * 12 / output.list\n",
    "    cr.name = \"cap rate\"\n",
    "\n",
    "    # combine rent predictions to homes listed for sale\n",
    "    best_of = pd.concat([output,ypred, cr],axis=1)\n",
    "\n",
    "    # save target list\n",
    "    best_of.to_csv(city+'_target_list.csv')\n",
    "\n",
    "    # save model\n",
    "    bst.save_model(path +  city.lower() + '_sales_' + today.strftime('%Y%m%d') + '.model')\n",
    "\n",
    "    # save rental model\n",
    "    rent_bst.save_model(path + city.lower() + '_rent_' + today.strftime('%Y%m%d') + '.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1185 rows affected.\n",
      "Top zipcode by count is 94565 with 18730 properties\n",
      "100th zipcode by count is 89147 with 9682 properties\n",
      "11 rows affected.\n",
      "Order of city models to run: ['BAY_AREA' 'HOUSTON' 'PH' 'VEGAS' 'DENVER' 'ST_LOUIS' 'SEATTLE' 'SF'\n",
      " 'PORTLAND' 'TUSCON' 'DETROIT']\n"
     ]
    }
   ],
   "source": [
    "# get list of top zipcodes to only run the model on them\n",
    "zipcode_list = top_zipcodes(20000)\n",
    "\n",
    "\n",
    "# limit on number of lines returned from sql queries (for debugging)\n",
    "limit = 10000000\n",
    "\n",
    "cut_off_date = (today - dt.timedelta(6*365/12)).isoformat()\n",
    "\n",
    "# get list of all available cities\n",
    "cities = city_query()\n",
    "print(\"Order of city models to run:\", cities)\n",
    "city_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running queries for city BAY_AREA\n",
      "170045 rows affected.\n",
      "6040 rows affected.\n",
      "13997 rows affected.\n",
      "35239 rows affected.\n",
      "2113 rows affected.\n",
      "Entries before filter:  2113\n",
      "Entries after filter:  2113\n",
      "Entries before filter:  35239\n",
      "Entries after filter:  35220\n",
      "Entries before filter:  6040\n",
      "Entries after filter:  5229\n",
      "Entries before filter:  13997\n",
      "Entries after filter:  13587\n",
      "Entries before filter:  170045\n",
      "Entries after filter:  164348\n",
      "Running queries for city HOUSTON\n",
      "122556 rows affected.\n",
      "7052 rows affected.\n",
      "6673 rows affected.\n",
      "26108 rows affected.\n",
      "1649 rows affected.\n",
      "Entries before filter:  1649\n",
      "Entries after filter:  1649\n",
      "Entries before filter:  26108\n",
      "Entries after filter:  26080\n",
      "Entries before filter:  7052\n",
      "Entries after filter:  6419\n",
      "Entries before filter:  6673\n",
      "Entries after filter:  5937\n",
      "Entries before filter:  122556\n",
      "Entries after filter:  106547\n",
      "Running queries for city PH\n",
      "449391 rows affected.\n",
      "16497 rows affected.\n",
      "24627 rows affected.\n",
      "50863 rows affected.\n",
      "5203 rows affected.\n",
      "Entries before filter:  5203\n",
      "Entries after filter:  5203\n",
      "Entries before filter:  50863\n",
      "Entries after filter:  50816\n",
      "Entries before filter:  16497\n",
      "Entries after filter:  15724\n",
      "Entries before filter:  24627\n",
      "Entries after filter:  22283\n",
      "Entries before filter:  449391\n",
      "Entries after filter:  425607\n",
      "Running queries for city VEGAS\n",
      "213009 rows affected.\n",
      "7535 rows affected.\n",
      "19658 rows affected.\n",
      "29326 rows affected.\n",
      "1555 rows affected.\n",
      "Entries before filter:  1555\n",
      "Entries after filter:  1555\n",
      "Entries before filter:  29326\n",
      "Entries after filter:  29296\n",
      "Entries before filter:  7535\n",
      "Entries after filter:  7179\n",
      "Entries before filter:  19658\n",
      "Entries after filter:  18781\n",
      "Entries before filter:  213009\n",
      "Entries after filter:  201831\n",
      "Running queries for city DENVER\n",
      "116556 rows affected.\n",
      "3423 rows affected.\n",
      "1445 rows affected.\n",
      "10457 rows affected.\n",
      "698 rows affected.\n",
      "Entries before filter:  698\n",
      "Entries after filter:  698\n",
      "Entries before filter:  10457\n",
      "Entries after filter:  10449\n",
      "Entries before filter:  3423\n",
      "Entries after filter:  3289\n",
      "Entries before filter:  1445\n",
      "Entries after filter:  1374\n",
      "Entries before filter:  116556\n",
      "Entries after filter:  114239\n",
      "Running queries for city ST_LOUIS\n",
      "79012 rows affected.\n",
      "2172 rows affected.\n",
      "5172 rows affected.\n",
      "6074 rows affected.\n",
      "219 rows affected.\n",
      "Entries before filter:  219\n",
      "Entries after filter:  217\n",
      "Entries before filter:  6074\n",
      "Entries after filter:  6032\n",
      "Entries before filter:  2172\n",
      "Entries after filter:  1737\n",
      "Entries before filter:  5172\n",
      "Entries after filter:  2558\n",
      "Entries before filter:  79012\n",
      "Entries after filter:  62228\n",
      "Running queries for city SEATTLE\n",
      "37939 rows affected.\n",
      "949 rows affected.\n",
      "9155 rows affected.\n",
      "5926 rows affected.\n",
      "429 rows affected.\n",
      "Entries before filter:  429\n",
      "Entries after filter:  429\n",
      "Entries before filter:  5926\n",
      "Entries after filter:  5925\n",
      "Entries before filter:  949\n",
      "Entries after filter:  854\n",
      "Entries before filter:  9155\n",
      "Entries after filter:  9085\n",
      "Entries before filter:  37939\n",
      "Entries after filter:  37195\n",
      "Running queries for city SF\n",
      "696 rows affected.\n",
      "64 rows affected.\n",
      "3 rows affected.\n",
      "805 rows affected.\n",
      "132 rows affected.\n",
      "Entries before filter:  132\n",
      "Entries after filter:  132\n",
      "Entries before filter:  805\n",
      "Entries after filter:  804\n",
      "Entries before filter:  64\n",
      "Entries after filter:  31\n",
      "Entries before filter:  3\n",
      "Entries after filter:  1\n",
      "Entries before filter:  696\n",
      "Entries after filter:  609\n",
      "Running queries for city PORTLAND\n",
      "101542 rows affected.\n",
      "3097 rows affected.\n",
      "3873 rows affected.\n",
      "9997 rows affected.\n",
      "716 rows affected.\n",
      "Entries before filter:  716\n",
      "Entries after filter:  716\n",
      "Entries before filter:  9997\n",
      "Entries after filter:  9989\n",
      "Entries before filter:  3097\n",
      "Entries after filter:  2923\n",
      "Entries before filter:  3873\n",
      "Entries after filter:  3810\n",
      "Entries before filter:  101542\n",
      "Entries after filter:  99039\n",
      "Running queries for city TUSCON\n",
      "15763 rows affected.\n",
      "1174 rows affected.\n",
      "6539 rows affected.\n",
      "2112 rows affected.\n",
      "453 rows affected.\n",
      "Entries before filter:  453\n",
      "Entries after filter:  449\n",
      "Entries before filter:  2112\n",
      "Entries after filter:  2099\n",
      "Entries before filter:  1174\n",
      "Entries after filter:  1089\n",
      "Entries before filter:  6539\n",
      "Entries after filter:  6126\n",
      "Entries before filter:  15763\n",
      "Entries after filter:  14739\n",
      "Running queries for city DETROIT\n",
      "32669 rows affected.\n",
      "1781 rows affected.\n",
      "20149 rows affected.\n",
      "5320 rows affected.\n",
      "796 rows affected.\n",
      "Entries before filter:  796\n",
      "Entries after filter:  780\n",
      "Entries before filter:  5320\n",
      "Entries after filter:  5128\n",
      "Entries before filter:  1781\n",
      "Entries after filter:  347\n",
      "Entries before filter:  20149\n",
      "Entries after filter:  2043\n",
      "Entries before filter:  32669\n",
      "Entries after filter:  6988\n"
     ]
    }
   ],
   "source": [
    "for city in cities:\n",
    "    print(\"Running queries for city\", city)\n",
    "    city_data[city] = queue_city_queries(city, cut_off_date, zipcode_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating model for city BAY_AREA\n"
     ]
    }
   ],
   "source": [
    "for city in cities:\n",
    "    print(\"Generating model for city\", city)\n",
    "    if city_data[city] == 0:\n",
    "        continue\n",
    "    generate_city_model(city_data[city])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "slack(\"Everything completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
