{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Based on: https://github.com/fmfn/BayesianOptimization/blob/master/examples/xgboost_example.py\n",
    "Computes the best parameters for XGB model optimization\n",
    "'''\n",
    "\n",
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "from bayes_opt import BayesianOptimization\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "import os\n",
    "from slacker import Slacker\n",
    "# slack secrets (in your ~/.bashrc)\n",
    "webhook_url = os.environ.get('SLACK_URL')\n",
    "slacker = Slacker(os.environ.get('SLACK_TOKEN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def XGBcv(max_depth, gamma, min_child_weight, max_delta_step, subsample, colsample_bytree, alpha):\n",
    "    folds = 5\n",
    "    paramt = {\n",
    "        'eta': 0.1,\n",
    "        'verbose_eval': None,\n",
    "        'silent': 0,\n",
    "        'objective': 'reg:linear',\n",
    "        'booster': 'gbtree',\n",
    "        'eval_metric': 'mae',\n",
    "        'updater': 'grow_gpu',\n",
    "#         'eta': max(eta, 0),\n",
    "        'max_depth': int(max_depth),\n",
    "        'alpha': max(alpha, 0),\n",
    "        'gamma': max(gamma, 0),\n",
    "        'subsample': max(min(subsample, 1), 0),\n",
    "        'colsample_bytree': max(min(colsample_bytree, 1), 0),\n",
    "        'min_child_weight': int(min_child_weight),\n",
    "        'max_delta_step': int(max_delta_step)\n",
    "    }\n",
    "    \n",
    "    out = xgb.cv(paramt,\n",
    "           dtrain,\n",
    "           num_boost_round=300,\n",
    "           folds=tscv.split(dtrain),\n",
    "           callbacks=[xgb.callback.early_stop(10)])\n",
    "    \n",
    "    output = -out['test-mae-mean'].values[-1]\n",
    "    del out\n",
    "    gc.collect()\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from past experiments\n",
    "{'target': [-207885.453125, -208155.27083333334, -208065.26041666666, -8482.436034999999, -208065.26041666666, -208065.26041666666, -208065.26041666666, -208065.26041666666, -208065.26041666666, -208065.26041666666, -187276.90625, -7297.8352863333339, -187186.921875, -13187.901367333334, -187186.921875, -187186.921875, -187186.921875, -187186.921875, -187186.921875, -187186.921875], 'alpha': [9.609593275137133, 0.6613706829779054, 9.99437912773472, 0.2082503541460734, 9.99437912773472, 9.99437912773472, 9.99437912773472, 9.99437912773472, 9.99437912773472, 9.99437912773472, 9.926950421589801, 8.8964024320545558, 9.9943791277347191, 0.58608203018219007, 9.9943791277347191, 9.9943791277347191, 9.9943791277347191, 9.9943791277347191, 9.9943791277347191, 9.9943791277347191], 'colsample_bytree': [0.3695897782674733, 0.8602917861499724, 0.26467482205195547, 0.2632600769188274, 0.26467482205195547, 0.26467482205195547, 0.26467482205195547, 0.26467482205195547, 0.26467482205195547, 0.26467482205195547, 0.93220963838148418, 0.31851666997270223, 0.26467482205195547, 0.17611852499412145, 0.26467482205195547, 0.26467482205195547, 0.26467482205195547, 0.26467482205195547, 0.26467482205195547, 0.26467482205195547], 'gamma': [9.865587065065188, 9.74686134560233, 6.417811142881344, 9.986369268602083, 6.417811142881344, 6.417811142881344, 6.417811142881344, 6.417811142881344, 6.417811142881344, 6.417811142881344, 0.2500394735324063, 0.52317867353906866, 6.4178111428813436, 0.6138584518188217, 6.4178111428813436, 6.4178111428813436, 6.4178111428813436, 6.4178111428813436, 6.4178111428813436, 6.4178111428813436], 'max_delta_step': [4.319369982200314, 1.4106219539239218, 2.8567339088646717, 0.62666064228038, 2.8567339088646717, 2.8567339088646717, 2.8567339088646717, 2.8567339088646717, 2.8567339088646717, 2.8567339088646717, 1.4850239461478287, 0.46898495419691544, 2.8567339088646717, 0.19645230111910383, 2.8567339088646717, 2.8567339088646717, 2.8567339088646717, 2.8567339088646717, 2.8567339088646717, 2.8567339088646717], 'max_depth': [5.051048152090837, 14.840043411931143, 9.996819662914094, 5.649088797554254, 9.996819662914094, 9.996819662914094, 9.996819662914094, 9.996819662914094, 9.996819662914094, 9.996819662914094, 6.2644943972420322, 14.315316864637497, 9.9968196629140937, 14.195801982264026, 9.9968196629140937, 9.9968196629140937, 9.9968196629140937, 9.9968196629140937, 9.9968196629140937, 9.9968196629140937], 'min_child_weight': [19.90604381074864, 1.5376515645602162, 6.3381577144228505, 19.934027009976592, 6.3381577144228505, 6.3381577144228505, 6.3381577144228505, 6.3381577144228505, 6.3381577144228505, 6.3381577144228505, 1.1124257567329519, 19.960599578245827, 6.3381577144228505, 19.570587168476809, 6.3381577144228505, 6.3381577144228505, 6.3381577144228505, 6.3381577144228505, 6.3381577144228505, 6.3381577144228505], 'subsample': [0.8722713229598846, 0.5416489553632888, 0.7964743895201556, 0.6059873611138029, 0.7964743895201556, 0.7964743895201556, 0.7964743895201556, 0.7964743895201556, 0.7964743895201556, 0.7964743895201556, 0.89264497955995503, 0.63825065926173097, 0.79647438952015559, 0.96166146546166686, 0.79647438952015559, 0.79647438952015559, 0.79647438952015559, 0.79647438952015559, 0.79647438952015559, 0.79647438952015559]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m----------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   subsample | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "    1 | 04m35s | \u001b[35m-1674.97685\u001b[0m | \u001b[32m   2.6456\u001b[0m | \u001b[32m            0.6759\u001b[0m | \u001b[32m   6.4589\u001b[0m | \u001b[32m          0.4356\u001b[0m | \u001b[32m    10.4881\u001b[0m | \u001b[32m           16.0428\u001b[0m | \u001b[32m     0.9893\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "    2 | 04m47s | -9962.74479 |    7.7423 |             0.2290 |    4.3759 |           0.1011 |     12.1519 |            11.0490 |      0.8996 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "    3 | 05m31s | -187006.93229 |    4.5615 |             0.9502 |    8.9177 |           4.1631 |     11.0276 |            11.7928 |      0.7307 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "    4 | 04m15s | -187097.34896 |    5.6843 |             0.5697 |    9.6366 |           3.8908 |     10.4488 |            18.5863 |      0.8903 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "    5 | 03m32s | -187006.98958 |    0.1879 |             0.4732 |    3.8344 |           4.3501 |      9.2365 |             2.3497 |      0.5591 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m----------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   subsample | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "    6 | 03m01s | -187276.90625 |    9.9270 |             0.9322 |    0.2500 |           1.4850 |      6.2645 |             1.1124 |      0.8926 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "    7 | 06m52s | -7297.83529 |    8.8964 |             0.3185 |    0.5232 |           0.4690 |     14.3153 |            19.9606 |      0.6383 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "    8 | 03m04s | -187186.92188 |    9.9944 |             0.2647 |    6.4178 |           2.8567 |      9.9968 |             6.3382 |      0.7965 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "    9 | 06m27s | -13187.90137 |    0.5861 |             0.1761 |    0.6139 |           0.1965 |     14.1958 |            19.5706 |      0.9617 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "   10 | 03m04s | -187186.92188 |    9.9944 |             0.2647 |    6.4178 |           2.8567 |      9.9968 |             6.3382 |      0.7965 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "   11 | 03m09s | -187186.92188 |    9.9944 |             0.2647 |    6.4178 |           2.8567 |      9.9968 |             6.3382 |      0.7965 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "   12 | 03m05s | -187186.92188 |    9.9944 |             0.2647 |    6.4178 |           2.8567 |      9.9968 |             6.3382 |      0.7965 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "   13 | 03m04s | -187186.92188 |    9.9944 |             0.2647 |    6.4178 |           2.8567 |      9.9968 |             6.3382 |      0.7965 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "   14 | 03m04s | -187186.92188 |    9.9944 |             0.2647 |    6.4178 |           2.8567 |      9.9968 |             6.3382 |      0.7965 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "   15 | 03m04s | -187186.92188 |    9.9944 |             0.2647 |    6.4178 |           2.8567 |      9.9968 |             6.3382 |      0.7965 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {       'max_depth': (5, 15),\n",
    "                 'gamma': (0.0, 10.0),\n",
    "                 'min_child_weight': (1, 20),\n",
    "                 'max_delta_step': (0, 5),\n",
    "                 'subsample': (0.5, 1.0),\n",
    "                 'colsample_bytree' :(0.1, 1.0),\n",
    "                 'alpha': (0, 10)\n",
    "               }\n",
    "\n",
    "XGB_BOpt = BayesianOptimization(XGBcv, params)\n",
    "#XGB_BOpt.initialize(init_values)\n",
    "\n",
    "df = pd.read_csv('CSV_backups/ALL-sales.csv',nrows=100000)\n",
    "\n",
    "cols = df.columns\n",
    "ind2remove = ['Unnamed: 0', 'address', 'area_name', 'date_listed', 'id', 'listed_diff_id', 'lookup_address',\n",
    "              'origin_url', 'neighborhood', 'zipcode', 'luxurious', 'transaction_status', 'transaction_type',\n",
    "              'zestimate_sale']\n",
    "factors = np.setdiff1d(cols, ind2remove)\n",
    "\n",
    "dtrain = xgb.DMatrix(df[factors].values, label=df.price, feature_names=factors)\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# per link below i need to use Upper Confidence Bound and add some alpha (square of stdev), otherwise it starts to loop\n",
    "# https://github.com/fmfn/BayesianOptimization/issues/10 \n",
    "gp_params = { 'alpha' : 400000}\n",
    "XGB_BOpt.maximize(init_points=5, n_iter=10, acq='ucb', kappa=50, **gp_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target': [-207885.453125, -208155.27083333334, -208065.26041666666, -8482.436034999999, -208065.26041666666, -208065.26041666666, -208065.26041666666, -208065.26041666666, -208065.26041666666, -208065.26041666666, -187276.90625, -7297.8352863333339, -187186.921875, -13187.901367333334, -187186.921875, -187186.921875, -187186.921875, -187186.921875, -187186.921875, -187186.921875], 'alpha': [9.609593275137133, 0.6613706829779054, 9.99437912773472, 0.2082503541460734, 9.99437912773472, 9.99437912773472, 9.99437912773472, 9.99437912773472, 9.99437912773472, 9.99437912773472, 9.926950421589801, 8.8964024320545558, 9.9943791277347191, 0.58608203018219007, 9.9943791277347191, 9.9943791277347191, 9.9943791277347191, 9.9943791277347191, 9.9943791277347191, 9.9943791277347191], 'colsample_bytree': [0.3695897782674733, 0.8602917861499724, 0.26467482205195547, 0.2632600769188274, 0.26467482205195547, 0.26467482205195547, 0.26467482205195547, 0.26467482205195547, 0.26467482205195547, 0.26467482205195547, 0.93220963838148418, 0.31851666997270223, 0.26467482205195547, 0.17611852499412145, 0.26467482205195547, 0.26467482205195547, 0.26467482205195547, 0.26467482205195547, 0.26467482205195547, 0.26467482205195547], 'gamma': [9.865587065065188, 9.74686134560233, 6.417811142881344, 9.986369268602083, 6.417811142881344, 6.417811142881344, 6.417811142881344, 6.417811142881344, 6.417811142881344, 6.417811142881344, 0.2500394735324063, 0.52317867353906866, 6.4178111428813436, 0.6138584518188217, 6.4178111428813436, 6.4178111428813436, 6.4178111428813436, 6.4178111428813436, 6.4178111428813436, 6.4178111428813436], 'max_delta_step': [4.319369982200314, 1.4106219539239218, 2.8567339088646717, 0.62666064228038, 2.8567339088646717, 2.8567339088646717, 2.8567339088646717, 2.8567339088646717, 2.8567339088646717, 2.8567339088646717, 1.4850239461478287, 0.46898495419691544, 2.8567339088646717, 0.19645230111910383, 2.8567339088646717, 2.8567339088646717, 2.8567339088646717, 2.8567339088646717, 2.8567339088646717, 2.8567339088646717], 'max_depth': [5.051048152090837, 14.840043411931143, 9.996819662914094, 5.649088797554254, 9.996819662914094, 9.996819662914094, 9.996819662914094, 9.996819662914094, 9.996819662914094, 9.996819662914094, 6.2644943972420322, 14.315316864637497, 9.9968196629140937, 14.195801982264026, 9.9968196629140937, 9.9968196629140937, 9.9968196629140937, 9.9968196629140937, 9.9968196629140937, 9.9968196629140937], 'min_child_weight': [19.90604381074864, 1.5376515645602162, 6.3381577144228505, 19.934027009976592, 6.3381577144228505, 6.3381577144228505, 6.3381577144228505, 6.3381577144228505, 6.3381577144228505, 6.3381577144228505, 1.1124257567329519, 19.960599578245827, 6.3381577144228505, 19.570587168476809, 6.3381577144228505, 6.3381577144228505, 6.3381577144228505, 6.3381577144228505, 6.3381577144228505, 6.3381577144228505], 'subsample': [0.8722713229598846, 0.5416489553632888, 0.7964743895201556, 0.6059873611138029, 0.7964743895201556, 0.7964743895201556, 0.7964743895201556, 0.7964743895201556, 0.7964743895201556, 0.7964743895201556, 0.89264497955995503, 0.63825065926173097, 0.79647438952015559, 0.96166146546166686, 0.79647438952015559, 0.79647438952015559, 0.79647438952015559, 0.79647438952015559, 0.79647438952015559, 0.79647438952015559]}\n"
     ]
    }
   ],
   "source": [
    "# not used - reset the variable\n",
    "#new_init = { 'target': [], 'alpha': [], 'colsample_bytree': [], 'gamma': [], 'max_delta_step': [], 'max_depth': [], 'min_child_weight': [], 'subsample': [] }\n",
    "new_init = init_values\n",
    "\n",
    "# store resulting values to help seed the next run. make sure not to overwrite but add incrementally\n",
    "# copy paste the print out of init_values into the cell above\n",
    "for i in range(len(XGB_BOpt.res['all']['values'])):\n",
    "    new_init['target'].append(XGB_BOpt.res['all']['values'][i])\n",
    "    for k,v in XGB_BOpt.res['all']['params'][i].items():\n",
    "        new_init[k].append(v)\n",
    "    \n",
    "print (new_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "print(XGB_BOpt.res['max'])\n",
    "(pd.DataFrame(XGB_BOpt.res['all']['values'])*-1.0).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from cloudinary.uploader import upload\n",
    "from cloudinary.utils import cloudinary_url\n",
    "from cloudinary.api import delete_resources_by_tag, resources_by_tag\n",
    "\n",
    "def plot_rounds(plot):\n",
    "    # uploads the graph to the web and returns the URL\n",
    "    \n",
    "    fig = plot.get_figure()\n",
    "    fig.savefig('temp_plot.png')\n",
    "    \n",
    "    response = upload(\"temp_plot.png\")\n",
    "    url, options = cloudinary_url(response['public_id'],\n",
    "        format = response['format'],\n",
    "        crop = \"fill\")\n",
    "    return url\n",
    "\n",
    "def slack(text, url = None):\n",
    "    print(\"Slacking: \" + text)\n",
    "    \n",
    "    if url == None:\n",
    "        data=json.dumps({\"text\": text})\n",
    "    else:\n",
    "        data = json.dumps( { \"text\": text, \"attachments\": [ { \"fallback\": \"Model MAE\"\n",
    "                                           , \"title\": \"Model Mean Average Error by Iteration ($)\"\n",
    "                                           , \"image_url\": url } ] } )\n",
    "    \n",
    "    response = requests.post(webhook_url, data , headers={'Content-Type': 'application/json'})\n",
    "    if response.status_code != 200:\n",
    "        raise ValueError('Request to slack returned an error %s, the response is:\\n%s' % (response.status_code, response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame(XGB_BOpt.res['all']['params'])\n",
    "error = pd.Series(XGB_BOpt.res['all']['values']) * -1\n",
    "error.name = 'test-mae-mean'\n",
    "result = pd.concat([error, result], axis=1)\n",
    "result.head(25)\n",
    "\n",
    "url = plot_rounds(error.plot())\n",
    "slack(\"Bayesian Search: Max params %s\" % XGB_BOpt.res['max'], url)\n",
    "\n",
    "file = 'ALL-bayesian-parameters.csv'\n",
    "result.to_csv(file)\n",
    "slacker.files.upload(file, channels='#progress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
