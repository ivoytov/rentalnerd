{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Based on: https://github.com/fmfn/BayesianOptimization/blob/master/examples/xgboost_example.py\n",
    "Computes the best parameters for XGB model optimization\n",
    "'''\n",
    "\n",
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from bayes_opt import BayesianOptimization\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# data columns used for the booster\n",
    "factors = ['area_name', 'days_on_market', 'property_id', 'bedrooms', 'bathrooms', 'sqft','longitude', 'latitude','zipcode', 'elevation', 'garage'\n",
    "                          ,'year_built', 'level','dist_to_park','dist_to_golf_course', 'has_pool'\n",
    "                          ,'date_closed','multifamily', 'hoa_fees', 'lot', 'zestimate_rent', 'zestimate_sale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def XGBcv(eta, max_depth, gamma, min_child_weight, max_delta_step, subsample, colsample_bytree, alpha):\n",
    "    folds = 5\n",
    "    paramt = {\n",
    "        'verbose_eval': None,\n",
    "        'silent': 0,\n",
    "        'objective': 'reg:linear',\n",
    "        'booster': 'gbtree',\n",
    "        'eval_metric': 'mae',\n",
    "        'updater': 'grow_gpu',\n",
    "        'eta': max(eta, 0),\n",
    "        'max_depth': int(max_depth),\n",
    "        'alpha': max(alpha, 0),\n",
    "        'gamma': max(gamma, 0),\n",
    "        'subsample': max(min(subsample, 1), 0),\n",
    "        'colsample_bytree': max(min(colsample_bytree, 1), 0),\n",
    "        'min_child_weight': int(min_child_weight),\n",
    "        'max_delta_step': int(max_delta_step)\n",
    "    }\n",
    "    \n",
    "    out = xgb.cv(paramt,\n",
    "           dtrain,\n",
    "           num_boost_round=30000,\n",
    "           folds=tscv.split(dtrain),\n",
    "           callbacks=[xgb.callback.early_stop(50)])\n",
    "    \n",
    "    return -out['test-mae-mean'].values[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from past experiments\n",
    "#init_values = {'target': [-193446, -193446, -24459, -192546, -47780, -37024, -24803, -193746.078125, -193746.06770833334, -25118.120442333337, -193446.38541666666, -25894.672526, -28622.063151, -193446.38541666666, -193446.38541666666, -193446.38541666666, -193446.38541666666, -193446.38541666666, -193146.109375, -192847.13020833334, -193746.078125, -193446.38541666666, -193446.38541666666, -193446.38541666666, -193446.38541666666, -193446.38541666666, -193446.38541666666, -193446.38541666666], 'alpha': [9.99437912773472, 10.0, 10.0, 10.0, 0.0, 0.0, 10.0, 4.015546409782273, 9.926950421589801, 8.896402432054556, 9.99437912773472, 0.5860820301821901, 0.2082503541460734, 9.99437912773472, 9.99437912773472, 9.99437912773472, 9.99437912773472, 9.99437912773472, 0.80436438137688415, 9.2037783619021472, 4.0155464097822726, 9.9943791277347191, 9.9943791277347191, 9.9943791277347191, 9.9943791277347191, 9.9943791277347191, 9.9943791277347191, 9.9943791277347191], 'colsample_bytree': [0.26467482205195547, 1.0, 1.0, 0.1, 0.1, 0.1, 1.0, 0.7833851019508481, 0.9322096383814842, 0.3185166699727022, 0.26467482205195547, 0.17611852499412145, 0.2632600769188274, 0.26467482205195547, 0.26467482205195547, 0.26467482205195547, 0.26467482205195547, 0.26467482205195547, 0.86097644716887534, 0.13285454916293565, 0.7833851019508481, 0.26467482205195547, 0.26467482205195547, 0.26467482205195547, 0.26467482205195547, 0.26467482205195547, 0.26467482205195547, 0.26467482205195547], 'gamma': [6.417811142881344, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.135534847780158, 0.2500394735324063, 0.5231786735390687, 6.417811142881344, 0.6138584518188217, 9.986369268602083, 6.417811142881344, 6.417811142881344, 6.417811142881344, 6.417811142881344, 6.417811142881344, 0.2275677738994164, 0.088652374383074717, 5.1355348477801579, 6.4178111428813436, 6.4178111428813436, 6.4178111428813436, 6.4178111428813436, 6.4178111428813436, 6.4178111428813436, 6.4178111428813436], 'max_delta_step': [2.8567339088646717, 2.2602105756123785, 0.0, 5.0, 0.0, 0.0, 0.0, 1.4019764818025178, 1.4850239461478287, 0.46898495419691544, 2.8567339088646717, 0.19645230111910383, 0.62666064228038, 2.8567339088646717, 2.8567339088646717, 2.8567339088646717, 2.8567339088646717, 2.8567339088646717, 3.165663024094056, 4.9049044579924264, 1.4019764818025178, 2.8567339088646717, 2.8567339088646717, 2.8567339088646717, 2.8567339088646717, 2.8567339088646717, 2.8567339088646717, 2.8567339088646717], 'max_depth': [9.996819662914094, 5.0, 15.0, 5.0, 15.0, 5.0, 15.0, 6.649297681680842, 6.264494397242032, 14.315316864637497, 9.996819662914094, 14.195801982264026, 5.649088797554254, 9.996819662914094, 9.996819662914094, 9.996819662914094, 9.996819662914094, 9.996819662914094, 5.7563941946454333, 14.886726836368352, 6.6492976816808422, 9.9968196629140937, 9.9968196629140937, 9.9968196629140937, 9.9968196629140937, 9.9968196629140937, 9.9968196629140937, 9.9968196629140937], 'min_child_weight': [6.3381577144228505, 19.494684702216194, 20.0, 1.0, 1.0, 20.0, 1.0, 9.297862559862699, 1.1124257567329519, 19.960599578245827, 6.3381577144228505, 19.57058716847681, 19.934027009976592, 6.3381577144228505, 6.3381577144228505, 6.3381577144228505, 6.3381577144228505, 6.3381577144228505, 19.950610038312728, 1.3119667615461024, 9.2978625598626987, 6.3381577144228505, 6.3381577144228505, 6.3381577144228505, 6.3381577144228505, 6.3381577144228505, 6.3381577144228505, 6.3381577144228505], 'subsample': [0.7964743895201556, 0.5, 1.0, 0.5, 0.5, 1.0, 1.0, 0.5057064445599841, 0.892644979559955, 0.638250659261731, 0.7964743895201556, 0.9616614654616669, 0.6059873611138029, 0.7964743895201556, 0.7964743895201556, 0.7964743895201556, 0.7964743895201556, 0.7964743895201556, 0.53720760387562039, 0.65232968466409491, 0.50570644455998415, 0.79647438952015559, 0.79647438952015559, 0.79647438952015559, 0.79647438952015559, 0.79647438952015559, 0.79647438952015559, 0.79647438952015559]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m----------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha |   colsample_bytree |       eta |     gamma |   max_delta_step |   max_depth |   min_child_weight |   subsample | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "    1 | 190m50s | \u001b[35m-102906.15365\u001b[0m | \u001b[32m   9.8231\u001b[0m | \u001b[32m            0.5659\u001b[0m | \u001b[32m   0.9139\u001b[0m | \u001b[32m   4.7747\u001b[0m | \u001b[32m          4.8645\u001b[0m | \u001b[32m    10.2601\u001b[0m | \u001b[32m           14.1032\u001b[0m | \u001b[32m     0.9590\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "    2 | 249m34s | -189572.75000 |    6.8514 |             0.2937 |    0.1268 |    7.1847 |           4.4766 |     11.9052 |            14.0477 |      0.8435 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[27]\ttrain-mae:40336.9+511.778\ttest-mae:40891.7+448.819\n",
      "\n",
      "    3 | 05m29s | \u001b[35m-40891.65104\u001b[0m | \u001b[32m   3.0038\u001b[0m | \u001b[32m            0.5818\u001b[0m | \u001b[32m   0.9359\u001b[0m | \u001b[32m   5.2934\u001b[0m | \u001b[32m          0.3594\u001b[0m | \u001b[32m     6.1628\u001b[0m | \u001b[32m           11.6286\u001b[0m | \u001b[32m     0.6394\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "    4 | 232m13s | -148004.10417 |    5.0871 |             0.5909 |    0.4737 |    4.9695 |           4.2517 |     13.8214 |             6.2333 |      0.6372 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[15]\ttrain-mae:35635+523.113\ttest-mae:39195.4+382.49\n",
      "\n",
      "    5 | 05m42s | \u001b[35m-39195.37500\u001b[0m | \u001b[32m   8.7477\u001b[0m | \u001b[32m            0.3798\u001b[0m | \u001b[32m   0.6694\u001b[0m | \u001b[32m   3.3636\u001b[0m | \u001b[32m          0.0296\u001b[0m | \u001b[32m    12.0087\u001b[0m | \u001b[32m           14.8001\u001b[0m | \u001b[32m     0.7008\u001b[0m | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m----------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha |   colsample_bytree |       eta |     gamma |   max_delta_step |   max_depth |   min_child_weight |   subsample | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[23]\ttrain-mae:43109.9+443.094\ttest-mae:43404.8+392.459\n",
      "\n",
      "    6 | 05m27s | -43404.79557 |    0.1484 |             0.6054 |    0.7472 |    0.2076 |           0.0101 |      5.5702 |             1.1016 |      0.6057 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "    7 | 230m18s | -120814.48958 |    6.8398 |             0.9315 |    0.7214 |    3.0585 |           4.1179 |     12.9399 |            18.1821 |      0.8707 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "    8 | 2432m20s | -120814.48958 |    6.8398 |             0.9315 |    0.7214 |    3.0585 |           4.1179 |     12.9399 |            18.1821 |      0.8707 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n"
     ]
    }
   ],
   "source": [
    "params = { 'eta': (0, 0.3),\n",
    "                 'max_depth': (5, 15),\n",
    "                 'gamma': (0.0, 10.0),\n",
    "                 'min_child_weight': (1, 20),\n",
    "                 'max_delta_step': (0, 5),\n",
    "                 'subsample': (0.5, 1.0),\n",
    "                 'colsample_bytree' :(0.1, 1.0),\n",
    "                 'alpha': (0, 10)\n",
    "               }\n",
    "\n",
    "XGB_BOpt = BayesianOptimization(XGBcv, params)\n",
    "#XGB_BOpt.initialize(init_values)\n",
    "\n",
    "df = pd.read_csv('CSV_backups/ALL-sales.csv')\n",
    "\n",
    "# uncomment this to run on a subset of the dataset (for debugging)\n",
    "#msk = np.random.rand(len(df)) < 0.1  # pick x% of the dataset for a quick run, 100% would be entire dataset\n",
    "#df = df[msk]\n",
    "\n",
    "dtrain = xgb.DMatrix(df[factors].values, label=df.price, feature_names=factors)\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# per link below i need to use Upper Confidence Bound and add some alpha (square of stdev), otherwise it starts to loop\n",
    "# https://github.com/fmfn/BayesianOptimization/issues/10 \n",
    "gp_params = { 'alpha' : 400000}\n",
    "XGB_BOpt.maximize(init_points=5, n_iter=10, acq='ucb', kappa=50, **gp_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# not used - reset the variable\n",
    "#new_init = { 'target': [], 'alpha': [], 'colsample_bytree': [], 'gamma': [], 'max_delta_step': [], 'max_depth': [], 'min_child_weight': [], 'subsample': [] }\n",
    "new_init = init_values\n",
    "\n",
    "# store resulting values to help seed the next run. make sure not to overwrite but add incrementally\n",
    "# copy paste the print out of init_values into the cell above\n",
    "for i in range(len(XGB_BOpt.res['all']['values'])):\n",
    "    new_init['target'].append(XGB_BOpt.res['all']['values'][i])\n",
    "    for k,v in XGB_BOpt.res['all']['params'][i].items():\n",
    "        new_init[k].append(v)\n",
    "    \n",
    "print (new_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "print(XGB_BOpt.res['max'])\n",
    "(pd.DataFrame(XGB_BOpt.res['all']['values'])*-1.0).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from cloudinary.uploader import upload\n",
    "from cloudinary.utils import cloudinary_url\n",
    "from cloudinary.api import delete_resources_by_tag, resources_by_tag\n",
    "\n",
    "\n",
    "from slacker import Slacker\n",
    "import os\n",
    "# slack secrets (in your ~/.bashrc)\n",
    "slack_webhook_url = os.environ.get('SLACK_WEBHOOK')\n",
    "slacker = Slacker(os.environ.get('SLACK_TOKEN'))\n",
    "\n",
    "\n",
    "def plot_rounds(plot):\n",
    "    # uploads the graph to the web and returns the URL\n",
    "    \n",
    "    fig = plot.get_figure()\n",
    "    fig.savefig('temp_plot.png')\n",
    "    \n",
    "    response = upload(\"temp_plot.png\")\n",
    "    url, options = cloudinary_url(response['public_id'],\n",
    "        format = response['format'],\n",
    "        crop = \"fill\")\n",
    "    return url\n",
    "\n",
    "def slack(text, url = None):\n",
    "    print(\"Slacking: \" + text)\n",
    "    \n",
    "    if url == None:\n",
    "        data=json.dumps({\"text\": text})\n",
    "    else:\n",
    "        data = json.dumps( { \"text\": text, \"attachments\": [ { \"fallback\": \"Model MAE\"\n",
    "                                           , \"title\": \"Model Mean Average Error by Iteration ($)\"\n",
    "                                           , \"image_url\": url } ] } )\n",
    "    \n",
    "    response = requests.post(webhook_url, data , headers={'Content-Type': 'application/json'})\n",
    "    if response.status_code != 200:\n",
    "        raise ValueError('Request to slack returned an error %s, the response is:\\n%s' % (response.status_code, response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame(XGB_BOpt.res['all']['params'])\n",
    "error = pd.Series(XGB_BOpt.res['all']['values']) * -1\n",
    "error.name = 'test-mae-mean'\n",
    "result = pd.concat([error, result], axis=1)\n",
    "result.head(25)\n",
    "\n",
    "url = plot_rounds(error.plot())\n",
    "slack(\"Bayesian Search: Max params %s\" % XGB_BOpt.res['max'], url)\n",
    "\n",
    "file = 'PH-bayesian-parameters.csv'\n",
    "result.to_csv(file)\n",
    "slacker.files.upload(file, channels='#progress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
