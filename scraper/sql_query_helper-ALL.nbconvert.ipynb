{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Connected: prod@rental_nerd'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext sql\n",
    "\n",
    "# imports\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "# today's date for output filenames\n",
    "today = dt.date.today()\n",
    "\n",
    "# %sql mysql://root@localhost/rental_nerd\n",
    "%sql mysql://prod:nerd@52.2.153.189/rental_nerd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def top_zipcodes(n = 100):\n",
    "    # query the top 100 zipcodes in the database (roughly equal to all zipcodes >10k properties)\n",
    "    query = %sql (\\\n",
    "    SELECT zipcode, COUNT(id) \\\n",
    "    FROM properties \\\n",
    "    GROUP BY zipcode \\\n",
    "    ORDER BY 2 DESC \\\n",
    "    limit :n)\n",
    "\n",
    "    zipcode_filter = query.DataFrame()\n",
    "#     print(\"Top zipcode by count is\",zipcode_filter.iloc[0,0],\"with\",zipcode_filter.iloc[0,1],\"properties\")\n",
    "#     print(\"100th zipcode by count is\",zipcode_filter.iloc[99,0],\"with\",zipcode_filter.iloc[99,1],\"properties\")\n",
    "    return zipcode_filter.zipcode.values\n",
    "\n",
    "def city_query():\n",
    "    query = %sql (\\\n",
    "    SELECT area_name, COUNT(id) \\\n",
    "    FROM area_name_zipcodes \\\n",
    "    GROUP BY area_name \\\n",
    "    ORDER BY 2 DESC \\\n",
    "    limit 100)\n",
    "    return query.DataFrame().area_name.values\n",
    "\n",
    "def sanitize(data, zipcode_list = None):\n",
    "    # abort if the city has no top zipcodes\n",
    "    if data.empty:\n",
    "        return 0    \n",
    "    \n",
    "    data.drop(['abnormal', 'bookmarked', 'created_at', 'ignore', 'is_latest', 'closed_diff_id', 'id', 'listed_diff_id',\n",
    "                      'notes', 'source', 'updated_at', 'home_type', 'sfh', 'description', \n",
    "                    'event_name', 'neighborhood'], axis=1, inplace=True)\n",
    "    \n",
    "    # filters out any non-sensical values or fat finger mistakes in MLS listings\n",
    "    print(\"Entries before filter: \", len(data))\n",
    "\n",
    "    if(data.transaction_type.iloc[0] == 'sales'):\n",
    "        data = data[ data.price > 50000 ]\n",
    "    else:\n",
    "        data = data [ data.price > 500 ]\n",
    "    \n",
    "    if(zipcode_list is not None):\n",
    "        data = data[data.zipcode.isin(zipcode_list)]\n",
    "\n",
    "    print(\"Entries after filter: \",len(data))\n",
    "    \n",
    "    # fills in some sensible defaults where data is missing\n",
    "    data[\"near_golf_course\"] = data[\"near_golf_course\"].apply(lambda x: True if x == 1.0 else False)\n",
    "    data[\"has_pool\"] = data[\"has_pool\"].apply(lambda x: True if x == 1.0 else False)\n",
    "    data[\"garage\"] = data[\"garage\"].apply(lambda x: True if x == 1.0 else False)\n",
    "    data['date_closed'] = data['date_closed'].apply(lambda x: 0 if x == None else (x - dt.date(2000, 1, 1)).days)\n",
    "    data['date_closed'] = data['date_closed'].astype(int)\n",
    "    \n",
    "    # convert the area name into dummy variables\n",
    "    dm = pd.get_dummies(data[['area_name', 'zipcode']], prefix=['area_name','zipcode'])\n",
    "    data = pd.concat([data, dm], axis=1)\n",
    "    del dm\n",
    "    \n",
    "    return data\n",
    "\n",
    "def generate_city_model(sales_train, sales_test, for_sale):\n",
    "    # cap number of homes that fit into VRAM\n",
    "    memory_cap = 250000\n",
    "    \n",
    "    # init empty model that we can load into on the second iteration\n",
    "    bst = xgb.Booster()\n",
    "    \n",
    "    # first run the price model\n",
    "    label = 'price'\n",
    "    f = factors\n",
    "    f.remove(label) # this happens in place\n",
    "    \n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    for g, df in sales_train.groupby(np.arange(limit) // memory_cap):  # split the dataset into 250k chunks    \n",
    "        train_model(df, sales_test, f, label, xgb_model = (bst if g > 0 else None))\n",
    "        \n",
    "        # load the model into memory - should have been saved by train_model function\n",
    "        bst.load_model(path +  'all_' + label + '_' + today.strftime('%Y%m%d') + '.model')\n",
    "    \n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    slack(\"%s:\\tTime to train:\\t%f minutes\" % (city, (elapsed / 60)))\n",
    "    \n",
    "    target = xgb.DMatrix( for_sale[f].values, feature_names=f)\n",
    "    ypred = bst.predict(target, ntree_limit=(bst.best_iteration if hasattr(bst, 'best_score') else None))\n",
    "\n",
    "    # second run the days on the market model\n",
    "    sales_train = sales_train[(sales.days_on_market > 0 )]\n",
    "    sales_test = sales_test[(sales.days_on_market > 0 )]\n",
    "    label = 'days_on_market'\n",
    "    f = factors\n",
    "    f.remove(label)\n",
    "    \n",
    "    start_time = timeit.default_timer()\n",
    "    for g, df in sales_train.groupby(np.arange(limit) // memory_cap):  # split the dataset into 100k chunks    \n",
    "        train_model(df, sales_test, f, label, xgb_model = (bst if g > 0 else None))\n",
    "        \n",
    "        # load the model into memory - should have been saved by train_model function\n",
    "        bst.load_model(path +  'all_' + label + '_' + today.strftime('%Y%m%d') + '.model')\n",
    "    \n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    slack(\"%s:\\tTime to train:\\t%f minutes\" % (city, (elapsed / 60)))\n",
    "    \n",
    "    target = xgb.DMatrix( for_sale[f].values, feature_names=f)\n",
    "    dayspred = bst.predict(target, ntree_limit=(bst.best_iteration if hasattr(bst, 'best_score') else None))\n",
    "\n",
    "    \n",
    "    values = np.column_stack((for_sale.property_id.values\n",
    "                             ,for_sale.address.values\n",
    "                             ,ypred\n",
    "                             ,for_sale.price.values\n",
    "                             ,ypred-for_sale.price\n",
    "                             ,ypred / for_sale.price - 1\n",
    "                             ,dayspred\n",
    "                             ,for_sale['origin_url'].values))\n",
    "    output = pd.DataFrame(values[:,1:],index=values[:,0],columns=['address','ypred',\n",
    "                                                                  'list','gain-loss', 'gain-loss%','days_pred', 'url'])\n",
    "    output = output.sort_values(by='gain-loss',ascending=False)\n",
    "\n",
    "    # save target list\n",
    "    file = 'all_target_list.csv'\n",
    "    output.to_csv(file)\n",
    "    slacker.files.upload(file, channels='#progress')\n",
    "\n",
    "def query(city=\"%\", zipcode=None, limit=100, start_date=\"2000-01-01 10:01:13\", ttype='sales',tstatus='open'):\n",
    "    # convert array of zipcodes into sql string which looks like a tuple\n",
    "    placeholders = tuple(zipcode)\n",
    "    \n",
    "    # sql query helper function\n",
    "    query = %sql (\\\n",
    "    SELECT  \\\n",
    "    *, \\\n",
    "    property_transaction_logs.id as 'transaction_id' \\\n",
    "    FROM  \\\n",
    "    properties, \\\n",
    "    property_transaction_logs, \\\n",
    "    area_name_zipcodes \\\n",
    "    where  \\\n",
    "    property_transaction_logs.abnormal != true and \\\n",
    "    properties.sqft between 1 and 10000 and \\\n",
    "    property_transaction_logs.price between 500 and 400000 and \\\n",
    "    properties.bedrooms <= 6 and \\\n",
    "    properties.bathrooms <= 6 and \\\n",
    "    properties.home_type = 'sfh' and \\\n",
    "    area_name_zipcodes.`area_name` LIKE :city and \\\n",
    "    area_name_zipcodes.`zipcode` = properties.`zipcode` and     \\\n",
    "    properties.zipcode IN :placeholders and \\\n",
    "    properties.`id` = property_transaction_logs.`property_id` and \\\n",
    "    property_transaction_logs.`transaction_type` = :ttype and \\\n",
    "    property_transaction_logs.`transaction_status` = :tstatus and \\\n",
    "    property_transaction_logs.`is_latest` = true \\\n",
    "    order by \\\n",
    "    property_transaction_logs.id desc \\\n",
    "    limit :limit) \n",
    "\n",
    "    q = query.DataFrame()\n",
    "    q.set_index('property_id', inplace=True)\n",
    "    q.index.name = 'property_id'\n",
    "    return q.T.groupby(level=0).first().T\n",
    "\n",
    "def queue_city_queries(city, zipcode_list, for_sale_zipcode_list):\n",
    "    i = query(zipcode=zipcode_list, limit=limit,ttype = 'sales',tstatus='closed')\n",
    "    j = query(zipcode=for_sale_zipcode_list, limit=limit,ttype = 'sales',tstatus='open') \n",
    "    k = query(zipcode=zipcode_list, limit=limit,ttype = 'rental',tstatus='closed')\n",
    "    \n",
    "    q = pd.concat([i,j,k])\n",
    "    q = sanitize(q)\n",
    "    \n",
    "    for_sale = q[(q.transaction_type == \"sales\") & \n",
    "                 (q.transaction_status == \"open\") & \n",
    "                 (q.date_listed > (today - dt.timedelta(days=60))) &\n",
    "                 (q.zipcode.isin(for_sale_zipcode_list))]\n",
    "    sales = q[(q.transaction_type == \"sales\") & (q.transaction_status == \"closed\")]\n",
    "    rent = q[(q.transaction_type == \"rental\") & (q.transaction_status == \"closed\")]\n",
    "        \n",
    "    data = {'sales': sales, 'rentals': rent, 'for_sale': for_sale }\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1216 rows affected.\n",
      "1216 rows affected.\n"
     ]
    }
   ],
   "source": [
    "# get list of top zipcodes to only run the model on them (put down 2000 to get every zipcode)\n",
    "zipcode_list = top_zipcodes(2000)\n",
    "\n",
    "# we filter the current listings further to only see the top zipcodes to not predict prices in areas with weak coverage\n",
    "focus_zipcodes = top_zipcodes(2000)\n",
    "\n",
    "# limit on number of lines returned from sql queries (for debugging)\n",
    "limit = 2000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191458 rows affected.\n",
      "75275 rows affected.\n",
      "139448 rows affected.\n",
      "Entries before filter:  406181\n",
      "Entries after filter:  223585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ilya/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ilya/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ilya/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ilya/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "q = queue_city_queries(\"%\", zipcode_list, focus_zipcodes)\n",
    "\n",
    "for k,v in q.items():\n",
    "    v.to_csv('CSV_backups/ALL-' + k + '.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>adult</th>\n",
       "      <th>area_name</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>construction</th>\n",
       "      <th>date_closed</th>\n",
       "      <th>date_listed</th>\n",
       "      <th>date_transacted_latest</th>\n",
       "      <th>days_on_market</th>\n",
       "      <th>...</th>\n",
       "      <th>zipcode_98146</th>\n",
       "      <th>zipcode_98148</th>\n",
       "      <th>zipcode_98155</th>\n",
       "      <th>zipcode_98166</th>\n",
       "      <th>zipcode_98168</th>\n",
       "      <th>zipcode_98177</th>\n",
       "      <th>zipcode_98178</th>\n",
       "      <th>zipcode_98188</th>\n",
       "      <th>zipcode_98198</th>\n",
       "      <th>zipcode_98199</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7498334</th>\n",
       "      <td>16202 W Mohave St, Goodyear, AZ 85338</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PH</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4717</td>\n",
       "      <td>2012-09-13</td>\n",
       "      <td>2012-11-30</td>\n",
       "      <td>78</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7491241</th>\n",
       "      <td>12544 W Alegre Dr, Litchfield Park, AZ 85340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PH</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5354</td>\n",
       "      <td>2014-05-07</td>\n",
       "      <td>2014-08-29</td>\n",
       "      <td>114</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7481107</th>\n",
       "      <td>15542 W Supai Cir, Goodyear, AZ 85338</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PH</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5149</td>\n",
       "      <td>2014-01-03</td>\n",
       "      <td>2014-02-05</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7477602</th>\n",
       "      <td>10804 E Salsabila Rd, Tucson, AZ 85747</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TUSCON</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6003</td>\n",
       "      <td>2016-04-29</td>\n",
       "      <td>2016-06-08</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7477511</th>\n",
       "      <td>9038 E Crystal Dr, Sun Lakes, AZ 85248</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PH</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5595</td>\n",
       "      <td>2015-02-12</td>\n",
       "      <td>2015-04-27</td>\n",
       "      <td>74</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 666 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   address adult area_name  \\\n",
       "property_id                                                                  \n",
       "7498334             16202 W Mohave St, Goodyear, AZ 85338    NaN        PH   \n",
       "7491241      12544 W Alegre Dr, Litchfield Park, AZ 85340    NaN        PH   \n",
       "7481107             15542 W Supai Cir, Goodyear, AZ 85338    NaN        PH   \n",
       "7477602            10804 E Salsabila Rd, Tucson, AZ 85747    NaN    TUSCON   \n",
       "7477511            9038 E Crystal Dr, Sun Lakes, AZ 85248    NaN        PH   \n",
       "\n",
       "            bathrooms bedrooms construction  date_closed date_listed  \\\n",
       "property_id                                                            \n",
       "7498334             3        5          NaN         4717  2012-09-13   \n",
       "7491241             2        5          NaN         5354  2014-05-07   \n",
       "7481107             2        3          NaN         5149  2014-01-03   \n",
       "7477602             4        5          NaN         6003  2016-04-29   \n",
       "7477511             2        2          NaN         5595  2015-02-12   \n",
       "\n",
       "            date_transacted_latest days_on_market      ...      zipcode_98146  \\\n",
       "property_id                                            ...                      \n",
       "7498334                 2012-11-30             78      ...                  0   \n",
       "7491241                 2014-08-29            114      ...                  0   \n",
       "7481107                 2014-02-05             33      ...                  0   \n",
       "7477602                 2016-06-08             40      ...                  0   \n",
       "7477511                 2015-04-27             74      ...                  0   \n",
       "\n",
       "            zipcode_98148 zipcode_98155 zipcode_98166 zipcode_98168  \\\n",
       "property_id                                                           \n",
       "7498334                 0             0             0             0   \n",
       "7491241                 0             0             0             0   \n",
       "7481107                 0             0             0             0   \n",
       "7477602                 0             0             0             0   \n",
       "7477511                 0             0             0             0   \n",
       "\n",
       "            zipcode_98177 zipcode_98178 zipcode_98188 zipcode_98198  \\\n",
       "property_id                                                           \n",
       "7498334                 0             0             0             0   \n",
       "7491241                 0             0             0             0   \n",
       "7481107                 0             0             0             0   \n",
       "7477602                 0             0             0             0   \n",
       "7477511                 0             0             0             0   \n",
       "\n",
       "            zipcode_98199  \n",
       "property_id                \n",
       "7498334                 0  \n",
       "7491241                 0  \n",
       "7481107                 0  \n",
       "7477602                 0  \n",
       "7477511                 0  \n",
       "\n",
       "[5 rows x 666 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q['sales'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
